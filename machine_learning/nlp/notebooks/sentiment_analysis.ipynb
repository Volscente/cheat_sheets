{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "\n",
    "This notebooks is intended to experiment with NLP Sentiment Analysis Text Classification task."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Flair"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Standard Libraries\n",
    "import flair"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define input sentence\n",
    "input_text = 'I like you!'\n",
    "input_text_2 = \"I hate it when I'm not learning\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenize the input through Flair\n",
    "input_text_tokens = flair.data.Sentence(input_text)\n",
    "input_text_2_tokens = flair.data.Sentence(input_text_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'I like you !'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_text_tokens.to_tokenized_string()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialise the model \"Distillbert\"\n",
    "model_flair = flair.models.TextClassifier.load('en-sentiment')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict the sentiment\n",
    "model_flair.predict(input_text_tokens)\n",
    "model_flair.predict(input_text_2_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentiment: NEGATIVE\n",
      "Score: 0.9991464614868164\n"
     ]
    }
   ],
   "source": [
    "# Extract rating\n",
    "print('Sentiment: {}'.format(input_text_2_tokens.get_labels()[0].value))\n",
    "print('Score: {}'.format(input_text_2_tokens.get_labels()[0].score))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Finbert\n",
    "\n",
    "The model would be [ProsusAI/finbert](https://huggingface.co/ProsusAI/finbert) from **Hugging Face**, which is specialized in financial text. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Standard Libraries\n",
    "from transformers import BertTokenizer\n",
    "from transformers import AutoModelForSequenceClassification\n",
    "\n",
    "import torch.nn.functional as F\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input text (Investing Subreddit post)\n",
    "input_text_finbert_1 = (\"Given the recent downturn in stocks especially in tech which is likely to persist as yields keep going up, \"\n",
    "                        \"I thought it would be prudent to share the risks of investing in ARK ETFs, written up very nicely by \"\n",
    "                        \"[The Bear Cave](https://thebearcave.substack.com/p/special-edition-will-ark-invest-blow). The risks comes \"\n",
    "                        \"primarily from ARK's illiquid and very large holdings in small cap companies. ARK is forced to sell its \"\n",
    "                        \"holdings whenever its liquid ETF gets hit with outflows as is especially the case in market downturns. \"\n",
    "                        \"This could force very painful liquidations at unfavorable prices and the ensuing crash goes into a \"\n",
    "                        \"positive feedback loop leading into a death spiral enticing even more outflows and predatory shorts.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instance a Bert Tokenizer\n",
    "# NOTE: Transformers might need the appropriate tokenizer for preparing the input data\n",
    "bert_tokenizer = BertTokenizer.from_pretrained('ProsusAI/finbert')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenize the Finbert input\n",
    "tokens_finbert_1 = bert_tokenizer.encode_plus(input_text_finbert_1, \n",
    "                                              max_length=512, # Max token length\n",
    "                                              truncation=True, # If sequence is bigger, drop it\n",
    "                                              padding='max_length', #\n",
    "                                              add_special_tokens=True, # CLS = 101, SEP = 102, MASK = 103, UNK = 100, PAD = 0\n",
    "                                              return_tensors='pt') # PyTorch Tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialise the Finbert model\n",
    "model_finbert = AutoModelForSequenceClassification.from_pretrained('ProsusAI/finbert')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finbert Inference - Compute the activations\n",
    "output_finbert_1 = model_finbert(**tokens_finbert_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SequenceClassifierOutput(loss=None, logits=tensor([[-1.8200,  2.4484,  0.0216]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# In order to have probs from the activations, we need to pass them through an acitvation function\n",
    "output_finbert_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply the Softmax function to all the dimensions of the input tensor\n",
    "probs = F.softmax(output_finbert_1[0], dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    }
   ],
   "source": [
    "# Reitreve max prob\n",
    "prediction = torch.argmax(probs)\n",
    "\n",
    "print(prediction.item())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Kaggle Movie Reviews\n",
    "\n",
    "The data is from Kaggle and can be found [here](https://www.kaggle.com/c/sentiment-analysis-on-movie-reviews/data)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/s.porreca/.local/share/virtualenvs/cheat_sheets-EiW5VkhA/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "2023-12-13 20:36:25.784641: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "# Import Standard Libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from transformers import BertTokenizer\n",
    "from transformers import TFAutoModel\n",
    "\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Read data\n",
    "movie_reviews_train = pd.read_csv('./../../../data/movie_reviews_train.tsv', sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PhraseId</th>\n",
       "      <th>SentenceId</th>\n",
       "      <th>Phrase</th>\n",
       "      <th>Sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>A series of escapades demonstrating the adage ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>A series of escapades demonstrating the adage ...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>A series</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>A</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>series</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156055</th>\n",
       "      <td>156056</td>\n",
       "      <td>8544</td>\n",
       "      <td>Hearst 's</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156056</th>\n",
       "      <td>156057</td>\n",
       "      <td>8544</td>\n",
       "      <td>forced avuncular chortles</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156057</th>\n",
       "      <td>156058</td>\n",
       "      <td>8544</td>\n",
       "      <td>avuncular chortles</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156058</th>\n",
       "      <td>156059</td>\n",
       "      <td>8544</td>\n",
       "      <td>avuncular</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156059</th>\n",
       "      <td>156060</td>\n",
       "      <td>8544</td>\n",
       "      <td>chortles</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>156060 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        PhraseId  SentenceId  \\\n",
       "0              1           1   \n",
       "1              2           1   \n",
       "2              3           1   \n",
       "3              4           1   \n",
       "4              5           1   \n",
       "...          ...         ...   \n",
       "156055    156056        8544   \n",
       "156056    156057        8544   \n",
       "156057    156058        8544   \n",
       "156058    156059        8544   \n",
       "156059    156060        8544   \n",
       "\n",
       "                                                   Phrase  Sentiment  \n",
       "0       A series of escapades demonstrating the adage ...          1  \n",
       "1       A series of escapades demonstrating the adage ...          2  \n",
       "2                                                A series          2  \n",
       "3                                                       A          2  \n",
       "4                                                  series          2  \n",
       "...                                                   ...        ...  \n",
       "156055                                          Hearst 's          2  \n",
       "156056                          forced avuncular chortles          1  \n",
       "156057                                 avuncular chortles          3  \n",
       "156058                                          avuncular          2  \n",
       "156059                                           chortles          2  \n",
       "\n",
       "[156060 rows x 4 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movie_reviews_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop duplicates and keep only single sentence (you can see they are repeated)\n",
    "movie_reviews_train = movie_reviews_train.drop_duplicates('SentenceId', keep='first')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: >"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Check the distribution of the Sentiment (0: negative - 4: positive)\n",
    "movie_reviews_train['Sentiment'].value_counts().plot(kind='bar')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenize with Bert\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-cased')\n",
    "\n",
    "# In latest version is better to call \"tokenizer\" itself instead of \"encode_plus\" function\n",
    "movie_reviews_train_tokens = tokenizer(movie_reviews_train['Phrase'].tolist(),\n",
    "                                       max_length=512,\n",
    "                                       truncation=True,\n",
    "                                       padding='max_length',\n",
    "                                       add_special_tokens=True,\n",
    "                                       return_tensors='np')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['input_ids', 'token_type_ids', 'attention_mask'])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movie_reviews_train_tokens.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**NOTE:** \n",
    "\n",
    "THe `attention_mask` is used in order to exclude from the computation the `[PAD]` special tokens.\n",
    "Consider the following example.\n",
    "\n",
    "*Input Sequence*: \"This is a short sentence\" &rarr; It has 5 tokens/words &rarr; If the max token length is 8 &rarr; [\"this\", \"is\", \"a\", \"short\", sentence\", [PAD], [PAD], [PAD]] &rarr; *Attention Mask*: [1, 1, 1, 1, 1, 0, 0, 0], because the last tokens are padding and thus not relevant."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the tokens in a binary file\n",
    "with open('./../tensors/movie-xids.npy', 'wb') as file:\n",
    "    np.save(file, movie_reviews_train_tokens['input_ids'])\n",
    "with open('./../tensors/movie-xmask.npy', 'wb') as file:\n",
    "    np.save(file, movie_reviews_train_tokens['attention_mask'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract labels\n",
    "labels = movie_reviews_train['Sentiment'].values\n",
    "\n",
    "# Retrieve number of labels\n",
    "num_labels = labels.max() + 1\n",
    "\n",
    "# Retrieve number of data points\n",
    "num_samples = len(movie_reviews_train)\n",
    "\n",
    "# Initialise empty one-hot labels encoded matrix\n",
    "labels_encoded = np.zeros((num_samples, num_labels))\n",
    "\n",
    "# One-hot encode the labels\n",
    "labels_encoded[np.arange(num_samples), labels] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 4, 1, ..., 1, 1, 2])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 1., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 1.],\n",
       "       [0., 1., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 1., 0., 0., 0.],\n",
       "       [0., 1., 0., 0., 0.],\n",
       "       [0., 0., 1., 0., 0.]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels_encoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the labels\n",
    "with open('./../tensors/movie-labels.npy', 'wb') as file:\n",
    "    np.save(file,labels_encoded )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load tensors previously saved\n",
    "with open('./../tensors/movie-xids.npy', 'rb') as file:\n",
    "    xids = np.load(file, allow_pickle=True)\n",
    "with open('./../tensors/movie-xmask.npy', 'rb') as file:\n",
    "    xmask = np.load(file, allow_pickle=True)\n",
    "with open('./../tensors/movie-labels.npy', 'rb') as file:\n",
    "    labels = np.load(file, allow_pickle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create TensorFlow Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create TensorFlow Dataset\n",
    "dataset = tf.data.Dataset.from_tensor_slices((xids, xmask, labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<_TakeDataset element_spec=(TensorSpec(shape=(512,), dtype=tf.int64, name=None), TensorSpec(shape=(512,), dtype=tf.int64, name=None), TensorSpec(shape=(5,), dtype=tf.float64, name=None))>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.take(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mapping_function(input_ids, attention_masks, labels):\n",
    "    \"\"\"\n",
    "    Format the input in the right format for TensorFlow Network\n",
    "    Convert our three-item tuple into a two-item tuple where the input item is a dictionary {input_ids, attention_mask}, output\n",
    "    \"\"\"\n",
    "    return {'input_ids': input_ids, 'attention_mask': attention_masks}, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<_TakeDataset element_spec=({'input_ids': TensorSpec(shape=(512,), dtype=tf.int64, name=None), 'attention_mask': TensorSpec(shape=(512,), dtype=tf.int64, name=None)}, TensorSpec(shape=(5,), dtype=tf.float64, name=None))>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Apply the reformat to the whole dataset\n",
    "dataset = dataset.map(mapping_function)\n",
    "\n",
    "dataset.take(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define Shuffle and Batch\n",
    "dataset = dataset.shuffle(10000)\n",
    "dataset = dataset.batch(batch_size=16, drop_remainder=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<_TakeDataset element_spec=({'input_ids': TensorSpec(shape=(16, 512), dtype=tf.int64, name=None), 'attention_mask': TensorSpec(shape=(16, 512), dtype=tf.int64, name=None)}, TensorSpec(shape=(16, 5), dtype=tf.float64, name=None))>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Note the batch size of 16\n",
    "dataset.take(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split in train & test data\n",
    "split_size = int((xids.shape[0] / 16) * 0.9)\n",
    "\n",
    "train_data = dataset.take(split_size)\n",
    "validation_data = dataset.skip(split_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save datasets\n",
    "tf.data.Dataset.save(train_data, './../datasets/movie_rating_train')\n",
    "tf.data.Dataset.save(validation_data, './../datasets/movie_rating_validation')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'input_ids': TensorSpec(shape=(16, 512), dtype=tf.int64, name=None),\n",
       "  'attention_mask': TensorSpec(shape=(16, 512), dtype=tf.int64, name=None)},\n",
       " TensorSpec(shape=(16, 5), dtype=tf.float64, name=None))"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.element_spec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load TensorFlow Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = tf.data.Dataset.load('./../datasets/movie_rating_train')\n",
    "validation_dataset = tf.data.Dataset.load('./../datasets/movie_rating_validation')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Development\n",
    "\n",
    "A TensorFlow version of the BERT model is adopted.\n",
    "\n",
    "In order to use it as a classifier, there is the need to add a couple of Dense layer as head to the top of the BERT architecture, and a couple of input layers to feed the data in input."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the PyTorch model were not used when initializing the TF 2.0 model TFBertModel: ['cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.weight', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.weight']\n",
      "- This IS expected if you are initializing TFBertModel from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFBertModel from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the weights of TFBertModel were initialized from the PyTorch model.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n"
     ]
    }
   ],
   "source": [
    "# Instance model\n",
    "tf_bert_model = TFAutoModel.from_pretrained('bert-base-cased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"tf_bert_model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " bert (TFBertMainLayer)      multiple                  108310272 \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 108310272 (413.17 MB)\n",
      "Trainable params: 108310272 (413.17 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "tf_bert_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the Neural Network Architecture\n",
    "# Define two input layers: one for input_ids and one for attention_masks (NOTE: BERT layer wants tensors and not input layers, that's why tf.keras.Input and not tf.keras.layers.InputLayer)\n",
    "input_ids_input_layer = tf.keras.Input(shape=(512,), # 512 comes from the token size / It does not include batch size\n",
    "                                       name='input_ids',\n",
    "                                       dtype='int32')\n",
    "\n",
    "attention_mask_input_layer = tf.keras.Input(shape=(512,), # 512 comes from the token size\n",
    "                                            name='attention_mask',\n",
    "                                            dtype='int32')\n",
    "\n",
    "# Pass the Output of the input layers to the \"bert\" layer and retrieve the embeddings of the sentences\n",
    "embeddings_layer = tf_bert_model.bert(input_ids_input_layer, attention_mask=attention_mask_input_layer)[1]  # [1] Access the max-pooled activations and not the raw activations\n",
    "\n",
    "# Add Dense layers for classificaiton purposes\n",
    "dense_layer_1 = tf.keras.layers.Dense(1024, activation='relu')(embeddings_layer)\n",
    "output = tf.keras.layers.Dense(5, activation='softmax', name='outputs')(dense_layer_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Construct the model\n",
    "model = tf.keras.Model(inputs=[input_ids_input_layer, attention_mask_input_layer], outputs=output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Freeze the 'bert' layer, so to not train it\n",
    "model.layers[2].trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                Output Shape                 Param #   Connected to                  \n",
      "==================================================================================================\n",
      " input_ids (InputLayer)      [(None, 512)]                0         []                            \n",
      "                                                                                                  \n",
      " attention_mask (InputLayer  [(None, 512)]                0         []                            \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " bert (TFBertMainLayer)      TFBaseModelOutputWithPooli   1083102   ['input_ids[0][0]',           \n",
      "                             ngAndCrossAttentions(last_   72         'attention_mask[0][0]']      \n",
      "                             hidden_state=(None, 512, 7                                           \n",
      "                             68),                                                                 \n",
      "                              pooler_output=(None, 768)                                           \n",
      "                             , past_key_values=None, hi                                           \n",
      "                             dden_states=None, attentio                                           \n",
      "                             ns=None, cross_attentions=                                           \n",
      "                             None)                                                                \n",
      "                                                                                                  \n",
      " dense (Dense)               (None, 1024)                 787456    ['bert[0][1]']                \n",
      "                                                                                                  \n",
      " outputs (Dense)             (None, 5)                    5125      ['dense[0][0]']               \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 109102853 (416.19 MB)\n",
      "Trainable params: 792581 (3.02 MB)\n",
      "Non-trainable params: 108310272 (413.17 MB)\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define training parameters\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=5e-5)\n",
    "loss = tf.keras.losses.CategoricalCrossentropy()\n",
    "accuracy = tf.keras.metrics.CategoricalAccuracy('accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile model\n",
    "model.compile(optimizer=optimizer, loss=loss, metrics=[accuracy])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - 170s 17s/step - loss: 1.7315 - accuracy: 0.1750 - val_loss: 1.6192 - val_accuracy: 0.2250\n",
      "Epoch 2/3\n",
      "10/10 [==============================] - 165s 17s/step - loss: 1.5226 - accuracy: 0.3063 - val_loss: 1.5745 - val_accuracy: 0.3438\n",
      "Epoch 3/3\n",
      "10/10 [==============================] - 170s 18s/step - loss: 1.5427 - accuracy: 0.2937 - val_loss: 1.5419 - val_accuracy: 0.3375\n"
     ]
    }
   ],
   "source": [
    "# Train model\n",
    "# NOTE: Let's reduce the data samples in order to speed it up a little bit\n",
    "history = model.fit(train_dataset.take(1000), \n",
    "                    validation_data=validation_dataset.take(10), \n",
    "                    steps_per_epoch=10,\n",
    "                    epochs=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./../models/movie_ratings_bert_model/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./../models/movie_ratings_bert_model/assets\n"
     ]
    }
   ],
   "source": [
    "# Save model\n",
    "model.save('./../models/movie_ratings_bert_model')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load model\n",
    "model = tf.keras.models.load_model('./../models/movie_ratings_bert_model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instance the tokenizer again (just for not go back in the notebook)\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-cased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_input_data(data):\n",
    "    \"\"\"\n",
    "    Process input data for inference through the BERT model\n",
    "    \"\"\"\n",
    "\n",
    "    # Create tokens\n",
    "    tokens = tokenizer(data,\n",
    "                       max_length=512,\n",
    "                       truncation=True,\n",
    "                       padding='max_length',\n",
    "                       add_special_tokens=True,\n",
    "                       return_tensors='tf')\n",
    "    \n",
    "    # Format input\n",
    "    return {'input_ids': tf.cast(tokens['input_ids'], tf.float64),\n",
    "            'attention_mask': tf.cast(tokens['attention_mask'], tf.float64)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 629ms/step\n"
     ]
    }
   ],
   "source": [
    "probabilities = model.predict(process_input_data('This movie is amazing and incredible and fantastic'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.argmax(probabilities[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cheat_sheets-EiW5VkhA",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
