{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "\n",
    "The notebook is intened to experiment with different technologies for the task of **Question and Answering**.\n",
    "\n",
    "There are two different **type of models**:\n",
    "- *Open Domain* - They do not require a passed context\n",
    "- *Reading Comprehension* - They find the answer within a given context\n",
    "\n",
    "Such models can work in two different **approaches**:\n",
    "- *Open Book* - The model can access external source of information\n",
    "- *Closed Book* - The model can only access what has been encoded in its paramters\n",
    "\n",
    "The **Components** of an Open Domain Q&A are:\n",
    "- *Retriever* - It finds relevant contexts from an external source given the question (This is the component that differentiate an Open Domain from a Reading Comprehension)\n",
    "- *Reader* - It locates the position in the context where the answer to the question is (alternatively there can be a *Generator*)\n",
    "- *Generator*\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SQuAD 2.0\n",
    "\n",
    "The SQuAD (Stanford Question and Answering Dataset) is a hugely popular dataset containing question and answer pairs scraped from Wikipedia, covering topics ranging from Beyonce, to Physics. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
