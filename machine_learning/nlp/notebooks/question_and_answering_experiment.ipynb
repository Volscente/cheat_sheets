{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "\n",
    "The notebook is intened to experiment with different technologies for the task of **Question and Answering**.\n",
    "\n",
    "There are two different **type of models**:\n",
    "- *Open Domain* - They do not require a passed context\n",
    "- *Reading Comprehension* - They find the answer within a given context\n",
    "\n",
    "Such models can work in two different **approaches**:\n",
    "- *Open Book* - The model can access external source of information\n",
    "- *Closed Book* - The model can only access what has been encoded in its paramters\n",
    "\n",
    "The **Components** of an Open Domain Q&A are:\n",
    "- *Retriever* - It finds relevant contexts from an external source given the question (This is the component that differentiate an Open Domain from a Reading Comprehension)\n",
    "- *Reader* - It locates the position in the context where the answer to the question is (alternatively there can be a *Generator*)\n",
    "- *Generator*\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SQuAD 2.0\n",
    "\n",
    "The SQuAD (Stanford Question and Answering Dataset) is a hugely popular dataset containing question and answer pairs scraped from Wikipedia, covering topics ranging from Beyonce, to Physics. \n",
    "\n",
    "It is possible to retrieve both the Training and Dev set at this [link](https://rajpurkar.github.io/SQuAD-explorer/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Standard Libraries\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read data\n",
    "with open('./../../../data/squad_train_v2.0.json', 'rb') as file:\n",
    "    squad_train_data = json.load(file)\n",
    "\n",
    "with open('./../../../data/squad_dev_v2.0.json', 'rb') as file:\n",
    "    squad_dev_data = json.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'qas': [{'question': 'When did Beyonce start becoming popular?',\n",
       "   'id': '56be85543aeaaa14008c9063',\n",
       "   'answers': [{'text': 'in the late 1990s', 'answer_start': 269}],\n",
       "   'is_impossible': False},\n",
       "  {'question': 'What areas did Beyonce compete in when she was growing up?',\n",
       "   'id': '56be85543aeaaa14008c9065',\n",
       "   'answers': [{'text': 'singing and dancing', 'answer_start': 207}],\n",
       "   'is_impossible': False},\n",
       "  {'question': \"When did Beyonce leave Destiny's Child and become a solo singer?\",\n",
       "   'id': '56be85543aeaaa14008c9066',\n",
       "   'answers': [{'text': '2003', 'answer_start': 526}],\n",
       "   'is_impossible': False},\n",
       "  {'question': 'In what city and state did Beyonce  grow up? ',\n",
       "   'id': '56bf6b0f3aeaaa14008c9601',\n",
       "   'answers': [{'text': 'Houston, Texas', 'answer_start': 166}],\n",
       "   'is_impossible': False},\n",
       "  {'question': 'In which decade did Beyonce become famous?',\n",
       "   'id': '56bf6b0f3aeaaa14008c9602',\n",
       "   'answers': [{'text': 'late 1990s', 'answer_start': 276}],\n",
       "   'is_impossible': False},\n",
       "  {'question': 'In what R&B group was she the lead singer?',\n",
       "   'id': '56bf6b0f3aeaaa14008c9603',\n",
       "   'answers': [{'text': \"Destiny's Child\", 'answer_start': 320}],\n",
       "   'is_impossible': False},\n",
       "  {'question': 'What album made her a worldwide known artist?',\n",
       "   'id': '56bf6b0f3aeaaa14008c9604',\n",
       "   'answers': [{'text': 'Dangerously in Love', 'answer_start': 505}],\n",
       "   'is_impossible': False},\n",
       "  {'question': \"Who managed the Destiny's Child group?\",\n",
       "   'id': '56bf6b0f3aeaaa14008c9605',\n",
       "   'answers': [{'text': 'Mathew Knowles', 'answer_start': 360}],\n",
       "   'is_impossible': False},\n",
       "  {'question': 'When did Beyoncé rise to fame?',\n",
       "   'id': '56d43c5f2ccc5a1400d830a9',\n",
       "   'answers': [{'text': 'late 1990s', 'answer_start': 276}],\n",
       "   'is_impossible': False},\n",
       "  {'question': \"What role did Beyoncé have in Destiny's Child?\",\n",
       "   'id': '56d43c5f2ccc5a1400d830aa',\n",
       "   'answers': [{'text': 'lead singer', 'answer_start': 290}],\n",
       "   'is_impossible': False},\n",
       "  {'question': 'What was the first album Beyoncé released as a solo artist?',\n",
       "   'id': '56d43c5f2ccc5a1400d830ab',\n",
       "   'answers': [{'text': 'Dangerously in Love', 'answer_start': 505}],\n",
       "   'is_impossible': False},\n",
       "  {'question': 'When did Beyoncé release Dangerously in Love?',\n",
       "   'id': '56d43c5f2ccc5a1400d830ac',\n",
       "   'answers': [{'text': '2003', 'answer_start': 526}],\n",
       "   'is_impossible': False},\n",
       "  {'question': 'How many Grammy awards did Beyoncé win for her first solo album?',\n",
       "   'id': '56d43c5f2ccc5a1400d830ad',\n",
       "   'answers': [{'text': 'five', 'answer_start': 590}],\n",
       "   'is_impossible': False},\n",
       "  {'question': \"What was Beyoncé's role in Destiny's Child?\",\n",
       "   'id': '56d43ce42ccc5a1400d830b4',\n",
       "   'answers': [{'text': 'lead singer', 'answer_start': 290}],\n",
       "   'is_impossible': False},\n",
       "  {'question': \"What was the name of Beyoncé's first solo album?\",\n",
       "   'id': '56d43ce42ccc5a1400d830b5',\n",
       "   'answers': [{'text': 'Dangerously in Love', 'answer_start': 505}],\n",
       "   'is_impossible': False}],\n",
       " 'context': 'Beyoncé Giselle Knowles-Carter (/biːˈjɒnseɪ/ bee-YON-say) (born September 4, 1981) is an American singer, songwriter, record producer and actress. Born and raised in Houston, Texas, she performed in various singing and dancing competitions as a child, and rose to fame in the late 1990s as lead singer of R&B girl-group Destiny\\'s Child. Managed by her father, Mathew Knowles, the group became one of the world\\'s best-selling girl groups of all time. Their hiatus saw the release of Beyoncé\\'s debut album, Dangerously in Love (2003), which established her as a solo artist worldwide, earned five Grammy Awards and featured the Billboard Hot 100 number-one singles \"Crazy in Love\" and \"Baby Boy\".'}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "squad_train_data['data'][0]['paragraphs'][0] # First data are about Beyonce"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieve all the Q&A pairs\n",
    "q_a_train_data = []\n",
    "\n",
    "# Loop through groups -> paragraphs -> qa_pairs\n",
    "for group in squad_train_data['data']:\n",
    "    for paragraph in group['paragraphs']:\n",
    "\n",
    "        # Retrieve context\n",
    "        context = paragraph['context']\n",
    "\n",
    "        for qa_pair in paragraph['qas']:\n",
    "\n",
    "            # Retrieve question\n",
    "            question = qa_pair['question']\n",
    "\n",
    "            # Check if there is 'answers' or 'plausible_answers'\n",
    "            if 'answers' in qa_pair.keys() and len(qa_pair['answers']) > 0:\n",
    "                answer_list = qa_pair['answers']\n",
    "            elif 'plausible_answers' in qa_pair.keys() and len(qa_pair['plausible_answers']) > 0:\n",
    "                answer_list = qa_pair['plausible_answers']\n",
    "            else:\n",
    "                # Check if no answer is given\n",
    "                answer_list = []\n",
    "\n",
    "            # Retrieve just the text from each answer\n",
    "            answer_list = [item['text'] for item in answer_list]\n",
    "\n",
    "            # Remove duplicates\n",
    "            answer_list = list(set(answer_list))\n",
    "\n",
    "            # Add each answer to the dataset\n",
    "            for answer in answer_list:\n",
    "                # append dictionary sample to parsed squad\n",
    "                q_a_train_data.append({\n",
    "                    'question': question,\n",
    "                    'answer': answer,\n",
    "                    'context': context\n",
    "                })\n",
    "\n",
    "# Retrieve all the Q&A pairs\n",
    "q_a_dev_data = []\n",
    "\n",
    "# Loop through groups -> paragraphs -> qa_pairs\n",
    "for group in squad_dev_data['data']:\n",
    "    for paragraph in group['paragraphs']:\n",
    "\n",
    "        # Retrieve context\n",
    "        context = paragraph['context']\n",
    "\n",
    "        for qa_pair in paragraph['qas']:\n",
    "\n",
    "            # Retrieve question\n",
    "            question = qa_pair['question']\n",
    "\n",
    "            # Check if there is 'answers' or 'plausible_answers'\n",
    "            if 'answers' in qa_pair.keys() and len(qa_pair['answers']) > 0:\n",
    "                answer_list = qa_pair['answers']\n",
    "            elif 'plausible_answers' in qa_pair.keys() and len(qa_pair['plausible_answers']) > 0:\n",
    "                answer_list = qa_pair['plausible_answers']\n",
    "            else:\n",
    "                # Check if no answer is given\n",
    "                answer_list = []\n",
    "\n",
    "            # Retrieve just the text from each answer\n",
    "            answer_list = [item['text'] for item in answer_list]\n",
    "\n",
    "            # Remove duplicates\n",
    "            answer_list = list(set(answer_list))\n",
    "\n",
    "            # Add each answer to the dataset\n",
    "            for answer in answer_list:\n",
    "                # append dictionary sample to parsed squad\n",
    "                q_a_dev_data.append({\n",
    "                    'question': question,\n",
    "                    'answer': answer,\n",
    "                    'context': context\n",
    "                })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'question': 'When did Beyonce start becoming popular?',\n",
       " 'answer': 'in the late 1990s',\n",
       " 'context': 'Beyoncé Giselle Knowles-Carter (/biːˈjɒnseɪ/ bee-YON-say) (born September 4, 1981) is an American singer, songwriter, record producer and actress. Born and raised in Houston, Texas, she performed in various singing and dancing competitions as a child, and rose to fame in the late 1990s as lead singer of R&B girl-group Destiny\\'s Child. Managed by her father, Mathew Knowles, the group became one of the world\\'s best-selling girl groups of all time. Their hiatus saw the release of Beyoncé\\'s debut album, Dangerously in Love (2003), which established her as a solo artist worldwide, earned five Grammy Awards and featured the Billboard Hot 100 number-one singles \"Crazy in Love\" and \"Baby Boy\".'}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q_a_train_data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save data\n",
    "with open('./../../../data/squad_processed_train.json', 'w') as file:\n",
    "    json.dump(q_a_train_data, file)\n",
    "\n",
    "with open('./../../../data/squad_processed_dev.json', 'w') as file:\n",
    "    json.dump(q_a_dev_data, file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BERT Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/s.porreca/.local/share/virtualenvs/cheat_sheets-EiW5VkhA/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "2024-01-03 13:26:23.290758: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "# Import Standard Libraries\n",
    "import json\n",
    "from transformers import BertTokenizer, BertForQuestionAnswering, pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./../../../data/squad_processed_train.json', 'r') as file:\n",
    "    q_a_train_data = json.load(file)\n",
    "\n",
    "with open('./../../../data/squad_processed_dev.json', 'r') as file:\n",
    "    q_a_dev_data = json.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at deepset/bert-base-cased-squad2 were not used when initializing BertForQuestionAnswering: ['bert.pooler.dense.weight', 'bert.pooler.dense.bias']\n",
      "- This IS expected if you are initializing BertForQuestionAnswering from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForQuestionAnswering from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "# Instantiate the tokenizer and the model\n",
    "tokenizer = BertTokenizer.from_pretrained('deepset/bert-base-cased-squad2')\n",
    "model = BertForQuestionAnswering.from_pretrained('deepset/bert-base-cased-squad2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the pipeline\n",
    "qa_pipeline = pipeline('question-answering', model=model, tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieve few answers\n",
    "answers = []\n",
    "\n",
    "for sample in q_a_train_data[:5]:\n",
    "\n",
    "    answer = qa_pipeline({\n",
    "        'question': sample['question'],\n",
    "        'context': sample['context']\n",
    "    })\n",
    "\n",
    "    answers.append({\n",
    "        'True Label': sample['answer'],\n",
    "        'Prediction': answer['answer'],\n",
    "        'Confidence': answer['score']\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'True Label': 'in the late 1990s',\n",
       "  'Prediction': 'late 1990s',\n",
       "  'Confidence': 0.5621357560157776},\n",
       " {'True Label': 'singing and dancing',\n",
       "  'Prediction': 'singing and dancing',\n",
       "  'Confidence': 0.9938411116600037},\n",
       " {'True Label': '2003',\n",
       "  'Prediction': '(2003),',\n",
       "  'Confidence': 0.9965661764144897},\n",
       " {'True Label': 'Houston, Texas',\n",
       "  'Prediction': 'Houston, Texas,',\n",
       "  'Confidence': 0.847782552242279},\n",
       " {'True Label': 'late 1990s',\n",
       "  'Prediction': '1990s',\n",
       "  'Confidence': 0.6779066324234009}]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "answers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exact Match (EM)\n",
    "\n",
    "There are few limitations, since an exact match is quite hard to achieve."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Standard Libraries\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exact matches: 0.6\n"
     ]
    }
   ],
   "source": [
    "# Retrieve the exact matches\n",
    "exact_matches = []\n",
    "\n",
    "for answer in answers:\n",
    "\n",
    "    # Normalise the text\n",
    "    prediction = re.sub('[^0-9a-z ]', '', answer['Prediction'].lower())\n",
    "    true_label = re.sub('[^0-9a-z ]', '', answer['True Label'].lower())\n",
    "\n",
    "    if prediction == true_label:\n",
    "\n",
    "        exact_matches.append(1)\n",
    "\n",
    "    else:\n",
    "\n",
    "        exact_matches.append(0)\n",
    "\n",
    "print(f'Exact matches: {sum(exact_matches)/len(exact_matches)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Recall Oriented Understudy for Gisting Evaluation (ROUGE)\n",
    "\n",
    "It is a set of metrics and each of them measure how similar a reference text is to the predicted text:\n",
    "- **ROUEE N** - It measures the number of matching N-Grams (group of tokens) between the reference and predicted text\n",
    "    ```python\n",
    "    # Reference text\n",
    "    reference_text = 'The quick brown fox jumps over the lazy dog'\n",
    "\n",
    "    example_1_gram = ['The', 'quick', ...]\n",
    "    example_2_gram = ['The quick', 'quick brown', ...]\n",
    "    ```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Theory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importa Standard Libraries\n",
    "from rouge import Rouge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define example predicted output and reference\n",
    "model_output = 'hello to the world'\n",
    "reference_output = 'hello world'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instance the Rogue object\n",
    "rouge_instance = Rouge()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'rouge-1': {'r': 1.0, 'p': 0.5, 'f': 0.6666666622222223},\n",
       "  'rouge-2': {'r': 0.0, 'p': 0.0, 'f': 0.0},\n",
       "  'rouge-l': {'r': 1.0, 'p': 0.5, 'f': 0.6666666622222223}}]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get the N-Gram scores\n",
    "rouge_instance.get_scores(model_output, reference_output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is Rouge-1 (one-Gram) and Rouge-2 (bi-gram) with F1, Precision and Recall metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieve full data for ROUGE\n",
    "model_predictions = [answer['Prediction'] for answer in answers]\n",
    "references = [answer['True Label'] for answer in answers]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'rouge-1': {'r': 0.5, 'p': 1.0, 'f': 0.6666666622222223},\n",
       "  'rouge-2': {'r': 0.3333333333333333, 'p': 1.0, 'f': 0.4999999962500001},\n",
       "  'rouge-l': {'r': 0.5, 'p': 1.0, 'f': 0.6666666622222223}},\n",
       " {'rouge-1': {'r': 1.0, 'p': 1.0, 'f': 0.999999995},\n",
       "  'rouge-2': {'r': 1.0, 'p': 1.0, 'f': 0.999999995},\n",
       "  'rouge-l': {'r': 1.0, 'p': 1.0, 'f': 0.999999995}},\n",
       " {'rouge-1': {'r': 0.0, 'p': 0.0, 'f': 0.0},\n",
       "  'rouge-2': {'r': 0.0, 'p': 0.0, 'f': 0.0},\n",
       "  'rouge-l': {'r': 0.0, 'p': 0.0, 'f': 0.0}},\n",
       " {'rouge-1': {'r': 0.5, 'p': 0.5, 'f': 0.4999999950000001},\n",
       "  'rouge-2': {'r': 0.0, 'p': 0.0, 'f': 0.0},\n",
       "  'rouge-l': {'r': 0.5, 'p': 0.5, 'f': 0.4999999950000001}},\n",
       " {'rouge-1': {'r': 0.5, 'p': 1.0, 'f': 0.6666666622222223},\n",
       "  'rouge-2': {'r': 0.0, 'p': 0.0, 'f': 0.0},\n",
       "  'rouge-l': {'r': 0.5, 'p': 1.0, 'f': 0.6666666622222223}}]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rouge_instance.get_scores(model_predictions, references)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Application"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importa Standard Libraries\n",
    "from rouge import Rouge\n",
    "from tqdm import tqdm\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize empty model outputs and references\n",
    "model_outputs, references = [], []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:43<00:00,  8.73s/it]\n"
     ]
    }
   ],
   "source": [
    "# Fetch the samples in the training data\n",
    "for sample in tqdm(q_a_train_data[:5], leave=True):\n",
    "\n",
    "    # Pass the question through the Q&A Pipeline\n",
    "    answer = qa_pipeline({\n",
    "        'question': sample['question'],\n",
    "        'context': sample['context']\n",
    "    })\n",
    "\n",
    "    # Append results\n",
    "    model_outputs.append(answer['answer'])\n",
    "    references.append(sample['answer'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'rouge-1': {'r': 0.5, 'p': 0.6875, 'f': 0.5624999964583334},\n",
       " 'rouge-2': {'r': 0.3333333333333333, 'p': 0.5, 'f': 0.37499999781250004},\n",
       " 'rouge-l': {'r': 0.5, 'p': 0.6875, 'f': 0.5624999964583334}}"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Initialize\n",
    "rouge_instance = Rouge()\n",
    "\n",
    "# Get scores\n",
    "rouge_instance.get_scores(model_outputs, references, avg=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "singing and dancing  |  singing and dancing  |  0.999999995\n",
      "(2003),  |  2003  |  0.0\n"
     ]
    }
   ],
   "source": [
    "# Retrieve score\n",
    "scores = rouge_instance.get_scores(model_outputs, references)\n",
    "\n",
    "# Manually check some of them\n",
    "print(model_outputs[1], ' | ', references[1], ' | ', scores[1]['rouge-1']['f'])\n",
    "print(model_outputs[2], ' | ', references[2], ' | ', scores[2]['rouge-1']['f'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use regex\n",
    "clean = re.compile('(?i)[^0-9a-z ]')\n",
    "\n",
    "# Apply this to both lists\n",
    "model_outputs = [clean.sub('', text) for text in model_outputs]\n",
    "references = [clean.sub('', text) for text in references]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "singing and dancing  |  singing and dancing  |  0.999999995\n",
      "2003  |  2003  |  0.999999995\n"
     ]
    }
   ],
   "source": [
    "# Retrieve score\n",
    "scores = rouge_instance.get_scores(model_outputs, references)\n",
    "\n",
    "# Manually check some of them\n",
    "print(model_outputs[1], ' | ', references[1], ' | ', scores[1]['rouge-1']['f'])\n",
    "print(model_outputs[2], ' | ', references[2], ' | ', scores[2]['rouge-1']['f'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'rouge-1': {'r': 0.8125, 'p': 1.0, 'f': 0.8749999952083333},\n",
       " 'rouge-2': {'r': 0.4583333333333333, 'p': 0.625, 'f': 0.49999999718750004},\n",
       " 'rouge-l': {'r': 0.8125, 'p': 1.0, 'f': 0.8749999952083333}}"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get scores\n",
    "rouge_instance.get_scores(model_outputs, references, avg=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model improves its performance by applying a regex."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ROUGE-L\n",
    "\n",
    "It measures the *Longest Common Subsequence* (LCS) between the model's outputs and the references.\n",
    "\n",
    "Given the model output (*The hello a cat daog fox jumps*), the reference (*the fox jumps*) and the 1-Gram &rarr; Precision = 2/7 = 29%"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Retriever-Reader\n",
    "\n",
    "So far, a Reader component of a Q&A system has been implemented, whichi leads to the implementation of a Reading Comprehension system: given the question and a context, find the answer. In most cases, we want to just give the question and the model, given an external source or its own memory (gained during the training), will find the correct answer. This is a *Retriever-Reader* Architecture."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Haystack\n",
    "\n",
    "We are going to use a library called `Haystack` in order to implement a Retriever-Reader system with two different approaches:\n",
    "- Elasticsearch\n",
    "- FAISS (Facebook AI Similarity Search)\n",
    "\n",
    "<br>\n",
    "\n",
    "**Docker Elasticsearch Command:** docker run --name es01 --net elastic -p 9200:9200 -it -m 1GB -e \"discovery.type=single-node\" -e \"ES_JAVA_OPTS=-Xms512m -Xmx512m\" --ulimit memlock=-1:-1 --ulimit nofile=65536:65536 docker.elastic.co/elasticsearch/elasticsearch:8.11.4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Elasticsearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Standard Libraries\n",
    "import json\n",
    "from elasticsearch_haystack.document_store import ElasticsearchDocumentStore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read data\n",
    "with open('./../../../data/squad_dev_v2.0.json', 'r') as file:\n",
    "\n",
    "    squad_dev_data = json.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "TlsError",
     "evalue": "TLS error caused by: TlsError(TLS error caused by: SSLError([SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: self signed certificate in certificate chain (_ssl.c:997)))",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTlsError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[15], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Initialise document store\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m document_store \u001b[38;5;241m=\u001b[39m \u001b[43mElasticsearchDocumentStore\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhosts\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mhttps://localhost:9200\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/share/virtualenvs/cheat_sheets-EiW5VkhA/lib/python3.10/site-packages/elasticsearch_haystack/document_store.py:67\u001b[0m, in \u001b[0;36mElasticsearchDocumentStore.__init__\u001b[0;34m(self, hosts, index, embedding_similarity_function, **kwargs)\u001b[0m\n\u001b[1;32m     64\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_kwargs \u001b[38;5;241m=\u001b[39m kwargs\n\u001b[1;32m     66\u001b[0m \u001b[38;5;66;03m# Check client connection, this will raise if not connected\u001b[39;00m\n\u001b[0;32m---> 67\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_client\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minfo\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     69\u001b[0m \u001b[38;5;66;03m# configure mapping for the embedding field\u001b[39;00m\n\u001b[1;32m     70\u001b[0m mappings \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m     71\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mproperties\u001b[39m\u001b[38;5;124m\"\u001b[39m: {\n\u001b[1;32m     72\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124membedding\u001b[39m\u001b[38;5;124m\"\u001b[39m: {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtype\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdense_vector\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mindex\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28;01mTrue\u001b[39;00m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msimilarity\u001b[39m\u001b[38;5;124m\"\u001b[39m: embedding_similarity_function}\n\u001b[1;32m     73\u001b[0m     }\n\u001b[1;32m     74\u001b[0m }\n",
      "File \u001b[0;32m~/.local/share/virtualenvs/cheat_sheets-EiW5VkhA/lib/python3.10/site-packages/elasticsearch/_sync/client/utils.py:402\u001b[0m, in \u001b[0;36m_rewrite_parameters.<locals>.wrapper.<locals>.wrapped\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    399\u001b[0m         \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m:\n\u001b[1;32m    400\u001b[0m             \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[0;32m--> 402\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mapi\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/share/virtualenvs/cheat_sheets-EiW5VkhA/lib/python3.10/site-packages/elasticsearch/_sync/client/__init__.py:2278\u001b[0m, in \u001b[0;36mElasticsearch.info\u001b[0;34m(self, error_trace, filter_path, human, pretty)\u001b[0m\n\u001b[1;32m   2276\u001b[0m     __query[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpretty\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m pretty\n\u001b[1;32m   2277\u001b[0m __headers \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124maccept\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mapplication/json\u001b[39m\u001b[38;5;124m\"\u001b[39m}\n\u001b[0;32m-> 2278\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mperform_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# type: ignore[return-value]\u001b[39;49;00m\n\u001b[1;32m   2279\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mGET\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m__path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparams\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m__query\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m__headers\u001b[49m\n\u001b[1;32m   2280\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/share/virtualenvs/cheat_sheets-EiW5VkhA/lib/python3.10/site-packages/elasticsearch/_sync/client/_base.py:285\u001b[0m, in \u001b[0;36mBaseClient.perform_request\u001b[0;34m(self, method, path, params, headers, body)\u001b[0m\n\u001b[1;32m    282\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    283\u001b[0m     target \u001b[38;5;241m=\u001b[39m path\n\u001b[0;32m--> 285\u001b[0m meta, resp_body \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtransport\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mperform_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    286\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    287\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    288\u001b[0m \u001b[43m    \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest_headers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    289\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbody\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    290\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrequest_timeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_request_timeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    291\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmax_retries\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_max_retries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    292\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretry_on_status\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_retry_on_status\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    293\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretry_on_timeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_retry_on_timeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    294\u001b[0m \u001b[43m    \u001b[49m\u001b[43mclient_meta\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_client_meta\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    295\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    297\u001b[0m \u001b[38;5;66;03m# HEAD with a 404 is returned as a normal response\u001b[39;00m\n\u001b[1;32m    298\u001b[0m \u001b[38;5;66;03m# since this is used as an 'exists' functionality.\u001b[39;00m\n\u001b[1;32m    299\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (method \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mHEAD\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m meta\u001b[38;5;241m.\u001b[39mstatus \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m404\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m (\n\u001b[1;32m    300\u001b[0m     \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;241m200\u001b[39m \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m meta\u001b[38;5;241m.\u001b[39mstatus \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m299\u001b[39m\n\u001b[1;32m    301\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m (\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    305\u001b[0m     )\n\u001b[1;32m    306\u001b[0m ):\n",
      "File \u001b[0;32m~/.local/share/virtualenvs/cheat_sheets-EiW5VkhA/lib/python3.10/site-packages/elastic_transport/_transport.py:328\u001b[0m, in \u001b[0;36mTransport.perform_request\u001b[0;34m(self, method, target, body, headers, max_retries, retry_on_status, retry_on_timeout, request_timeout, client_meta)\u001b[0m\n\u001b[1;32m    326\u001b[0m start_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[1;32m    327\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 328\u001b[0m     meta, raw_data \u001b[38;5;241m=\u001b[39m \u001b[43mnode\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mperform_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    329\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    330\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    331\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbody\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest_body\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    332\u001b[0m \u001b[43m        \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest_headers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    333\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrequest_timeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest_timeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    334\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    335\u001b[0m     _logger\u001b[38;5;241m.\u001b[39minfo(\n\u001b[1;32m    336\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m [status:\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m duration:\u001b[39m\u001b[38;5;132;01m%.3f\u001b[39;00m\u001b[38;5;124ms]\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    337\u001b[0m         \u001b[38;5;241m%\u001b[39m (\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    343\u001b[0m         )\n\u001b[1;32m    344\u001b[0m     )\n\u001b[1;32m    346\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m method \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mHEAD\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n",
      "File \u001b[0;32m~/.local/share/virtualenvs/cheat_sheets-EiW5VkhA/lib/python3.10/site-packages/elastic_transport/_node/_http_urllib3.py:202\u001b[0m, in \u001b[0;36mUrllib3HttpNode.perform_request\u001b[0;34m(self, method, target, body, headers, request_timeout)\u001b[0m\n\u001b[1;32m    194\u001b[0m         err \u001b[38;5;241m=\u001b[39m \u001b[38;5;167;01mConnectionError\u001b[39;00m(\u001b[38;5;28mstr\u001b[39m(e), errors\u001b[38;5;241m=\u001b[39m(e,))\n\u001b[1;32m    195\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_log_request(\n\u001b[1;32m    196\u001b[0m         method\u001b[38;5;241m=\u001b[39mmethod,\n\u001b[1;32m    197\u001b[0m         target\u001b[38;5;241m=\u001b[39mtarget,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    200\u001b[0m         exception\u001b[38;5;241m=\u001b[39merr,\n\u001b[1;32m    201\u001b[0m     )\n\u001b[0;32m--> 202\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m err \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    204\u001b[0m meta \u001b[38;5;241m=\u001b[39m ApiResponseMeta(\n\u001b[1;32m    205\u001b[0m     node\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig,\n\u001b[1;32m    206\u001b[0m     duration\u001b[38;5;241m=\u001b[39mduration,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    209\u001b[0m     headers\u001b[38;5;241m=\u001b[39mresponse_headers,\n\u001b[1;32m    210\u001b[0m )\n\u001b[1;32m    211\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_log_request(\n\u001b[1;32m    212\u001b[0m     method\u001b[38;5;241m=\u001b[39mmethod,\n\u001b[1;32m    213\u001b[0m     target\u001b[38;5;241m=\u001b[39mtarget,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    217\u001b[0m     response\u001b[38;5;241m=\u001b[39mdata,\n\u001b[1;32m    218\u001b[0m )\n",
      "\u001b[0;31mTlsError\u001b[0m: TLS error caused by: TlsError(TLS error caused by: SSLError([SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: self signed certificate in certificate chain (_ssl.c:997)))"
     ]
    }
   ],
   "source": [
    "# Initialise document store\n",
    "document_store = ElasticsearchDocumentStore(hosts=\"https://localhost:9200\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### FAISS\n",
    "\n",
    "An inherit drawback of the Nearest Neighbours algorithm, which check the distance between vectors, is that it becomes quite soon very slow when increasing the number of dimensions. With FAISS, we have:\n",
    "- Faster GPU implementation with parallel processing\n",
    "- Vectors are prepocessed with PCA and L2 normalization, to reduce the dimensionality\n",
    "- It uses the *Inverted File Indexing* (IVF), which group similar vectors into clusters and thus speeding up the query similarity with the clusters instead with each vector"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cheat_sheets-EiW5VkhA",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
