{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "\n",
    "This notebook is intended to experiment with Sentence Similarity techniques."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/s.porreca/.local/share/virtualenvs/cheat_sheets-EiW5VkhA/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "# Import Standard Libraries\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define model\n",
    "model_name = 'sentence-transformers/bert-base-nli-mean-tokens'\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModel.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define text input\n",
    "text = 'hello world what a time to be alive!'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenize the sentence\n",
    "tokens = tokenizer.encode_plus(text, \n",
    "                               max_length=128, \n",
    "                               truncation=True, \n",
    "                               padding='max_length', \n",
    "                               return_tensors='pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 128])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We have 128 tokens\n",
    "tokens.attention_mask.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feed tokens\n",
    "outputs = model(**tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieve the embeddings of the sentence by taking the last layer output\n",
    "embeddings = outputs.last_hidden_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 128, 768])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We have 128 tokens with 768 values each\n",
    "embeddings.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "768 values &rarr; most zeroes &rarr; sparse vectors\n",
    "\n",
    "Let's convert them to dense vectors through a max pooling.\n",
    "\n",
    "First of all, we need to multiply the sentence embeddings for their respective attention mask, in order to retrieve only the \"real\" important tokens and exclude the zero tokens."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieve attention mask\n",
    "attention_mask = tokens.attention_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 128, 1])\n",
      "torch.Size([1, 128, 768])\n"
     ]
    }
   ],
   "source": [
    "# Convert the attention_mask shape to match the embeddings one\n",
    "print(attention_mask.unsqueeze(-1).shape)\n",
    "print(attention_mask.unsqueeze(-1).expand(embeddings.shape).shape)\n",
    "\n",
    "mask = attention_mask.unsqueeze(-1).expand(embeddings.shape).float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute the embeddings mask, in order to retrieve only important tokens\n",
    "masked_embeddings = embeddings * mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 128, 768])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "masked_embeddings.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 3.0681e-01, -7.8806e-02,  1.7431e+00,  ..., -2.5348e-02,\n",
       "          -1.1080e-01,  4.8310e-02],\n",
       "         [ 7.1301e-01,  1.0437e-01,  1.8346e+00,  ...,  1.1344e-01,\n",
       "          -7.5563e-02,  1.2667e-01],\n",
       "         [ 8.1722e-01,  1.1321e-01,  1.5408e+00,  ..., -3.8067e-01,\n",
       "           8.7479e-02, -1.9020e-01],\n",
       "         ...,\n",
       "         [ 5.4669e-01,  1.7181e-01,  1.1392e+00,  ...,  3.8548e-02,\n",
       "          -1.5396e-01,  2.3015e-01],\n",
       "         [ 3.4457e-01,  1.3151e-01,  1.1324e+00,  ..., -1.4203e-03,\n",
       "          -1.7517e-01,  1.5220e-01],\n",
       "         [ 3.2320e-01,  3.3353e-03,  1.1888e+00,  ...,  1.6736e-02,\n",
       "          -2.0863e-01,  8.9315e-02]]], grad_fn=<NativeLayerNormBackward0>)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0.3068, -0.0788,  1.7431,  ..., -0.0253, -0.1108,  0.0483],\n",
       "         [ 0.7130,  0.1044,  1.8346,  ...,  0.1134, -0.0756,  0.1267],\n",
       "         [ 0.8172,  0.1132,  1.5408,  ..., -0.3807,  0.0875, -0.1902],\n",
       "         ...,\n",
       "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000, -0.0000,  0.0000],\n",
       "         [ 0.0000,  0.0000,  0.0000,  ..., -0.0000, -0.0000,  0.0000],\n",
       "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000, -0.0000,  0.0000]]],\n",
       "       grad_fn=<MulBackward0>)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "masked_embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we compare values in `embeddings` and `masked_embeddings`, we can see that now some vectors have zeros instead of values. This is due to the application of the mask, which filters out non-important tokens.\n",
    "\n",
    "<br>\n",
    "\n",
    "Now we need to compute the max pooling, in order to transform the sparse `masked_embeddings` vectors into dense vectors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summed shape: torch.Size([1, 768])\n",
      "Counts shape: torch.Size([1, 768])\n"
     ]
    }
   ],
   "source": [
    "# Compute the sum of all vecotrs dimension\n",
    "summed = torch.sum(masked_embeddings, 1)\n",
    "print(f'Summed shape: {summed.shape}')\n",
    "\n",
    "# Count the 1 values in the mask (there are either 1 or 0) and a small value of avoid divide-by-zero\n",
    "counts = torch.clamp(mask.sum(1), min=1e-9)\n",
    "print(f'Counts shape: {counts.shape}')\n",
    "\n",
    "# Compute the mean\n",
    "mean_pooled = summed / counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 768])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# This is our dense sentence vector\n",
    "mean_pooled.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cheat_sheets-EiW5VkhA",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
