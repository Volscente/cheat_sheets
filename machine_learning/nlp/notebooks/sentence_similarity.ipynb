{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "\n",
    "This notebook is intended to experiment with Sentence Similarity techniques."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Standard Libraries\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "import torch\n",
    "from sklearn.metrics.pairwise import cosine_similarity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define model\n",
    "model_name = 'sentence-transformers/bert-base-nli-mean-tokens'\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModel.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define text input\n",
    "text = 'hello world what a time to be alive!'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenize the sentence\n",
    "tokens = tokenizer.encode_plus(text, \n",
    "                               max_length=128, \n",
    "                               truncation=True, \n",
    "                               padding='max_length', \n",
    "                               return_tensors='pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 128])"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We have 128 tokens\n",
    "tokens.attention_mask.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feed tokens\n",
    "outputs = model(**tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieve the embeddings of the sentence by taking the last layer output\n",
    "embeddings = outputs.last_hidden_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 128, 768])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We have 128 tokens with 768 values each\n",
    "embeddings.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "768 values &rarr; most zeroes &rarr; sparse vectors\n",
    "\n",
    "Let's convert them to dense vectors through a max pooling.\n",
    "\n",
    "First of all, we need to multiply the sentence embeddings for their respective attention mask, in order to retrieve only the \"real\" important tokens and exclude the zero tokens."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieve attention mask\n",
    "attention_mask = tokens.attention_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 128, 1])\n",
      "torch.Size([1, 128, 768])\n"
     ]
    }
   ],
   "source": [
    "# Convert the attention_mask shape to match the embeddings one\n",
    "print(attention_mask.unsqueeze(-1).shape)\n",
    "print(attention_mask.unsqueeze(-1).expand(embeddings.shape).shape)\n",
    "\n",
    "mask = attention_mask.unsqueeze(-1).expand(embeddings.shape).float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute the embeddings mask, in order to retrieve only important tokens\n",
    "masked_embeddings = embeddings * mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 128, 768])"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "masked_embeddings.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 3.0681e-01, -7.8806e-02,  1.7431e+00,  ..., -2.5348e-02,\n",
       "          -1.1080e-01,  4.8310e-02],\n",
       "         [ 7.1301e-01,  1.0437e-01,  1.8346e+00,  ...,  1.1344e-01,\n",
       "          -7.5563e-02,  1.2667e-01],\n",
       "         [ 8.1722e-01,  1.1321e-01,  1.5408e+00,  ..., -3.8067e-01,\n",
       "           8.7479e-02, -1.9020e-01],\n",
       "         ...,\n",
       "         [ 5.4669e-01,  1.7181e-01,  1.1392e+00,  ...,  3.8548e-02,\n",
       "          -1.5396e-01,  2.3015e-01],\n",
       "         [ 3.4457e-01,  1.3151e-01,  1.1324e+00,  ..., -1.4203e-03,\n",
       "          -1.7517e-01,  1.5220e-01],\n",
       "         [ 3.2320e-01,  3.3353e-03,  1.1888e+00,  ...,  1.6736e-02,\n",
       "          -2.0863e-01,  8.9315e-02]]], grad_fn=<NativeLayerNormBackward0>)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0.3068, -0.0788,  1.7431,  ..., -0.0253, -0.1108,  0.0483],\n",
       "         [ 0.7130,  0.1044,  1.8346,  ...,  0.1134, -0.0756,  0.1267],\n",
       "         [ 0.8172,  0.1132,  1.5408,  ..., -0.3807,  0.0875, -0.1902],\n",
       "         ...,\n",
       "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000, -0.0000,  0.0000],\n",
       "         [ 0.0000,  0.0000,  0.0000,  ..., -0.0000, -0.0000,  0.0000],\n",
       "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000, -0.0000,  0.0000]]],\n",
       "       grad_fn=<MulBackward0>)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "masked_embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we compare values in `embeddings` and `masked_embeddings`, we can see that now some vectors have zeros instead of values. This is due to the application of the mask, which filters out non-important tokens.\n",
    "\n",
    "<br>\n",
    "\n",
    "Now we need to compute the max pooling, in order to transform the sparse `masked_embeddings` vectors into dense vectors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summed shape: torch.Size([1, 768])\n",
      "Counts shape: torch.Size([1, 768])\n"
     ]
    }
   ],
   "source": [
    "# Compute the sum of all vecotrs dimension\n",
    "summed = torch.sum(masked_embeddings, 1)\n",
    "print(f'Summed shape: {summed.shape}')\n",
    "\n",
    "# Count the 1 values in the mask (there are either 1 or 0) and a small value of avoid divide-by-zero\n",
    "counts = torch.clamp(mask.sum(1), min=1e-9)\n",
    "print(f'Counts shape: {counts.shape}')\n",
    "\n",
    "# Compute the mean\n",
    "mean_pooled = summed / counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 768])"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# This is our dense sentence vector\n",
    "mean_pooled.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's add some sentences\n",
    "sentences = [\n",
    "    \"Three years later, the coffin was still full of Jello.\",\n",
    "    \"The fish dreamed of escaping the fishbowl and into the toilet where he saw his riends.\",\n",
    "    \"The person box was packed with jelly many dozens of months later.\",\n",
    "    \"Standing on one's head at job interviews forms a lasting impression.\",\n",
    "    \"It took him a month to finish the meal.\",\n",
    "    \"He found a leprechaun in his walnut sheel.\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initilaize dictionary for tokenized sentences\n",
    "tokens = {\n",
    "    'input_ids': [],\n",
    "    'attention_mask': []\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenize each sentence\n",
    "for sentence in sentences:\n",
    "\n",
    "    # Tokenize the sentence\n",
    "    new_tokens = tokenizer.encode_plus(sentence, \n",
    "                                       max_length=128, \n",
    "                                       truncation=True, \n",
    "                                       padding='max_length', \n",
    "                                       return_tensors='pt')\n",
    "    \n",
    "    # Append tokens\n",
    "    tokens['input_ids'].append(new_tokens['input_ids'][0])\n",
    "    tokens['attention_mask'].append(new_tokens['attention_mask'][0])    \n",
    "\n",
    "# Cast the list into a single tensor\n",
    "tokens['input_ids'] = torch.stack(tokens['input_ids'])\n",
    "tokens['attention_mask'] = torch.stack(tokens['attention_mask'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([6, 128])"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens['input_ids'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute sentences embeddings\n",
    "outputs = model(**tokens)\n",
    "embeddings = outputs.last_hidden_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute mask\n",
    "mask = tokens['attention_mask'].unsqueeze(-1).expand(embeddings.size()).float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieve embeddings masked\n",
    "masked_embeddings = embeddings * mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute dense vectors for sentence embeddings\n",
    "summed = torch.sum(masked_embeddings, 1)\n",
    "counts = torch.clamp(mask.sum(1), min=1e-9)\n",
    "mean_pooled = summed / counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.32754934, 0.72192574, 0.1747549 , 0.44709635, 0.54106987]],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Detach tensors from PyTorch\n",
    "mean_pooled = mean_pooled.detach().numpy()\n",
    "\n",
    "cosine_similarity(\n",
    "    [mean_pooled[0]],\n",
    "    mean_pooled[1:]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ref: \"Three years later, the coffin was still full of Jello.\",\n",
    "- 0: \"The fish dreamed of escaping the fishbowl and into the toilet where he saw his riends.\",\n",
    "- 1: \"The person box was packed with jelly many dozens of months later.\",\n",
    "- 2: \"Standing on one's head at job interviews forms a lasting impression.\",\n",
    "- 3: \"It took him a month to finish the meal.\",\n",
    "- 4: \"He found a leprechaun in his walnut sheel.\"\n",
    "\n",
    "<br>\n",
    "\n",
    "The reference sentence has the highest similarity with the sentence number 1, has we expected! They use almost the same words and have the same meaning."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cheat_sheets-EiW5VkhA",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
