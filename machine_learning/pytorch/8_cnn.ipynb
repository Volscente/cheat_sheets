{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bdda28d4-89ff-46b1-8e04-e0a4f019b98d",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "\n",
    "The notebook is intended to experiment with Convolutional Neural Network in PyTorch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d64a7af1-6c78-4eb4-8ca7-60eaca077446",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/s.porreca/.local/share/virtualenvs/cheat_sheets-EiW5VkhA/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "# Import Standard Libraries\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.datasets as datasets\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0934eba2-4449-4a73-aec2-a1ae7d4dbf9f",
   "metadata": {},
   "source": [
    "# Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a40cf337-80a9-4d12-ac4b-341fe7021c5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the mean and std of the MNIST dataset for the data normalisation\n",
    "# NOTE: We are not going to compute them\n",
    "mean = 0.1307\n",
    "std = 0.3081"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b13aef16-73c3-4e50-a816-3d55e2154e23",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the a set of data transformation through the function \"compose\"\n",
    "data_transformations = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((mean,), (std,))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ff45eb77-18ad-4e85-94a9-9c1584217f25",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the MNIST dataset\n",
    "train_data = datasets.MNIST(root='./../../data', \n",
    "                            train=True, \n",
    "                            transform=data_transformations, \n",
    "                            download=True)\n",
    "\n",
    "test_data = datasets.MNIST(root='./../../data',\n",
    "                           train=False,\n",
    "                           transform=data_transformations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2009860d-d641-4b44-b826-18d24b781bb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a DataLoader for batch training & testing\n",
    "train_data_loader = torch.utils.data.DataLoader(train_data, \n",
    "                                                batch_size=100, \n",
    "                                                shuffle=True)\n",
    "\n",
    "test_data_loader = torch.utils.data.DataLoader(test_data, \n",
    "                                               batch_size=100, \n",
    "                                               shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "646a7ae0-a6ef-4d3a-85ed-ddeee0a7b6a5",
   "metadata": {},
   "source": [
    "# Plot Sample Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bc49ebf6-c775-4033-9f7e-fb41b19422f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieve an image and normalise it\n",
    "image = train_data[20][0].numpy() * mean * std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "086ba894-ab1e-4410-8332-959d7352fb7b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Show the image\n",
    "# NOTE: It needs to be reshaped to N x N dimension from a 3-Channel\n",
    "_ = plt.imshow(image.reshape(28, 28),\n",
    "               cmap='gray') # Define image gray color"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f27b0dcf-cbc6-4964-b612-513e594bf3c6",
   "metadata": {},
   "source": [
    "# Model Definition"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2734df46-f4fb-4c8d-a013-0226b1889b9a",
   "metadata": {},
   "source": [
    "## Define the Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f78d6c46-af11-4f15-890d-8f332865a173",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(nn.Module):\n",
    "    \n",
    "    \"\"\"\n",
    "    Initialise a Convolutional Neural Network\n",
    "\n",
    "    Attributes:\n",
    "        conv2d_1 nn.Conv2d Convolutional 2-D Layer 1 \n",
    "\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, \n",
    "                 conv2d_1_attributes: dict, \n",
    "                 batch_normalisation_1_attributes: dict, \n",
    "                 max_pooling_1_attributes: dict, \n",
    "                 conv2d_2_attributes: dict, \n",
    "                 batch_normalisation_2_attributes: dict, \n",
    "                 max_pooling_2_attributes: dict):\n",
    "    \n",
    "        \"\"\"\n",
    "        Initialise the Neural Network\n",
    "\n",
    "        Args:\n",
    "            conv2d_1_attributes Dictionary of conv2d_1 attributes\n",
    "            batch_normalisation_1_attributes Dictionary of batch_normalisation_1 attributes\n",
    "            max_pooling_1_attributes Dictionary of max_pooling_1 attributes\n",
    "            conv2d_2_attributes Dictionary of conv2d_1 attributes\n",
    "            batch_normalisation_2_attributes Dictionary of batch_normalisation_2 attributes\n",
    "            max_pooling_2_attributes Dictionary of max_pooling_2 attributes\n",
    "\n",
    "        \"\"\"\n",
    "\n",
    "        # Call the nn.Module constructor\n",
    "        super(Model, self).__init__()\n",
    "\n",
    "        # Define the first Convolutional layer\n",
    "        self.conv2d_1 = nn.Conv2d(in_channels=conv2d_1_attributes['input_channels'], \n",
    "                                  out_channels=conv2d_1_attributes['output_channels'], \n",
    "                                  kernel_size=conv2d_1_attributes['kernel_size'], \n",
    "                                  stride=conv2d_1_attributes['stride'], \n",
    "                                  padding=conv2d_1_attributes['padding'])\n",
    "        \n",
    "        # Define the Batch Normalisation layer for conv2d_1\n",
    "        self.batch_normalisation_1 = nn.BatchNorm2d(batch_normalisation_1_attributes['feature_map_dim'])\n",
    "        \n",
    "        # Specify conv2d_1 activation function\n",
    "        self.activation_function_1 = nn.ReLU()\n",
    "                 \n",
    "        # Max Pooling for conv2d_1\n",
    "        # Note: the final dimension of the feature map after the max_pooling_1 would be\n",
    "        # [(input_size - kernel_size + 2*padding/stride + 1]\n",
    "        # 28 - 3 + 2*1/1 + 1 = 28\n",
    "        # After the MaxPooling: Feature Map Size / Max Pooling Kernel = 28/2 = 14\n",
    "        self.max_pooling_1 = nn.MaxPool2d(max_pooling_1_attributes['kernel_size'])\n",
    "        \n",
    "        # Define the second Convolutional layer\n",
    "        self.conv2d_2 = nn.Conv2d(in_channels=conv2d_2_attributes['input_channels'], \n",
    "                                  out_channels=conv2d_2_attributes['output_channels'], \n",
    "                                  kernel_size=conv2d_2_attributes['kernel_size'], \n",
    "                                  stride=conv2d_2_attributes['stride'], \n",
    "                                  padding=conv2d_2_attributes['padding'])\n",
    "        \n",
    "        # Define the Batch Normalisation layer for conv2d_2\n",
    "        self.batch_normalisation_2 = nn.BatchNorm2d(batch_normalisation_2_attributes['feature_map_dim'])\n",
    "        \n",
    "        # Specify conv2d_2 activation function\n",
    "        self.activation_function_2 = nn.ReLU()\n",
    "        \n",
    "        # Max Pooling for conv2d_2\n",
    "        # Output size: 14 - 5 + 2*2/1 + 1 = 14\n",
    "        # After Max Pooling: 14/2 = 7\n",
    "        self.max_pooling_2 = nn.MaxPool2d(max_pooling_2_attributes['kernel_size'])\n",
    "        \n",
    "        # Define first fully-connected layer\n",
    "        # NOTE: The number of neurons is 32x7x7 = 1568\n",
    "        # NOTE2: 600 is the arbitrary chosen output dimension\n",
    "        self.fully_connected_1 = nn.Linear(1568, 600)\n",
    "        \n",
    "        # Specify fully_connected_1 activation function\n",
    "        self.activation_function_fcc_1 = nn.ReLU()\n",
    "        \n",
    "        # Apply dropout \n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "        \n",
    "        # Define second fully-connected layer\n",
    "        # NOTE: the output dimension is 10 because of the number of classes\n",
    "        self.fully_connected_2 = nn.Linear(600, 10)\n",
    "                                  \n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        Implements the feed forward process of the input x through the CNN\n",
    "        \"\"\"\n",
    "                                  \n",
    "        # Feed forward the input through the CNN layers\n",
    "        output_conv2d_1 = self.conv2d_1(x)\n",
    "        output_conv2d_1 = self.batch_normalisation_1(output_conv2d_1)\n",
    "        output_conv2d_1 = self.activation_function_1(output_conv2d_1)\n",
    "        output_conv2d_1 = self.max_pooling_1(output_conv2d_1)\n",
    "        \n",
    "        output_conv2d_2 = self.conv2d_2(output_conv2d_1)\n",
    "        output_conv2d_2 = self.batch_normalisation_2(output_conv2d_2)\n",
    "        output_conv2d_2 = self.activation_function_2(output_conv2d_2)\n",
    "        output_conv2d_2 = self.max_pooling_2(output_conv2d_2)\n",
    "        \n",
    "        output_fcc_1 = self.fully_connected_1(output_conv2d_2)\n",
    "        output_fcc_1 = self.activation_function_fcc_1(output_fcc_1)\n",
    "        output_fcc_1 = self.dropout(output_fcc_1)\n",
    "        \n",
    "        output = self.fully_connected_2(output_fcc_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "aff0e63c-ba3d-4915-9b05-89230f8d7953",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameters\n",
    "conv2d_1_attributes = {\n",
    "    'input_channels': 1,\n",
    "    'output_channels': 8, # Number of filters to apply\n",
    "    'kernel_size': 3,\n",
    "    'stride': 1,\n",
    "    'padding': 1 # (kernel_size - 1)/2\n",
    "}\n",
    "\n",
    "batch_normalisation_1_attributes = {\n",
    "    'feature_map_dim': 8\n",
    "}\n",
    "\n",
    "max_pooling_1_attributes = {\n",
    "    'kernel_size': 2\n",
    "}\n",
    "\n",
    "conv2d_2_attributes = {\n",
    "    'input_channels': 8,\n",
    "    'output_channels': 32, # Number of filters to apply\n",
    "    'kernel_size': 5,\n",
    "    'stride': 1,\n",
    "    'padding': 2 # (kernel_size - 1)/2\n",
    "}\n",
    "\n",
    "batch_normalisation_2_attributes = {\n",
    "    'feature_map_dim': 32\n",
    "}\n",
    "\n",
    "max_pooling_2_attributes = {\n",
    "    'kernel_size': 2\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "217e9e25-c7b6-49eb-8308-098144d4a9f4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
