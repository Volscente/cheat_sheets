{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1b86efb9-e5da-4904-9cda-739b08053443",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "The notebook is intended to experiment with the different TensorFlow APIs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1ce2cacb-a45c-471d-bc46-a28743cb89ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Standard Libraries\n",
    "import os\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.layers.experimental import preprocessing\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Suppress warnings\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cefb6a3-8d26-4616-8dcd-6c8eaae13af8",
   "metadata": {},
   "source": [
    "# Read Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0d6df178-17bc-4a14-93dd-6981b16a17b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a dataset\n",
    "X = tf.constant(range(10), dtype=tf.float32)\n",
    "Y = 2 * X + 10"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd7a128b-1a5c-4e24-970e-17429d85e8af",
   "metadata": {},
   "source": [
    "## Pet Finder Mini Toy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "89ac23c0-2f8d-46f1-927c-2b58b98a7a55",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read required data petfinder_mini_toy\n",
    "petfinder_mini_toy = pd.read_csv('./../../data/petfinder-mini.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "21c5a607-cd69-4d0c-84d4-913450a568b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Type</th>\n",
       "      <th>Age</th>\n",
       "      <th>Breed1</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Color1</th>\n",
       "      <th>Color2</th>\n",
       "      <th>MaturitySize</th>\n",
       "      <th>FurLength</th>\n",
       "      <th>Vaccinated</th>\n",
       "      <th>Sterilized</th>\n",
       "      <th>Health</th>\n",
       "      <th>Fee</th>\n",
       "      <th>Description</th>\n",
       "      <th>PhotoAmt</th>\n",
       "      <th>AdoptionSpeed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Cat</td>\n",
       "      <td>3</td>\n",
       "      <td>Tabby</td>\n",
       "      <td>Male</td>\n",
       "      <td>Black</td>\n",
       "      <td>White</td>\n",
       "      <td>Small</td>\n",
       "      <td>Short</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>Healthy</td>\n",
       "      <td>100</td>\n",
       "      <td>Nibble is a 3+ month old ball of cuteness. He ...</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Cat</td>\n",
       "      <td>1</td>\n",
       "      <td>Domestic Medium Hair</td>\n",
       "      <td>Male</td>\n",
       "      <td>Black</td>\n",
       "      <td>Brown</td>\n",
       "      <td>Medium</td>\n",
       "      <td>Medium</td>\n",
       "      <td>Not Sure</td>\n",
       "      <td>Not Sure</td>\n",
       "      <td>Healthy</td>\n",
       "      <td>0</td>\n",
       "      <td>I just found it alone yesterday near my apartm...</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Dog</td>\n",
       "      <td>1</td>\n",
       "      <td>Mixed Breed</td>\n",
       "      <td>Male</td>\n",
       "      <td>Brown</td>\n",
       "      <td>White</td>\n",
       "      <td>Medium</td>\n",
       "      <td>Medium</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>Healthy</td>\n",
       "      <td>0</td>\n",
       "      <td>Their pregnant mother was dumped by her irresp...</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Dog</td>\n",
       "      <td>4</td>\n",
       "      <td>Mixed Breed</td>\n",
       "      <td>Female</td>\n",
       "      <td>Black</td>\n",
       "      <td>Brown</td>\n",
       "      <td>Medium</td>\n",
       "      <td>Short</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>Healthy</td>\n",
       "      <td>150</td>\n",
       "      <td>Good guard dog, very alert, active, obedience ...</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Dog</td>\n",
       "      <td>1</td>\n",
       "      <td>Mixed Breed</td>\n",
       "      <td>Male</td>\n",
       "      <td>Black</td>\n",
       "      <td>No Color</td>\n",
       "      <td>Medium</td>\n",
       "      <td>Short</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>Healthy</td>\n",
       "      <td>0</td>\n",
       "      <td>This handsome yet cute boy is up for adoption....</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Type  Age                Breed1  Gender Color1    Color2 MaturitySize  \\\n",
       "0  Cat    3                 Tabby    Male  Black     White        Small   \n",
       "1  Cat    1  Domestic Medium Hair    Male  Black     Brown       Medium   \n",
       "2  Dog    1           Mixed Breed    Male  Brown     White       Medium   \n",
       "3  Dog    4           Mixed Breed  Female  Black     Brown       Medium   \n",
       "4  Dog    1           Mixed Breed    Male  Black  No Color       Medium   \n",
       "\n",
       "  FurLength Vaccinated Sterilized   Health  Fee  \\\n",
       "0     Short         No         No  Healthy  100   \n",
       "1    Medium   Not Sure   Not Sure  Healthy    0   \n",
       "2    Medium        Yes         No  Healthy    0   \n",
       "3     Short        Yes         No  Healthy  150   \n",
       "4     Short         No         No  Healthy    0   \n",
       "\n",
       "                                         Description  PhotoAmt  AdoptionSpeed  \n",
       "0  Nibble is a 3+ month old ball of cuteness. He ...         1              2  \n",
       "1  I just found it alone yesterday near my apartm...         2              0  \n",
       "2  Their pregnant mother was dumped by her irresp...         7              3  \n",
       "3  Good guard dog, very alert, active, obedience ...         8              2  \n",
       "4  This handsome yet cute boy is up for adoption....         3              2  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "petfinder_mini_toy.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3c89812e-aee1-427d-bac7-f94e09cb0bac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create target variable\n",
    "petfinder_mini_toy['target'] = np.where(petfinder_mini_toy['AdoptionSpeed']==4, 0, 1)\n",
    "\n",
    "# Drop unused columns\n",
    "petfinder_mini_toy = petfinder_mini_toy.drop(columns=['AdoptionSpeed', 'Description'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "176acebd-a4d3-4505-aee1-a05ac75f2aab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7383 train examples\n",
      "1846 validation examples\n",
      "2308 test examples\n"
     ]
    }
   ],
   "source": [
    "# Split train + validation + test\n",
    "petfinder_mini_toy_train, petfinder_mini_toy_test = train_test_split(petfinder_mini_toy, test_size=0.2)\n",
    "petfinder_mini_toy_train, petfinder_mini_toy_validation = train_test_split(petfinder_mini_toy_train, test_size=0.2)\n",
    "\n",
    "print(len(petfinder_mini_toy_train), 'train examples')\n",
    "print(len(petfinder_mini_toy_validation), 'validation examples')\n",
    "print(len(petfinder_mini_toy_test), 'test examples')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f20444ff-7e89-4f20-bf59-f63f50360545",
   "metadata": {},
   "source": [
    "# Dataset API"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "055c2518-54cb-49d9-8f48-62ccac04dac7",
   "metadata": {},
   "source": [
    "## Create"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f0272685-6353-49eb-8214-d145e6801113",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a dataset\n",
    "dataset = tf.data.Dataset.from_tensor_slices((X, Y))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d97c5aa7-a70f-40af-830c-e33be82c7ec6",
   "metadata": {},
   "source": [
    "## Fetch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "625edc2f-8d0b-499c-9eef-c505d6fa9c53",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0 - 10.0\n",
      "1.0 - 12.0\n",
      "2.0 - 14.0\n",
      "3.0 - 16.0\n",
      "4.0 - 18.0\n",
      "5.0 - 20.0\n",
      "6.0 - 22.0\n",
      "7.0 - 24.0\n",
      "8.0 - 26.0\n",
      "9.0 - 28.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-06-13 19:37:35.960429: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_1' with dtype float and shape [10]\n",
      "\t [[{{node Placeholder/_1}}]]\n"
     ]
    }
   ],
   "source": [
    "# Retrieve the data samples\n",
    "for x, y in dataset:\n",
    "    print(f'{x} - {y}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38c9ad2c-51c0-407d-bdb3-5a00dccb822b",
   "metadata": {},
   "source": [
    "## Batch and Epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dbf473c4-88ed-453e-a902-8cff11e4d6c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define batch size and epochs\n",
    "batch_size = 3\n",
    "epochs = 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c516f058-397e-4928-846c-8879753848ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add batches and epochs\n",
    "dataset = dataset.repeat(epochs).batch(batch_size, drop_remainder=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1e352dab-b0f1-45c7-a2c9-302f23a9792e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 1. 2.] - [10. 12. 14.]\n",
      "[3. 4. 5.] - [16. 18. 20.]\n",
      "[6. 7. 8.] - [22. 24. 26.]\n",
      "[9. 0. 1.] - [28. 10. 12.]\n",
      "[2. 3. 4.] - [14. 16. 18.]\n",
      "[5. 6. 7.] - [20. 22. 24.]\n",
      "[8. 9. 0.] - [26. 28. 10.]\n",
      "[1. 2. 3.] - [12. 14. 16.]\n",
      "[4. 5. 6.] - [18. 20. 22.]\n",
      "[7. 8. 9.] - [24. 26. 28.]\n",
      "[0. 1. 2.] - [10. 12. 14.]\n",
      "[3. 4. 5.] - [16. 18. 20.]\n",
      "[6. 7. 8.] - [22. 24. 26.]\n",
      "[9. 0. 1.] - [28. 10. 12.]\n",
      "[2. 3. 4.] - [14. 16. 18.]\n",
      "[5. 6. 7.] - [20. 22. 24.]\n",
      "[8. 9. 0.] - [26. 28. 10.]\n",
      "[1. 2. 3.] - [12. 14. 16.]\n",
      "[4. 5. 6.] - [18. 20. 22.]\n",
      "[7. 8. 9.] - [24. 26. 28.]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-06-13 19:37:36.026819: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_1' with dtype float and shape [10]\n",
      "\t [[{{node Placeholder/_1}}]]\n"
     ]
    }
   ],
   "source": [
    "# Reitreve the batches for the epochs\n",
    "for batch_x, batch_y in dataset:\n",
    "    print(f'{batch_x} - {batch_y}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f62a59f2-e4d0-4410-8b95-f59438613dd2",
   "metadata": {},
   "source": [
    "## Read CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "022f63cf-9a9a-407e-b130-2846a40de137",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define feature columns\n",
    "features = ['date', \n",
    "            'country', \n",
    "            'store', \n",
    "            'product']\n",
    "\n",
    "# Define labels\n",
    "labels = ['num_sold']\n",
    "\n",
    "# Read data from csv\n",
    "dataset_csv = tf.data.experimental.make_csv_dataset(file_pattern='./../../data/books_sold_train.csv', batch_size=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d7258be3-f0bc-4187-90c5-ffb2001daf54",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-06-13 19:37:36.118080: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype string and shape [1]\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "2023-06-13 19:37:36.118521: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_7' with dtype int32 and shape [1]\n",
      "\t [[{{node Placeholder/_7}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([2662 2322 8868 3475], shape=(4,), dtype=int32)\n",
      "tf.Tensor([5627 8225 7237 4607], shape=(4,), dtype=int32)\n",
      "tf.Tensor([7890 1647 8350 2818], shape=(4,), dtype=int32)\n",
      "tf.Tensor([4393  373 1462 4099], shape=(4,), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "# Fetch data\n",
    "for step, (row) in enumerate(dataset_csv):\n",
    "\n",
    "    print(row['row_id'])\n",
    "\n",
    "    if step == 3:\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc662db7-0683-4567-a169-6d84d80aa940",
   "metadata": {},
   "source": [
    "## Create Dataset from DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "19071770-32bc-40d7-b39c-b5946c1f0192",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dataframe_to_dataset(data: pd.DataFrame, \n",
    "                         label_column: str, \n",
    "                         shuffle:bool = True, \n",
    "                         epochs:int = None, \n",
    "                         batch_size:int = 32):\n",
    "\n",
    "    # Ensure to not work on the original dataframe\n",
    "    data = data.copy()\n",
    "\n",
    "    # Extract the label\n",
    "    labels = data.pop(label_column)\n",
    "\n",
    "    # Create the dataset\n",
    "    dataset = tf.data.Dataset.from_tensor_slices(dict(data), labels)\n",
    "\n",
    "    # Shuffle dataset\n",
    "    if shuffle:\n",
    "        dataset = ds.shuffle(buffer_size=len(data))\n",
    "\n",
    "    # Repeat for epochs\n",
    "    if epochs:\n",
    "        dataset = dataset.repeat(epochs)\n",
    "\n",
    "    # Add batches\n",
    "    if batch_size:\n",
    "\n",
    "        # Add batches \n",
    "        dataset = dataset.batch(batch_size)\n",
    "        \n",
    "        # Prefect method ensures to prepare the next element while the current is being processed\n",
    "        dataset = dataset.prefecth(batch_size)\n",
    "                             \n",
    "    return dataset          "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "2a2b7ab1-daa6-4421-aec3-2b39411e0af9",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "The truth value of a Series is ambiguous. Use a.empty, a.bool(), a.item(), a.any() or a.all().",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/2t/wgg9ryl91kxd7b51f7g035jsdh30gy/T/ipykernel_29692/351380811.py\u001b[0m in \u001b[0;36m?\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mpetfinder_mini_toy_dataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdataframe_to_dataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpetfinder_mini_toy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'target'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/var/folders/2t/wgg9ryl91kxd7b51f7g035jsdh30gy/T/ipykernel_29692/2483850751.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(data, label_column, shuffle, epochs, batch_size)\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0;31m# Extract the label\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabel_column\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0;31m# Create the dataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m     \u001b[0mdataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_tensor_slices\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0;31m# Shuffle dataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/share/virtualenvs/cheat_sheets-EiW5VkhA/lib/python3.10/site-packages/tensorflow/python/data/ops/dataset_ops.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(tensors, name)\u001b[0m\n\u001b[1;32m    826\u001b[0m     \u001b[0;31m# Loaded lazily due to a circular dependency (dataset_ops ->\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    827\u001b[0m     \u001b[0;31m# from_tensor_slices_op -> dataset_ops).\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    828\u001b[0m     \u001b[0;31m# pylint: disable=g-import-not-at-top,protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    829\u001b[0m     \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mops\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mfrom_tensor_slices_op\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 830\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mfrom_tensor_slices_op\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_from_tensor_slices\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    831\u001b[0m     \u001b[0;31m# pylint: enable=g-import-not-at-top,protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/share/virtualenvs/cheat_sheets-EiW5VkhA/lib/python3.10/site-packages/tensorflow/python/data/ops/from_tensor_slices_op.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(tensors, name)\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_from_tensor_slices\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0m_TensorSliceDataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/.local/share/virtualenvs/cheat_sheets-EiW5VkhA/lib/python3.10/site-packages/tensorflow/python/data/ops/from_tensor_slices_op.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(self, element, is_files, name)\u001b[0m\n\u001b[1;32m     49\u001b[0m     variant_tensor = gen_dataset_ops.tensor_slice_dataset(\n\u001b[1;32m     50\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tensors\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m         \u001b[0moutput_shapes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstructure\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_flat_tensor_shapes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_structure\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m         \u001b[0mis_files\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mis_files\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 53\u001b[0;31m         metadata=self._metadata.SerializeToString())\n\u001b[0m\u001b[1;32m     54\u001b[0m     \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvariant_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/share/virtualenvs/cheat_sheets-EiW5VkhA/lib/python3.10/site-packages/tensorflow/python/data/ops/dataset_ops.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    671\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    672\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_metadata\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    673\u001b[0m     \u001b[0;34m\"\"\"Helper for generating dataset metadata.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    674\u001b[0m     \u001b[0mmetadata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdataset_metadata_pb2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mMetadata\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 675\u001b[0;31m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    676\u001b[0m       \u001b[0mmetadata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_validate_and_encode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    677\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mmetadata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/share/virtualenvs/cheat_sheets-EiW5VkhA/lib/python3.10/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1464\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mfinal\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1465\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__nonzero__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mNoReturn\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1466\u001b[0;31m         raise ValueError(\n\u001b[0m\u001b[1;32m   1467\u001b[0m             \u001b[0;34mf\"The truth value of a {type(self).__name__} is ambiguous. \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1468\u001b[0m             \u001b[0;34m\"Use a.empty, a.bool(), a.item(), a.any() or a.all().\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1469\u001b[0m         )\n",
      "\u001b[0;31mValueError\u001b[0m: The truth value of a Series is ambiguous. Use a.empty, a.bool(), a.item(), a.any() or a.all()."
     ]
    }
   ],
   "source": [
    "petfinder_mini_toy_dataset = dataframe_to_dataset(petfinder_mini_toy, 'target', epochs=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b30b4f3c-d356-42d0-bd42-5f269645ce2e",
   "metadata": {},
   "source": [
    "# Linear Regression Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b478b477-37d9-462d-9602-2c244d467b77",
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_mse(X, Y, w0, b):\n",
    "    \"\"\"\n",
    "    Compute the Loss as Mean Squared Error\n",
    "    \"\"\"\n",
    "    \n",
    "    # Predict the y value\n",
    "    y_predicted = w0 * X + b\n",
    "\n",
    "    # Compute the error\n",
    "    errors = (y_predicted - Y)**2\n",
    "\n",
    "    # Compute the mean\n",
    "    mse = tf.reduce_mean(errors)\n",
    "    \n",
    "    return mse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0dd26993-a375-41cb-805c-d4aebbbccc9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_derivate_terms(X, Y, w0, b):\n",
    "    \"\"\"\n",
    "    Compute the derivative terms for w0 and b\n",
    "    \"\"\"\n",
    "    \n",
    "    with tf.GradientTape() as tape:\n",
    "        loss = loss_mse(X, Y, w0, b)\n",
    "    return tape.gradient(loss, [w0, b])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "98a8820c-e908-416e-9879-f93935ca77f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-06-13 19:37:36.294767: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_1' with dtype float and shape [10]\n",
      "\t [[{{node Placeholder/_1}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 0 - Loss 121.37281799316406\n",
      "Step 100 - Loss 67.96109008789062\n",
      "Step 200 - Loss 60.568275451660156\n",
      "Step 300 - Loss 54.036888122558594\n",
      "Step 400 - Loss 48.209930419921875\n",
      "Step 500 - Loss 43.01130676269531\n",
      "Step 600 - Loss 38.37327575683594\n",
      "Step 700 - Loss 34.235374450683594\n",
      "Step 800 - Loss 30.54366683959961\n",
      "Step 900 - Loss 27.25004768371582\n",
      "Step 1000 - Loss 24.31158447265625\n",
      "Step 1100 - Loss 21.689990997314453\n",
      "Step 1200 - Loss 19.35108184814453\n"
     ]
    }
   ],
   "source": [
    "# Initialise w0 and b\n",
    "w0, b = tf.Variable(0.0), tf.Variable(0.0)\n",
    "\n",
    "# Set learning rate\n",
    "learning_rate = 0.001\n",
    "\n",
    "# Create bigger dataset\n",
    "dataset = tf.data.Dataset.from_tensor_slices((X, Y)).repeat(250).batch(2, drop_remainder=True)\n",
    "\n",
    "for step, (X_batch, Y_batch) in enumerate(dataset):\n",
    "\n",
    "    # Compute the derivate terms\n",
    "    dw0, db = compute_derivate_terms(X_batch, Y_batch, w0, b)\n",
    "\n",
    "    # Update w0 and b\n",
    "    w0.assign_sub(dw0 * learning_rate)\n",
    "    b.assign_sub(db * learning_rate)\n",
    "\n",
    "    # Print loss every 100 steps\n",
    "    if step % 100 == 0:\n",
    "        loss = loss_mse(X_batch, Y_batch, w0, b)\n",
    "        print(f'Step {step} - Loss {loss}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6942d50f-0b11-4665-9ee0-e7ed76bd0c88",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
