{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f0920911-f521-48a6-aead-3ee6996cbb2a",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "\n",
    "Experiment with PyTorch Loss Functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "128b08c6-515f-424e-b032-ade44bc07961",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Standard Libraries\n",
    "import torch\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "06a3248f-5f47-43e9-b267-dac6a8de2b41",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a tensor of possible output layer values: 4 values with 5 features\n",
    "tensor_1 = torch.randn(4, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "538ae427-72db-4782-a8c6-cba1815c6948",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.6564, -1.2322,  1.8523,  1.3146, -1.0642],\n",
       "        [-0.2401,  0.2339, -0.4977,  0.8021, -0.0224],\n",
       "        [-0.0341,  0.9484, -0.5104, -0.0370,  1.5323],\n",
       "        [ 2.4812, -0.7941,  0.2984, -1.1028,  0.1910]])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "cbac4db7-2bec-4213-851c-0357acfd1dd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the label for applying the loss function\n",
    "# NOTE: The shape should be the same as the tensor_1\n",
    "label = torch.randn(4, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "798f718a-30a8-4aa0-9a9c-ee4166874b9f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.2279, -1.3853, -0.6009, -0.1746, -0.3740],\n",
       "        [ 0.3180,  1.3059, -1.2588,  0.3353, -1.4413],\n",
       "        [-1.1685, -1.7911, -0.9912,  0.2887, -0.5451],\n",
       "        [ 1.1822, -1.6947,  1.5271,  0.7561, -1.1159]])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d2b72db-87be-4f42-aa1f-b2c3105171cb",
   "metadata": {},
   "source": [
    "# MSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "31950fcd-223d-4436-b1e6-2777e4470c11",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Â Define the MSE\n",
    "# NOTE: 'reduction' defines the value to return (e.g., 'sum' returns a double value, while 'none' returns a tensor (N, *))\n",
    "mse = nn.MSELoss(reduction='none')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e0233bfe-b25a-4173-93e3-c90caf57bb17",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute the MSE\n",
    "loss_mse = mse(tensor_1, label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "12a77f52-ade0-43e6-9399-77c37f9ee371",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.7821, 0.0235, 6.0183, 2.2178, 0.4764],\n",
       "        [0.3115, 1.1493, 0.5793, 0.2179, 2.0131],\n",
       "        [1.2868, 7.5050, 0.2312, 0.1061, 4.3153],\n",
       "        [1.6875, 0.8110, 1.5095, 3.4554, 1.7082]])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss_mse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c2286d1e-2bc3-4bef-b42f-65b093e7449f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.7821)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(tensor_1[0][0] - label[0][0]) ** 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "110f4285-1285-49bd-850a-f6dc2a6a47c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's try the mean reduction\n",
    "mse_mean = nn.MSELoss(reduction='mean')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "5bd148eb-07af-4e19-be68-183f7c41453f",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_mse_mean = mse_mean(tensor_1, label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "9f7ca5f0-0d62-4f3f-a54d-0e81535a8c96",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1.8203)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss_mse_mean"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f938b249-7227-477a-b411-e9cb522e3717",
   "metadata": {},
   "source": [
    "# Binary Cross-Entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "298be63c-c3a0-4cd0-92b9-ea93dbb114d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the labels\n",
    "# NOTE: Initialise a matrix 4 x 5 with zeros and then randomly fill it with 0 and 1 (random_(0, 2))\n",
    "label = torch.zeros(4, 5).random_(0, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "8f8d0063-152c-456a-af43-944741c01756",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 1., 1., 1., 0.],\n",
       "        [1., 1., 1., 1., 0.],\n",
       "        [1., 1., 0., 0., 1.],\n",
       "        [1., 0., 1., 1., 0.]])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "3370f2ec-a7a5-489c-8fe5-7ac1ec75151f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Since we're not using BCE with Logits, we need that the input of the BCE comes from a Sigmoid function\n",
    "# NOTE: BCE with Logits applies the Sigmoid function internally\n",
    "sigmoid = nn.Sigmoid()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "8aecbb0b-38de-4384-9198-ba02aa0a3514",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the BCE Loss\n",
    "bce = nn.BCELoss(reduction='mean')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "681b8ded-e5cb-44b0-b01b-34e1b0224d45",
   "metadata": {},
   "outputs": [],
   "source": [
    "bce_loss = bce(sigmoid(tensor_1), label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "1d79e471-b014-40c9-8f32-e7f6abe6c86d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.5792)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bce_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "597e57ef-cea9-46a5-9c47-9a4f3b0e50ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "bce_with_logits = nn.BCEWithLogitsLoss(reduction='mean')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "ee34d15f-76e1-4189-83de-82982fa44ba3",
   "metadata": {},
   "outputs": [],
   "source": [
    "bce_with_logits_loss = bce_with_logits(tensor_1, label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "9973d36a-3a78-4a56-ac33-3b46a61c6048",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.5792)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bce_with_logits_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6eef3b04-c3cc-4374-8f4c-e07e67f25a92",
   "metadata": {},
   "source": [
    "Note that the results between BCE and BCE with Logits is exactly the same, because BCE with Logits applies the Sigmoid funciton internally. While for BCE we used the Sigmoid explicitly."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
