{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f38e528f-614c-46c9-894b-86d81e9c91c6",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "\n",
    "Experiment with MLflow from this [Video Tutorial](https://www.youtube.com/watch?v=WbicniUy_u0)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9852a18e-3ab5-4476-b9d9-37159d5b7ed7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLflow Version:  2.2.2\n"
     ]
    }
   ],
   "source": [
    "# Import Standard Libraries\n",
    "import mlflow\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.linear_model import LinearRegression, ElasticNet\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "print('MLflow Version: ', mlflow.version.VERSION)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "77b29473-f821-46cb-ad3e-146f11027ef5",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on package mlflow:\n",
      "\n",
      "NAME\n",
      "    mlflow\n",
      "\n",
      "DESCRIPTION\n",
      "    The ``mlflow`` module provides a high-level \"fluent\" API for starting and managing MLflow runs.\n",
      "    For example:\n",
      "    \n",
      "    .. code:: python\n",
      "    \n",
      "        import mlflow\n",
      "    \n",
      "        mlflow.start_run()\n",
      "        mlflow.log_param(\"my\", \"param\")\n",
      "        mlflow.log_metric(\"score\", 100)\n",
      "        mlflow.end_run()\n",
      "    \n",
      "    You can also use the context manager syntax like this:\n",
      "    \n",
      "    .. code:: python\n",
      "    \n",
      "        with mlflow.start_run() as run:\n",
      "            mlflow.log_param(\"my\", \"param\")\n",
      "            mlflow.log_metric(\"score\", 100)\n",
      "    \n",
      "    which automatically terminates the run at the end of the ``with`` block.\n",
      "    \n",
      "    The fluent tracking API is not currently threadsafe. Any concurrent callers to the tracking API must\n",
      "    implement mutual exclusion manually.\n",
      "    \n",
      "    For a lower level API, see the :py:mod:`mlflow.client` module.\n",
      "\n",
      "PACKAGE CONTENTS\n",
      "    __main__\n",
      "    _doctor\n",
      "    _spark_autologging\n",
      "    artifacts (package)\n",
      "    azure (package)\n",
      "    catboost\n",
      "    cli\n",
      "    client\n",
      "    data\n",
      "    db\n",
      "    deployments (package)\n",
      "    diviner\n",
      "    entities (package)\n",
      "    environment_variables\n",
      "    exceptions\n",
      "    experiments\n",
      "    fastai (package)\n",
      "    gluon (package)\n",
      "    h2o\n",
      "    keras\n",
      "    lightgbm\n",
      "    ml_package_versions\n",
      "    mleap\n",
      "    models (package)\n",
      "    onnx\n",
      "    paddle (package)\n",
      "    pmdarima\n",
      "    projects (package)\n",
      "    prophet\n",
      "    protos (package)\n",
      "    pyfunc (package)\n",
      "    pyspark (package)\n",
      "    pytorch (package)\n",
      "    recipes (package)\n",
      "    rfunc (package)\n",
      "    runs\n",
      "    sagemaker (package)\n",
      "    server (package)\n",
      "    shap\n",
      "    sklearn (package)\n",
      "    spacy\n",
      "    spark\n",
      "    statsmodels\n",
      "    store (package)\n",
      "    tensorflow (package)\n",
      "    tracking (package)\n",
      "    types (package)\n",
      "    utils (package)\n",
      "    version\n",
      "    xgboost (package)\n",
      "\n",
      "CLASSES\n",
      "    builtins.Exception(builtins.BaseException)\n",
      "        mlflow.exceptions.MlflowException\n",
      "    builtins.object\n",
      "        mlflow.tracking.client.MlflowClient\n",
      "    mlflow.entities.run.Run(mlflow.entities._mlflow_object._MLflowObject)\n",
      "        mlflow.tracking.fluent.ActiveRun\n",
      "    \n",
      "    class ActiveRun(mlflow.entities.run.Run)\n",
      "     |  ActiveRun(run)\n",
      "     |  \n",
      "     |  Wrapper around :py:class:`mlflow.entities.Run` to enable using Python ``with`` syntax.\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      ActiveRun\n",
      "     |      mlflow.entities.run.Run\n",
      "     |      mlflow.entities._mlflow_object._MLflowObject\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __enter__(self)\n",
      "     |  \n",
      "     |  __exit__(self, exc_type, exc_val, exc_tb)\n",
      "     |  \n",
      "     |  __init__(self, run)\n",
      "     |      Initialize self.  See help(type(self)) for accurate signature.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from mlflow.entities.run.Run:\n",
      "     |  \n",
      "     |  to_dictionary(self)\n",
      "     |  \n",
      "     |  to_proto(self)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Class methods inherited from mlflow.entities.run.Run:\n",
      "     |  \n",
      "     |  from_proto(proto) from builtins.type\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Readonly properties inherited from mlflow.entities.run.Run:\n",
      "     |  \n",
      "     |  data\n",
      "     |      The run data, including metrics, parameters, and tags.\n",
      "     |      \n",
      "     |      :rtype: :py:class:`mlflow.entities.RunData`\n",
      "     |  \n",
      "     |  info\n",
      "     |      The run metadata, such as the run id, start time, and status.\n",
      "     |      \n",
      "     |      :rtype: :py:class:`mlflow.entities.RunInfo`\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from mlflow.entities._mlflow_object._MLflowObject:\n",
      "     |  \n",
      "     |  __iter__(self)\n",
      "     |  \n",
      "     |  __repr__(self)\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Class methods inherited from mlflow.entities._mlflow_object._MLflowObject:\n",
      "     |  \n",
      "     |  from_dictionary(the_dict) from builtins.type\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from mlflow.entities._mlflow_object._MLflowObject:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "    \n",
      "    class MlflowClient(builtins.object)\n",
      "     |  MlflowClient(tracking_uri: Optional[str] = None, registry_uri: Optional[str] = None)\n",
      "     |  \n",
      "     |  Client of an MLflow Tracking Server that creates and manages experiments and runs, and of an\n",
      "     |  MLflow Registry Server that creates and manages registered models and model versions. It's a\n",
      "     |  thin wrapper around TrackingServiceClient and RegistryClient so there is a unified API but we\n",
      "     |  can keep the implementation of the tracking and registry clients independent from each other.\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __init__(self, tracking_uri: Optional[str] = None, registry_uri: Optional[str] = None)\n",
      "     |      :param tracking_uri: Address of local or remote tracking server. If not provided, defaults\n",
      "     |                           to the service set by ``mlflow.tracking.set_tracking_uri``. See\n",
      "     |                           `Where Runs Get Recorded <../tracking.html#where-runs-get-recorded>`_\n",
      "     |                           for more info.\n",
      "     |      :param registry_uri: Address of local or remote model registry server. If not provided,\n",
      "     |                           defaults to the service set by ``mlflow.tracking.set_registry_uri``. If\n",
      "     |                           no such service was set, defaults to the tracking uri of the client.\n",
      "     |  \n",
      "     |  create_experiment(self, name: str, artifact_location: Optional[str] = None, tags: Optional[Dict[str, Any]] = None) -> str\n",
      "     |      Create an experiment.\n",
      "     |      \n",
      "     |      :param name: The experiment name. Must be unique.\n",
      "     |      :param artifact_location: The location to store run artifacts.\n",
      "     |                                If not provided, the server picks an appropriate default.\n",
      "     |      :param tags: A dictionary of key-value pairs that are converted into\n",
      "     |                              :py:class:`mlflow.entities.ExperimentTag` objects, set as\n",
      "     |                              experiment tags upon experiment creation.\n",
      "     |      :return: String as an integer ID of the created experiment.\n",
      "     |      \n",
      "     |      .. code-block:: python\n",
      "     |          :caption: Example\n",
      "     |      \n",
      "     |          from pathlib import Path\n",
      "     |          from mlflow import MlflowClient\n",
      "     |      \n",
      "     |          # Create an experiment with a name that is unique and case sensitive.\n",
      "     |          client = MlflowClient()\n",
      "     |          experiment_id = client.create_experiment(\n",
      "     |              \"Social NLP Experiments\",\n",
      "     |              artifact_location=Path.cwd().joinpath(\"mlruns\").as_uri(),\n",
      "     |              tags={\"version\": \"v1\", \"priority\": \"P1\"},\n",
      "     |          )\n",
      "     |          client.set_experiment_tag(experiment_id, \"nlp.framework\", \"Spark NLP\")\n",
      "     |      \n",
      "     |          # Fetch experiment metadata information\n",
      "     |          experiment = client.get_experiment(experiment_id)\n",
      "     |          print(\"Name: {}\".format(experiment.name))\n",
      "     |          print(\"Experiment_id: {}\".format(experiment.experiment_id))\n",
      "     |          print(\"Artifact Location: {}\".format(experiment.artifact_location))\n",
      "     |          print(\"Tags: {}\".format(experiment.tags))\n",
      "     |          print(\"Lifecycle_stage: {}\".format(experiment.lifecycle_stage))\n",
      "     |      \n",
      "     |      .. code-block:: text\n",
      "     |          :caption: Output\n",
      "     |      \n",
      "     |          Name: Social NLP Experiments\n",
      "     |          Experiment_id: 1\n",
      "     |          Artifact Location: file:///.../mlruns\n",
      "     |          Tags: {'version': 'v1', 'priority': 'P1', 'nlp.framework': 'Spark NLP'}\n",
      "     |          Lifecycle_stage: active\n",
      "     |  \n",
      "     |  create_model_version(self, name: str, source: str, run_id: Optional[str] = None, tags: Optional[Dict[str, Any]] = None, run_link: Optional[str] = None, description: Optional[str] = None, await_creation_for: int = 300) -> mlflow.entities.model_registry.model_version.ModelVersion\n",
      "     |      Create a new model version from given source (artifact URI).\n",
      "     |      \n",
      "     |      :param name: Name for the containing registered model.\n",
      "     |      :param source: Source path where the MLflow model is stored.\n",
      "     |      :param run_id: Run ID from MLflow tracking server that generated the model\n",
      "     |      :param tags: A dictionary of key-value pairs that are converted into\n",
      "     |                   :py:class:`mlflow.entities.model_registry.ModelVersionTag` objects.\n",
      "     |      :param run_link: Link to the run from an MLflow tracking server that generated this model.\n",
      "     |      :param description: Description of the version.\n",
      "     |      :param await_creation_for: Number of seconds to wait for the model version to finish being\n",
      "     |                                  created and is in ``READY`` status. By default, the function\n",
      "     |                                  waits for five minutes. Specify 0 or None to skip waiting.\n",
      "     |      :return: Single :py:class:`mlflow.entities.model_registry.ModelVersion` object created by\n",
      "     |               backend.\n",
      "     |      \n",
      "     |      .. code-block:: python\n",
      "     |          :caption: Example\n",
      "     |      \n",
      "     |          import mlflow.sklearn\n",
      "     |          from mlflow.store.artifact.runs_artifact_repo import RunsArtifactRepository\n",
      "     |          from mlflow import MlflowClient\n",
      "     |          from sklearn.ensemble import RandomForestRegressor\n",
      "     |      \n",
      "     |          mlflow.set_tracking_uri(\"sqlite:///mlruns.db\")\n",
      "     |          params = {\"n_estimators\": 3, \"random_state\": 42}\n",
      "     |          name = \"RandomForestRegression\"\n",
      "     |          rfr = RandomForestRegressor(**params).fit([[0, 1]], [1])\n",
      "     |          # Log MLflow entities\n",
      "     |          with mlflow.start_run() as run:\n",
      "     |              mlflow.log_params(params)\n",
      "     |              mlflow.sklearn.log_model(rfr, artifact_path=\"sklearn-model\")\n",
      "     |      \n",
      "     |          # Register model name in the model registry\n",
      "     |          client = MlflowClient()\n",
      "     |          client.create_registered_model(name)\n",
      "     |      \n",
      "     |          # Create a new version of the rfr model under the registered model name\n",
      "     |          desc = \"A new version of the model\"\n",
      "     |          runs_uri = \"runs:/{}/sklearn-model\".format(run.info.run_id)\n",
      "     |          model_src = RunsArtifactRepository.get_underlying_uri(runs_uri)\n",
      "     |          mv = client.create_model_version(name, model_src, run.info.run_id, description=desc)\n",
      "     |          print(\"Name: {}\".format(mv.name))\n",
      "     |          print(\"Version: {}\".format(mv.version))\n",
      "     |          print(\"Description: {}\".format(mv.description))\n",
      "     |          print(\"Status: {}\".format(mv.status))\n",
      "     |          print(\"Stage: {}\".format(mv.current_stage))\n",
      "     |      \n",
      "     |      .. code-block:: text\n",
      "     |          :caption: Output\n",
      "     |      \n",
      "     |          Name: RandomForestRegression\n",
      "     |          Version: 1\n",
      "     |          Description: A new version of the model\n",
      "     |          Status: READY\n",
      "     |          Stage: None\n",
      "     |  \n",
      "     |  create_registered_model(self, name: str, tags: Optional[Dict[str, Any]] = None, description: Optional[str] = None) -> mlflow.entities.model_registry.registered_model.RegisteredModel\n",
      "     |      Create a new registered model in backend store.\n",
      "     |      \n",
      "     |      :param name: Name of the new model. This is expected to be unique in the backend store.\n",
      "     |      :param tags: A dictionary of key-value pairs that are converted into\n",
      "     |                   :py:class:`mlflow.entities.model_registry.RegisteredModelTag` objects.\n",
      "     |      :param description: Description of the model.\n",
      "     |      :return: A single object of :py:class:`mlflow.entities.model_registry.RegisteredModel`\n",
      "     |               created by backend.\n",
      "     |      \n",
      "     |      .. code-block:: python\n",
      "     |          :caption: Example\n",
      "     |      \n",
      "     |          import mlflow\n",
      "     |          from mlflow import MlflowClient\n",
      "     |      \n",
      "     |      \n",
      "     |          def print_registered_model_info(rm):\n",
      "     |              print(\"name: {}\".format(rm.name))\n",
      "     |              print(\"tags: {}\".format(rm.tags))\n",
      "     |              print(\"description: {}\".format(rm.description))\n",
      "     |      \n",
      "     |      \n",
      "     |          name = \"SocialMediaTextAnalyzer\"\n",
      "     |          tags = {\"nlp.framework\": \"Spark NLP\"}\n",
      "     |          desc = \"This sentiment analysis model classifies the tone-happy, sad, angry.\"\n",
      "     |      \n",
      "     |          mlflow.set_tracking_uri(\"sqlite:///mlruns.db\")\n",
      "     |          client = MlflowClient()\n",
      "     |          client.create_registered_model(name, tags, desc)\n",
      "     |          print_registered_model_info(client.get_registered_model(name))\n",
      "     |      \n",
      "     |      .. code-block:: text\n",
      "     |          :caption: Output\n",
      "     |      \n",
      "     |          name: SocialMediaTextAnalyzer\n",
      "     |          tags: {'nlp.framework': 'Spark NLP'}\n",
      "     |          description: This sentiment analysis model classifies the tone-happy, sad, angry.\n",
      "     |  \n",
      "     |  create_run(self, experiment_id: str, start_time: Optional[int] = None, tags: Optional[Dict[str, Any]] = None, run_name: Optional[str] = None) -> mlflow.entities.run.Run\n",
      "     |      Create a :py:class:`mlflow.entities.Run` object that can be associated with\n",
      "     |      metrics, parameters, artifacts, etc.\n",
      "     |      Unlike :py:func:`mlflow.projects.run`, creates objects but does not run code.\n",
      "     |      Unlike :py:func:`mlflow.start_run`, does not change the \"active run\" used by\n",
      "     |      :py:func:`mlflow.log_param`.\n",
      "     |      \n",
      "     |      :param experiment_id: The string ID of the experiment to create a run in.\n",
      "     |      :param start_time: If not provided, use the current timestamp.\n",
      "     |      :param tags: A dictionary of key-value pairs that are converted into\n",
      "     |                   :py:class:`mlflow.entities.RunTag` objects.\n",
      "     |      :param run_name: The name of this run.\n",
      "     |      :return: :py:class:`mlflow.entities.Run` that was created.\n",
      "     |      \n",
      "     |      .. code-block:: python\n",
      "     |          :caption: Example\n",
      "     |      \n",
      "     |          from mlflow import MlflowClient\n",
      "     |      \n",
      "     |          # Create a run with a tag under the default experiment (whose id is '0').\n",
      "     |          tags = {\"engineering\": \"ML Platform\"}\n",
      "     |          name = \"platform-run-24\"\n",
      "     |          client = MlflowClient()\n",
      "     |          experiment_id = \"0\"\n",
      "     |          run = client.create_run(experiment_id, tags=tags, run_name=name)\n",
      "     |      \n",
      "     |          # Show newly created run metadata info\n",
      "     |          print(\"Run tags: {}\".format(run.data.tags))\n",
      "     |          print(\"Experiment id: {}\".format(run.info.experiment_id))\n",
      "     |          print(\"Run id: {}\".format(run.info.run_id))\n",
      "     |          print(\"Run name: {}\".format(run.info.run_name))\n",
      "     |          print(\"lifecycle_stage: {}\".format(run.info.lifecycle_stage))\n",
      "     |          print(\"status: {}\".format(run.info.status))\n",
      "     |      \n",
      "     |      .. code-block:: text\n",
      "     |          :caption: Output\n",
      "     |      \n",
      "     |          Run tags: {'engineering': 'ML Platform'}\n",
      "     |          Experiment id: 0\n",
      "     |          Run id: 65fb9e2198764354bab398105f2e70c1\n",
      "     |          Run name: platform-run-24\n",
      "     |          lifecycle_stage: active\n",
      "     |          status: RUNNING\n",
      "     |  \n",
      "     |  delete_experiment(self, experiment_id: str) -> None\n",
      "     |      Delete an experiment from the backend store.\n",
      "     |      This deletion is a soft-delete, not a permanent deletion.\n",
      "     |      Experiment names can not be reused, unless the deleted experiment\n",
      "     |      is permanently deleted by a database admin.\n",
      "     |      \n",
      "     |      :param experiment_id: The experiment ID returned from ``create_experiment``.\n",
      "     |      \n",
      "     |      .. code-block:: python\n",
      "     |          :caption: Example\n",
      "     |      \n",
      "     |          from mlflow import MlflowClient\n",
      "     |      \n",
      "     |          # Create an experiment with a name that is unique and case sensitive\n",
      "     |          client = MlflowClient()\n",
      "     |          experiment_id = client.create_experiment(\"New Experiment\")\n",
      "     |          client.delete_experiment(experiment_id)\n",
      "     |      \n",
      "     |          # Examine the deleted experiment details.\n",
      "     |          experiment = client.get_experiment(experiment_id)\n",
      "     |          print(\"Name: {}\".format(experiment.name))\n",
      "     |          print(\"Artifact Location: {}\".format(experiment.artifact_location))\n",
      "     |          print(\"Lifecycle_stage: {}\".format(experiment.lifecycle_stage))\n",
      "     |      \n",
      "     |      .. code-block:: text\n",
      "     |          :caption: Output\n",
      "     |      \n",
      "     |          Name: New Experiment\n",
      "     |          Artifact Location: file:///.../mlruns/1\n",
      "     |          Lifecycle_stage: deleted\n",
      "     |  \n",
      "     |  delete_model_version(self, name: str, version: str) -> None\n",
      "     |      Delete model version in backend.\n",
      "     |      \n",
      "     |      :param name: Name of the containing registered model.\n",
      "     |      :param version: Version number of the model version.\n",
      "     |      \n",
      "     |      .. code-block:: python\n",
      "     |          :caption: Example\n",
      "     |      \n",
      "     |          import mlflow.sklearn\n",
      "     |          from mlflow import MlflowClient\n",
      "     |          from sklearn.ensemble import RandomForestRegressor\n",
      "     |      \n",
      "     |      \n",
      "     |          def print_models_info(mv):\n",
      "     |              for m in mv:\n",
      "     |                  print(\"name: {}\".format(m.name))\n",
      "     |                  print(\"latest version: {}\".format(m.version))\n",
      "     |                  print(\"run_id: {}\".format(m.run_id))\n",
      "     |                  print(\"current_stage: {}\".format(m.current_stage))\n",
      "     |      \n",
      "     |      \n",
      "     |          mlflow.set_tracking_uri(\"sqlite:///mlruns.db\")\n",
      "     |      \n",
      "     |          # Create two runs and log MLflow entities\n",
      "     |          with mlflow.start_run() as run1:\n",
      "     |              params = {\"n_estimators\": 3, \"random_state\": 42}\n",
      "     |              rfr = RandomForestRegressor(**params).fit([[0, 1]], [1])\n",
      "     |              mlflow.log_params(params)\n",
      "     |              mlflow.sklearn.log_model(rfr, artifact_path=\"sklearn-model\")\n",
      "     |      \n",
      "     |          with mlflow.start_run() as run2:\n",
      "     |              params = {\"n_estimators\": 6, \"random_state\": 42}\n",
      "     |              rfr = RandomForestRegressor(**params).fit([[0, 1]], [1])\n",
      "     |              mlflow.log_params(params)\n",
      "     |              mlflow.sklearn.log_model(rfr, artifact_path=\"sklearn-model\")\n",
      "     |      \n",
      "     |          # Register model name in the model registry\n",
      "     |          name = \"RandomForestRegression\"\n",
      "     |          client = MlflowClient()\n",
      "     |          client.create_registered_model(name)\n",
      "     |      \n",
      "     |          # Create a two versions of the rfr model under the registered model name\n",
      "     |          for run_id in [run1.info.run_id, run2.info.run_id]:\n",
      "     |              model_uri = \"runs:/{}/sklearn-model\".format(run_id)\n",
      "     |              mv = client.create_model_version(name, model_uri, run_id)\n",
      "     |              print(\"model version {} created\".format(mv.version))\n",
      "     |      \n",
      "     |          print(\"--\")\n",
      "     |      \n",
      "     |          # Fetch latest version; this will be version 2\n",
      "     |          models = client.get_latest_versions(name, stages=[\"None\"])\n",
      "     |          print_models_info(models)\n",
      "     |          print(\"--\")\n",
      "     |      \n",
      "     |          # Delete the latest model version 2\n",
      "     |          print(\"Deleting model version {}\".format(mv.version))\n",
      "     |          client.delete_model_version(name, mv.version)\n",
      "     |          models = client.get_latest_versions(name, stages=[\"None\"])\n",
      "     |          print_models_info(models)\n",
      "     |      \n",
      "     |      .. code-block:: text\n",
      "     |          :caption: Output\n",
      "     |      \n",
      "     |          model version 1 created\n",
      "     |          model version 2 created\n",
      "     |          --\n",
      "     |          name: RandomForestRegression\n",
      "     |          latest version: 2\n",
      "     |          run_id: 9881172ef10f4cb08df3ed452c0c362b\n",
      "     |          current_stage: None\n",
      "     |          --\n",
      "     |          Deleting model version 2\n",
      "     |          name: RandomForestRegression\n",
      "     |          latest version: 1\n",
      "     |          run_id: 9165d4f8aa0a4d069550824bdc55caaf\n",
      "     |          current_stage: None\n",
      "     |  \n",
      "     |  delete_model_version_tag(self, name: str, version: str = None, key: str = None, stage: str = None) -> None\n",
      "     |      Delete a tag associated with the model version.\n",
      "     |      When stage is set, tag will be deleted for latest model version of the stage.\n",
      "     |      Setting both version and stage parameter will result in error.\n",
      "     |      \n",
      "     |      :param name: Registered model name.\n",
      "     |      :param version: Registered model version.\n",
      "     |      :param key: Tag key. key is required.\n",
      "     |      :param stage: Registered model stage.\n",
      "     |      :return: None\n",
      "     |      \n",
      "     |      .. code-block:: python\n",
      "     |          :caption: Example\n",
      "     |      \n",
      "     |          import mlflow.sklearn\n",
      "     |          from mlflow import MlflowClient\n",
      "     |          from sklearn.ensemble import RandomForestRegressor\n",
      "     |      \n",
      "     |      \n",
      "     |          def print_model_version_info(mv):\n",
      "     |              print(\"Name: {}\".format(mv.name))\n",
      "     |              print(\"Version: {}\".format(mv.version))\n",
      "     |              print(\"Tags: {}\".format(mv.tags))\n",
      "     |      \n",
      "     |      \n",
      "     |          mlflow.set_tracking_uri(\"sqlite:///mlruns.db\")\n",
      "     |          params = {\"n_estimators\": 3, \"random_state\": 42}\n",
      "     |          name = \"RandomForestRegression\"\n",
      "     |          rfr = RandomForestRegressor(**params).fit([[0, 1]], [1])\n",
      "     |      \n",
      "     |          # Log MLflow entities\n",
      "     |          with mlflow.start_run() as run:\n",
      "     |              mlflow.log_params(params)\n",
      "     |              mlflow.sklearn.log_model(rfr, artifact_path=\"sklearn-model\")\n",
      "     |      \n",
      "     |          # Register model name in the model registry\n",
      "     |          client = MlflowClient()\n",
      "     |          client.create_registered_model(name)\n",
      "     |      \n",
      "     |          # Create a new version of the rfr model under the registered model name\n",
      "     |          # and delete a tag\n",
      "     |          model_uri = \"runs:/{}/sklearn-model\".format(run.info.run_id)\n",
      "     |          tags = {\"t\": \"1\", \"t1\": \"2\"}\n",
      "     |          mv = client.create_model_version(name, model_uri, run.info.run_id, tags=tags)\n",
      "     |          print_model_version_info(mv)\n",
      "     |          print(\"--\")\n",
      "     |          # using version to delete tag\n",
      "     |          client.delete_model_version_tag(name, mv.version, \"t\")\n",
      "     |      \n",
      "     |          # using stage to delete tag\n",
      "     |          client.delete_model_version_tag(name, key=\"t1\", stage=mv.current_stage)\n",
      "     |          mv = client.get_model_version(name, mv.version)\n",
      "     |          print_model_version_info(mv)\n",
      "     |      \n",
      "     |      .. code-block:: text\n",
      "     |          :caption: Output\n",
      "     |      \n",
      "     |          Name: RandomForestRegression\n",
      "     |          Version: 1\n",
      "     |          Tags: {'t': '1', 't1': '2'}\n",
      "     |          --\n",
      "     |          Name: RandomForestRegression\n",
      "     |          Version: 1\n",
      "     |          Tags: {}\n",
      "     |  \n",
      "     |  delete_registered_model(self, name: str)\n",
      "     |      Delete registered model.\n",
      "     |      Backend raises exception if a registered model with given name does not exist.\n",
      "     |      \n",
      "     |      :param name: Name of the registered model to delete.\n",
      "     |      \n",
      "     |      .. code-block:: python\n",
      "     |          :caption: Example\n",
      "     |      \n",
      "     |          import mlflow\n",
      "     |          from mlflow import MlflowClient\n",
      "     |      \n",
      "     |      \n",
      "     |          def print_registered_models_info(r_models):\n",
      "     |              print(\"--\")\n",
      "     |              for rm in r_models:\n",
      "     |                  print(\"name: {}\".format(rm.name))\n",
      "     |                  print(\"tags: {}\".format(rm.tags))\n",
      "     |                  print(\"description: {}\".format(rm.description))\n",
      "     |      \n",
      "     |      \n",
      "     |          mlflow.set_tracking_uri(\"sqlite:///mlruns.db\")\n",
      "     |          client = MlflowClient()\n",
      "     |      \n",
      "     |          # Register a couple of models with respective names, tags, and descriptions\n",
      "     |          for name, tags, desc in [\n",
      "     |              (\"name1\", {\"t1\": \"t1\"}, \"description1\"),\n",
      "     |              (\"name2\", {\"t2\": \"t2\"}, \"description2\"),\n",
      "     |          ]:\n",
      "     |              client.create_registered_model(name, tags, desc)\n",
      "     |      \n",
      "     |          # Fetch all registered models\n",
      "     |          print_registered_models_info(client.search_registered_models())\n",
      "     |      \n",
      "     |          # Delete one registered model and fetch again\n",
      "     |          client.delete_registered_model(\"name1\")\n",
      "     |          print_registered_models_info(client.search_registered_models())\n",
      "     |      \n",
      "     |      .. code-block:: text\n",
      "     |          :caption: Output\n",
      "     |      \n",
      "     |          --\n",
      "     |          name: name1\n",
      "     |          tags: {'t1': 't1'}\n",
      "     |          description: description1\n",
      "     |          name: name2\n",
      "     |          tags: {'t2': 't2'}\n",
      "     |          description: description2\n",
      "     |          --\n",
      "     |          name: name2\n",
      "     |          tags: {'t2': 't2'}\n",
      "     |          description: description2\n",
      "     |  \n",
      "     |  delete_registered_model_tag(self, name: str, key: str) -> None\n",
      "     |      Delete a tag associated with the registered model.\n",
      "     |      \n",
      "     |      :param name: Registered model name.\n",
      "     |      :param key: Registered model tag key.\n",
      "     |      :return: None\n",
      "     |      \n",
      "     |      .. code-block:: python\n",
      "     |          :caption: Example\n",
      "     |      \n",
      "     |          import mlflow\n",
      "     |          from mlflow import MlflowClient\n",
      "     |      \n",
      "     |      \n",
      "     |          def print_registered_models_info(r_models):\n",
      "     |              print(\"--\")\n",
      "     |              for rm in r_models:\n",
      "     |                  print(\"name: {}\".format(rm.name))\n",
      "     |                  print(\"tags: {}\".format(rm.tags))\n",
      "     |      \n",
      "     |      \n",
      "     |          mlflow.set_tracking_uri(\"sqlite:///mlruns.db\")\n",
      "     |          client = MlflowClient()\n",
      "     |      \n",
      "     |          # Register a couple of models with respective names and tags\n",
      "     |          for name, tags in [(\"name1\", {\"t1\": \"t1\"}), (\"name2\", {\"t2\": \"t2\"})]:\n",
      "     |              client.create_registered_model(name, tags)\n",
      "     |      \n",
      "     |          # Fetch all registered models\n",
      "     |          print_registered_models_info(client.search_registered_models())\n",
      "     |      \n",
      "     |          # Delete a tag from model `name2`\n",
      "     |          client.delete_registered_model_tag(\"name2\", \"t2\")\n",
      "     |          print_registered_models_info(client.search_registered_models())\n",
      "     |      \n",
      "     |      .. code-block:: text\n",
      "     |          :caption: Output\n",
      "     |      \n",
      "     |          --\n",
      "     |          name: name1\n",
      "     |          tags: {'t1': 't1'}\n",
      "     |          name: name2\n",
      "     |          tags: {'t2': 't2'}\n",
      "     |          --\n",
      "     |          name: name1\n",
      "     |          tags: {'t1': 't1'}\n",
      "     |          name: name2\n",
      "     |          tags: {}\n",
      "     |  \n",
      "     |  delete_run(self, run_id: str) -> None\n",
      "     |      Deletes a run with the given ID.\n",
      "     |      \n",
      "     |      :param run_id: The unique run id to delete.\n",
      "     |      \n",
      "     |      .. code-block:: python\n",
      "     |          :caption: Example\n",
      "     |      \n",
      "     |          from mlflow import MlflowClient\n",
      "     |      \n",
      "     |          # Create a run under the default experiment (whose id is '0').\n",
      "     |          client = MlflowClient()\n",
      "     |          experiment_id = \"0\"\n",
      "     |          run = client.create_run(experiment_id)\n",
      "     |          run_id = run.info.run_id\n",
      "     |          print(\"run_id: {}; lifecycle_stage: {}\".format(run_id, run.info.lifecycle_stage))\n",
      "     |          print(\"--\")\n",
      "     |          client.delete_run(run_id)\n",
      "     |          del_run = client.get_run(run_id)\n",
      "     |          print(\"run_id: {}; lifecycle_stage: {}\".format(run_id, del_run.info.lifecycle_stage))\n",
      "     |      \n",
      "     |      .. code-block:: text\n",
      "     |          :caption: Output\n",
      "     |      \n",
      "     |          run_id: a61c7a1851324f7094e8d5014c58c8c8; lifecycle_stage: active\n",
      "     |          run_id: a61c7a1851324f7094e8d5014c58c8c8; lifecycle_stage: deleted\n",
      "     |  \n",
      "     |  delete_tag(self, run_id: str, key: str) -> None\n",
      "     |      Delete a tag from a run. This is irreversible.\n",
      "     |      \n",
      "     |      :param run_id: String ID of the run\n",
      "     |      :param key: Name of the tag\n",
      "     |      \n",
      "     |      .. code-block:: python\n",
      "     |          :caption: Example\n",
      "     |      \n",
      "     |          from mlflow import MlflowClient\n",
      "     |      \n",
      "     |      \n",
      "     |          def print_run_info(run):\n",
      "     |              print(\"run_id: {}\".format(run.info.run_id))\n",
      "     |              print(\"Tags: {}\".format(run.data.tags))\n",
      "     |      \n",
      "     |      \n",
      "     |          # Create a run under the default experiment (whose id is '0').\n",
      "     |          client = MlflowClient()\n",
      "     |          tags = {\"t1\": 1, \"t2\": 2}\n",
      "     |          experiment_id = \"0\"\n",
      "     |          run = client.create_run(experiment_id, tags=tags)\n",
      "     |          print_run_info(run)\n",
      "     |          print(\"--\")\n",
      "     |      \n",
      "     |          # Delete tag and fetch updated info\n",
      "     |          client.delete_tag(run.info.run_id, \"t1\")\n",
      "     |          run = client.get_run(run.info.run_id)\n",
      "     |          print_run_info(run)\n",
      "     |      \n",
      "     |      .. code-block:: text\n",
      "     |          :caption: Output\n",
      "     |      \n",
      "     |          run_id: b7077267a59a45d78cd9be0de4bc41f5\n",
      "     |          Tags: {'t2': '2', 't1': '1'}\n",
      "     |          --\n",
      "     |          run_id: b7077267a59a45d78cd9be0de4bc41f5\n",
      "     |          Tags: {'t2': '2'}\n",
      "     |  \n",
      "     |  download_artifacts(self, run_id: str, path: str, dst_path: Optional[str] = None) -> str\n",
      "     |      .. Warning:: ``mlflow.tracking.client.MlflowClient.download_artifacts`` is deprecated since 2.0. This method will be removed in a future release. Use ``mlflow.artifacts.download_artifacts`` instead.\n",
      "     |      \n",
      "     |      Download an artifact file or directory from a run to a local directory if applicable,\n",
      "     |      and return a local path for it.\n",
      "     |      \n",
      "     |      :param run_id: The run to download artifacts from.\n",
      "     |      :param path: Relative source path to the desired artifact.\n",
      "     |      :param dst_path: Absolute path of the local filesystem destination directory to which to\n",
      "     |                       download the specified artifacts. This directory must already exist.\n",
      "     |                       If unspecified, the artifacts will either be downloaded to a new\n",
      "     |                       uniquely-named directory on the local filesystem or will be returned\n",
      "     |                       directly in the case of the LocalArtifactRepository.\n",
      "     |      :return: Local path of desired artifact.\n",
      "     |      \n",
      "     |      .. code-block:: python\n",
      "     |          :caption: Example\n",
      "     |      \n",
      "     |          import os\n",
      "     |          import mlflow\n",
      "     |          from mlflow import MlflowClient\n",
      "     |      \n",
      "     |          features = \"rooms, zipcode, median_price, school_rating, transport\"\n",
      "     |          with open(\"features.txt\", \"w\") as f:\n",
      "     |              f.write(features)\n",
      "     |      \n",
      "     |          # Log artifacts\n",
      "     |          with mlflow.start_run() as run:\n",
      "     |              mlflow.log_artifact(\"features.txt\", artifact_path=\"features\")\n",
      "     |      \n",
      "     |          # Download artifacts\n",
      "     |          client = MlflowClient()\n",
      "     |          local_dir = \"/tmp/artifact_downloads\"\n",
      "     |          if not os.path.exists(local_dir):\n",
      "     |              os.mkdir(local_dir)\n",
      "     |          local_path = client.download_artifacts(run.info.run_id, \"features\", local_dir)\n",
      "     |          print(\"Artifacts downloaded in: {}\".format(local_path))\n",
      "     |          print(\"Artifacts: {}\".format(os.listdir(local_path)))\n",
      "     |      \n",
      "     |      .. code-block:: text\n",
      "     |          :caption: Output\n",
      "     |      \n",
      "     |          Artifacts downloaded in: /tmp/artifact_downloads/features\n",
      "     |          Artifacts: ['features.txt']\n",
      "     |  \n",
      "     |  get_experiment(self, experiment_id: str) -> mlflow.entities.experiment.Experiment\n",
      "     |      Retrieve an experiment by experiment_id from the backend store\n",
      "     |      \n",
      "     |      :param experiment_id: The experiment ID returned from ``create_experiment``.\n",
      "     |      :return: :py:class:`mlflow.entities.Experiment`\n",
      "     |      \n",
      "     |      .. code-block:: python\n",
      "     |          :caption: Example\n",
      "     |      \n",
      "     |          from mlflow import MlflowClient\n",
      "     |      \n",
      "     |          client = MlflowClient()\n",
      "     |          exp_id = client.create_experiment(\"Experiment\")\n",
      "     |          experiment = client.get_experiment(exp_id)\n",
      "     |      \n",
      "     |          # Show experiment info\n",
      "     |          print(\"Name: {}\".format(experiment.name))\n",
      "     |          print(\"Experiment ID: {}\".format(experiment.experiment_id))\n",
      "     |          print(\"Artifact Location: {}\".format(experiment.artifact_location))\n",
      "     |          print(\"Lifecycle_stage: {}\".format(experiment.lifecycle_stage))\n",
      "     |      \n",
      "     |      .. code-block:: text\n",
      "     |          :caption: Output\n",
      "     |      \n",
      "     |          Name: Experiment\n",
      "     |          Experiment ID: 1\n",
      "     |          Artifact Location: file:///.../mlruns/1\n",
      "     |          Lifecycle_stage: active\n",
      "     |  \n",
      "     |  get_experiment_by_name(self, name: str) -> Optional[mlflow.entities.experiment.Experiment]\n",
      "     |      Retrieve an experiment by experiment name from the backend store\n",
      "     |      \n",
      "     |      :param name: The experiment name, which is case sensitive.\n",
      "     |      :return: An instance of :py:class:`mlflow.entities.Experiment`\n",
      "     |               if an experiment with the specified name exists, otherwise None.\n",
      "     |      \n",
      "     |      .. code-block:: python\n",
      "     |          :caption: Example\n",
      "     |      \n",
      "     |          from mlflow import MlflowClient\n",
      "     |      \n",
      "     |          # Case-sensitive name\n",
      "     |          client = MlflowClient()\n",
      "     |          experiment = client.get_experiment_by_name(\"Default\")\n",
      "     |      \n",
      "     |          # Show experiment info\n",
      "     |          print(\"Name: {}\".format(experiment.name))\n",
      "     |          print(\"Experiment ID: {}\".format(experiment.experiment_id))\n",
      "     |          print(\"Artifact Location: {}\".format(experiment.artifact_location))\n",
      "     |          print(\"Lifecycle_stage: {}\".format(experiment.lifecycle_stage))\n",
      "     |      \n",
      "     |      .. code-block:: text\n",
      "     |          :caption: Output\n",
      "     |      \n",
      "     |          Name: Default\n",
      "     |          Experiment ID: 0\n",
      "     |          Artifact Location: file:///.../mlruns/0\n",
      "     |          Lifecycle_stage: active\n",
      "     |  \n",
      "     |  get_latest_versions(self, name: str, stages: List[str] = None) -> List[mlflow.entities.model_registry.model_version.ModelVersion]\n",
      "     |      Latest version models for each requests stage. If no ``stages`` provided, returns the\n",
      "     |      latest version for each stage.\n",
      "     |      \n",
      "     |      :param name: Name of the registered model from which to get the latest versions.\n",
      "     |      :param stages: List of desired stages. If input list is None, return latest versions for\n",
      "     |                     for ALL_STAGES.\n",
      "     |      :return: List of :py:class:`mlflow.entities.model_registry.ModelVersion` objects.\n",
      "     |      \n",
      "     |      .. code-block:: python\n",
      "     |          :caption: Example\n",
      "     |      \n",
      "     |          import mlflow.sklearn\n",
      "     |          from mlflow import MlflowClient\n",
      "     |          from sklearn.ensemble import RandomForestRegressor\n",
      "     |      \n",
      "     |      \n",
      "     |          def print_models_info(mv):\n",
      "     |              for m in mv:\n",
      "     |                  print(\"name: {}\".format(m.name))\n",
      "     |                  print(\"latest version: {}\".format(m.version))\n",
      "     |                  print(\"run_id: {}\".format(m.run_id))\n",
      "     |                  print(\"current_stage: {}\".format(m.current_stage))\n",
      "     |      \n",
      "     |      \n",
      "     |          mlflow.set_tracking_uri(\"sqlite:///mlruns.db\")\n",
      "     |      \n",
      "     |          # Create two runs Log MLflow entities\n",
      "     |          with mlflow.start_run() as run1:\n",
      "     |              params = {\"n_estimators\": 3, \"random_state\": 42}\n",
      "     |              rfr = RandomForestRegressor(**params).fit([[0, 1]], [1])\n",
      "     |              mlflow.log_params(params)\n",
      "     |              mlflow.sklearn.log_model(rfr, artifact_path=\"sklearn-model\")\n",
      "     |      \n",
      "     |          with mlflow.start_run() as run2:\n",
      "     |              params = {\"n_estimators\": 6, \"random_state\": 42}\n",
      "     |              rfr = RandomForestRegressor(**params).fit([[0, 1]], [1])\n",
      "     |              mlflow.log_params(params)\n",
      "     |              mlflow.sklearn.log_model(rfr, artifact_path=\"sklearn-model\")\n",
      "     |      \n",
      "     |          # Register model name in the model registry\n",
      "     |          name = \"RandomForestRegression\"\n",
      "     |          client = MlflowClient()\n",
      "     |          client.create_registered_model(name)\n",
      "     |      \n",
      "     |          # Create a two versions of the rfr model under the registered model name\n",
      "     |          for run_id in [run1.info.run_id, run2.info.run_id]:\n",
      "     |              model_uri = \"runs:/{}/sklearn-model\".format(run_id)\n",
      "     |              mv = client.create_model_version(name, model_uri, run_id)\n",
      "     |              print(\"model version {} created\".format(mv.version))\n",
      "     |      \n",
      "     |          # Fetch latest version; this will be version 2\n",
      "     |          print(\"--\")\n",
      "     |          print_models_info(client.get_latest_versions(name, stages=[\"None\"]))\n",
      "     |      \n",
      "     |      .. code-block:: text\n",
      "     |          :caption: Output\n",
      "     |      \n",
      "     |          model version 1 created\n",
      "     |          model version 2 created\n",
      "     |          --\n",
      "     |          name: RandomForestRegression\n",
      "     |          latest version: 2\n",
      "     |          run_id: 31165664be034dc698c52a4bdeb71663\n",
      "     |          current_stage: None\n",
      "     |  \n",
      "     |  get_metric_history(self, run_id: str, key: str) -> List[mlflow.entities.metric.Metric]\n",
      "     |      Return a list of metric objects corresponding to all values logged for a given metric.\n",
      "     |      \n",
      "     |      :param run_id: Unique identifier for run\n",
      "     |      :param key: Metric name within the run\n",
      "     |      \n",
      "     |      :return: A list of :py:class:`mlflow.entities.Metric` entities if logged, else empty list\n",
      "     |      \n",
      "     |      .. code-block:: python\n",
      "     |          :caption: Example\n",
      "     |      \n",
      "     |          from mlflow import MlflowClient\n",
      "     |      \n",
      "     |      \n",
      "     |          def print_metric_info(history):\n",
      "     |              for m in history:\n",
      "     |                  print(\"name: {}\".format(m.key))\n",
      "     |                  print(\"value: {}\".format(m.value))\n",
      "     |                  print(\"step: {}\".format(m.step))\n",
      "     |                  print(\"timestamp: {}\".format(m.timestamp))\n",
      "     |                  print(\"--\")\n",
      "     |      \n",
      "     |      \n",
      "     |          # Create a run under the default experiment (whose id is \"0\"). Since this is low-level\n",
      "     |          # CRUD operation, the method will create a run. To end the run, you'll have\n",
      "     |          # to explicitly end it.\n",
      "     |          client = MlflowClient()\n",
      "     |          experiment_id = \"0\"\n",
      "     |          run = client.create_run(experiment_id)\n",
      "     |          print(\"run_id: {}\".format(run.info.run_id))\n",
      "     |          print(\"--\")\n",
      "     |      \n",
      "     |          # Log couple of metrics, update their initial value, and fetch each\n",
      "     |          # logged metrics' history.\n",
      "     |          for k, v in [(\"m1\", 1.5), (\"m2\", 2.5)]:\n",
      "     |              client.log_metric(run.info.run_id, k, v, step=0)\n",
      "     |              client.log_metric(run.info.run_id, k, v + 1, step=1)\n",
      "     |              print_metric_info(client.get_metric_history(run.info.run_id, k))\n",
      "     |          client.set_terminated(run.info.run_id)\n",
      "     |      \n",
      "     |      .. code-block:: text\n",
      "     |          :caption: Output\n",
      "     |      \n",
      "     |          run_id: c360d15714994c388b504fe09ea3c234\n",
      "     |          --\n",
      "     |          name: m1\n",
      "     |          value: 1.5\n",
      "     |          step: 0\n",
      "     |          timestamp: 1603423788607\n",
      "     |          --\n",
      "     |          name: m1\n",
      "     |          value: 2.5\n",
      "     |          step: 1\n",
      "     |          timestamp: 1603423788608\n",
      "     |          --\n",
      "     |          name: m2\n",
      "     |          value: 2.5\n",
      "     |          step: 0\n",
      "     |          timestamp: 1603423788609\n",
      "     |          --\n",
      "     |          name: m2\n",
      "     |          value: 3.5\n",
      "     |          step: 1\n",
      "     |          timestamp: 1603423788610\n",
      "     |          --\n",
      "     |  \n",
      "     |  get_model_version(self, name: str, version: str) -> mlflow.entities.model_registry.model_version.ModelVersion\n",
      "     |      :param name: Name of the containing registered model.\n",
      "     |      :param version: Version number as an integer of the model version.\n",
      "     |      :return: A single :py:class:`mlflow.entities.model_registry.ModelVersion` object.\n",
      "     |      \n",
      "     |      .. code-block:: python\n",
      "     |          :caption: Example\n",
      "     |      \n",
      "     |          import mlflow.sklearn\n",
      "     |          from mlflow import MlflowClient\n",
      "     |          from sklearn.ensemble import RandomForestRegressor\n",
      "     |      \n",
      "     |          # Create two runs Log MLflow entities\n",
      "     |          with mlflow.start_run() as run1:\n",
      "     |              params = {\"n_estimators\": 3, \"random_state\": 42}\n",
      "     |              rfr = RandomForestRegressor(**params).fit([[0, 1]], [1])\n",
      "     |              mlflow.log_params(params)\n",
      "     |              mlflow.sklearn.log_model(rfr, artifact_path=\"sklearn-model\")\n",
      "     |      \n",
      "     |          with mlflow.start_run() as run2:\n",
      "     |              params = {\"n_estimators\": 6, \"random_state\": 42}\n",
      "     |              rfr = RandomForestRegressor(**params).fit([[0, 1]], [1])\n",
      "     |              mlflow.log_params(params)\n",
      "     |              mlflow.sklearn.log_model(rfr, artifact_path=\"sklearn-model\")\n",
      "     |      \n",
      "     |          # Register model name in the model registry\n",
      "     |          name = \"RandomForestRegression\"\n",
      "     |          client = MlflowClient()\n",
      "     |          client.create_registered_model(name)\n",
      "     |      \n",
      "     |          # Create a two versions of the rfr model under the registered model name\n",
      "     |          for run_id in [run1.info.run_id, run2.info.run_id]:\n",
      "     |              model_uri = \"runs:/{}/sklearn-model\".format(run_id)\n",
      "     |              mv = client.create_model_version(name, model_uri, run_id)\n",
      "     |              print(\"model version {} created\".format(mv.version))\n",
      "     |          print(\"--\")\n",
      "     |      \n",
      "     |          # Fetch the last version; this will be version 2\n",
      "     |          mv = client.get_model_version(name, mv.version)\n",
      "     |          print_model_version_info(mv)\n",
      "     |      \n",
      "     |      .. code-block:: text\n",
      "     |          :caption: Output\n",
      "     |      \n",
      "     |          model version 1 created\n",
      "     |          model version 2 created\n",
      "     |          --\n",
      "     |          Name: RandomForestRegression\n",
      "     |          Version: 2\n",
      "     |  \n",
      "     |  get_model_version_download_uri(self, name: str, version: str) -> str\n",
      "     |      Get the download location in Model Registry for this model version.\n",
      "     |      \n",
      "     |      :param name: Name of the containing registered model.\n",
      "     |      :param version: Version number as an integer of the model version.\n",
      "     |      :return: A single URI location that allows reads for downloading.\n",
      "     |      \n",
      "     |      .. code-block:: python\n",
      "     |          :caption: Example\n",
      "     |      \n",
      "     |          import mlflow.sklearn\n",
      "     |          from mlflow import MlflowClient\n",
      "     |          from sklearn.ensemble import RandomForestRegressor\n",
      "     |      \n",
      "     |          mlflow.set_tracking_uri(\"sqlite:///mlruns.db\")\n",
      "     |          params = {\"n_estimators\": 3, \"random_state\": 42}\n",
      "     |          name = \"RandomForestRegression\"\n",
      "     |          rfr = RandomForestRegressor(**params).fit([[0, 1]], [1])\n",
      "     |      \n",
      "     |          # Log MLflow entities\n",
      "     |          with mlflow.start_run() as run:\n",
      "     |              mlflow.log_params(params)\n",
      "     |              mlflow.sklearn.log_model(rfr, artifact_path=\"models/sklearn-model\")\n",
      "     |      \n",
      "     |          # Register model name in the model registry\n",
      "     |          client = MlflowClient()\n",
      "     |          client.create_registered_model(name)\n",
      "     |      \n",
      "     |          # Create a new version of the rfr model under the registered model name\n",
      "     |          model_uri = \"runs:/{}/models/sklearn-model\".format(run.info.run_id)\n",
      "     |          mv = client.create_model_version(name, model_uri, run.info.run_id)\n",
      "     |          artifact_uri = client.get_model_version_download_uri(name, mv.version)\n",
      "     |          print(\"Download URI: {}\".format(artifact_uri))\n",
      "     |      \n",
      "     |      .. code-block:: text\n",
      "     |          :caption: Output\n",
      "     |      \n",
      "     |          Download URI: runs:/44e04097ac364cd895f2039eaccca9ac/models/sklearn-model\n",
      "     |  \n",
      "     |  get_model_version_stages(self, name: str, version: str) -> List[str]\n",
      "     |      :return: A list of valid stages.\n",
      "     |      \n",
      "     |      .. code-block:: python\n",
      "     |          :caption: Example\n",
      "     |      \n",
      "     |          import mlflow.sklearn\n",
      "     |          from mlflow import MlflowClient\n",
      "     |          from sklearn.ensemble import RandomForestRegressor\n",
      "     |      \n",
      "     |          mlflow.set_tracking_uri(\"sqlite:///mlruns.db\")\n",
      "     |          params = {\"n_estimators\": 3, \"random_state\": 42}\n",
      "     |          name = \"RandomForestRegression\"\n",
      "     |          rfr = RandomForestRegressor(**params).fit([[0, 1]], [1])\n",
      "     |      \n",
      "     |          # Log MLflow entities\n",
      "     |          with mlflow.start_run() as run:\n",
      "     |              mlflow.log_params(params)\n",
      "     |              mlflow.sklearn.log_model(rfr, artifact_path=\"models/sklearn-model\")\n",
      "     |      \n",
      "     |          # Register model name in the model registry\n",
      "     |          client = MlflowClient()\n",
      "     |          client.create_registered_model(name)\n",
      "     |      \n",
      "     |          # Create a new version of the rfr model under the registered model name\n",
      "     |          # fetch valid stages\n",
      "     |          model_uri = \"runs:/{}/models/sklearn-model\".format(run.info.run_id)\n",
      "     |          mv = client.create_model_version(name, model_uri, run.info.run_id)\n",
      "     |          stages = client.get_model_version_stages(name, mv.version)\n",
      "     |          print(\"Model list of valid stages: {}\".format(stages))\n",
      "     |      \n",
      "     |      .. code-block:: text\n",
      "     |          :caption: Output\n",
      "     |      \n",
      "     |          Model list of valid stages: ['None', 'Staging', 'Production', 'Archived']\n",
      "     |  \n",
      "     |  get_registered_model(self, name: str) -> mlflow.entities.model_registry.registered_model.RegisteredModel\n",
      "     |      :param name: Name of the registered model to get.\n",
      "     |      :return: A single :py:class:`mlflow.entities.model_registry.RegisteredModel` object.\n",
      "     |      \n",
      "     |      .. code-block:: python\n",
      "     |          :caption: Example\n",
      "     |      \n",
      "     |          import mlflow\n",
      "     |          from mlflow import MlflowClient\n",
      "     |      \n",
      "     |      \n",
      "     |          def print_model_info(rm):\n",
      "     |              print(\"--\")\n",
      "     |              print(\"name: {}\".format(rm.name))\n",
      "     |              print(\"tags: {}\".format(rm.tags))\n",
      "     |              print(\"description: {}\".format(rm.description))\n",
      "     |      \n",
      "     |      \n",
      "     |          name = \"SocialMediaTextAnalyzer\"\n",
      "     |          tags = {\"nlp.framework\": \"Spark NLP\"}\n",
      "     |          desc = \"This sentiment analysis model classifies the tone-happy, sad, angry.\"\n",
      "     |          mlflow.set_tracking_uri(\"sqlite:///mlruns.db\")\n",
      "     |          client = MlflowClient()\n",
      "     |      \n",
      "     |          # Create and fetch the registered model\n",
      "     |          client.create_registered_model(name, tags, desc)\n",
      "     |          model = client.get_registered_model(name)\n",
      "     |          print_model_info(model)\n",
      "     |      \n",
      "     |      .. code-block:: text\n",
      "     |          :caption: Output\n",
      "     |      \n",
      "     |          --\n",
      "     |          name: SocialMediaTextAnalyzer\n",
      "     |          tags: {'nlp.framework': 'Spark NLP'}\n",
      "     |          description: This sentiment analysis model classifies the tone-happy, sad, angry.\n",
      "     |  \n",
      "     |  get_run(self, run_id: str) -> mlflow.entities.run.Run\n",
      "     |      Fetch the run from backend store. The resulting :py:class:`Run <mlflow.entities.Run>`\n",
      "     |      contains a collection of run metadata -- :py:class:`RunInfo <mlflow.entities.RunInfo>`,\n",
      "     |      as well as a collection of run parameters, tags, and metrics --\n",
      "     |      :py:class:`RunData <mlflow.entities.RunData>`. In the case where multiple metrics with the\n",
      "     |      same key are logged for the run, the :py:class:`RunData <mlflow.entities.RunData>` contains\n",
      "     |      the most recently logged value at the largest step for each metric.\n",
      "     |      \n",
      "     |      :param run_id: Unique identifier for the run.\n",
      "     |      \n",
      "     |      :return: A single :py:class:`mlflow.entities.Run` object, if the run exists. Otherwise,\n",
      "     |               raises an exception.\n",
      "     |      \n",
      "     |      .. code-block:: python\n",
      "     |          :caption: Example\n",
      "     |      \n",
      "     |          import mlflow\n",
      "     |          from mlflow import MlflowClient\n",
      "     |      \n",
      "     |          with mlflow.start_run() as run:\n",
      "     |              mlflow.log_param(\"p\", 0)\n",
      "     |      \n",
      "     |          # The run has finished since we have exited the with block\n",
      "     |          # Fetch the run\n",
      "     |          client = MlflowClient()\n",
      "     |          run = client.get_run(run.info.run_id)\n",
      "     |          print(\"run_id: {}\".format(run.info.run_id))\n",
      "     |          print(\"params: {}\".format(run.data.params))\n",
      "     |          print(\"status: {}\".format(run.info.status))\n",
      "     |      \n",
      "     |      .. code-block:: text\n",
      "     |          :caption: Output\n",
      "     |      \n",
      "     |          run_id: e36b42c587a1413ead7c3b6764120618\n",
      "     |          params: {'p': '0'}\n",
      "     |          status: FINISHED\n",
      "     |  \n",
      "     |  list_artifacts(self, run_id: str, path=None) -> List[mlflow.entities.file_info.FileInfo]\n",
      "     |      List the artifacts for a run.\n",
      "     |      \n",
      "     |      :param run_id: The run to list artifacts from.\n",
      "     |      :param path: The run's relative artifact path to list from. By default it is set to None\n",
      "     |                   or the root artifact path.\n",
      "     |      :return: List of :py:class:`mlflow.entities.FileInfo`\n",
      "     |      \n",
      "     |      .. code-block:: python\n",
      "     |          :caption: Example\n",
      "     |      \n",
      "     |          from mlflow import MlflowClient\n",
      "     |      \n",
      "     |      \n",
      "     |          def print_artifact_info(artifact):\n",
      "     |              print(\"artifact: {}\".format(artifact.path))\n",
      "     |              print(\"is_dir: {}\".format(artifact.is_dir))\n",
      "     |              print(\"size: {}\".format(artifact.file_size))\n",
      "     |      \n",
      "     |      \n",
      "     |          features = \"rooms zipcode, median_price, school_rating, transport\"\n",
      "     |          labels = \"price\"\n",
      "     |      \n",
      "     |          # Create a run under the default experiment (whose id is '0').\n",
      "     |          client = MlflowClient()\n",
      "     |          experiment_id = \"0\"\n",
      "     |          run = client.create_run(experiment_id)\n",
      "     |      \n",
      "     |          # Create some artifacts and log under the above run\n",
      "     |          for file, content in [(\"features\", features), (\"labels\", labels)]:\n",
      "     |              with open(\"{}.txt\".format(file), \"w\") as f:\n",
      "     |                  f.write(content)\n",
      "     |              client.log_artifact(run.info.run_id, \"{}.txt\".format(file))\n",
      "     |      \n",
      "     |          # Fetch the logged artifacts\n",
      "     |          artifacts = client.list_artifacts(run.info.run_id)\n",
      "     |          for artifact in artifacts:\n",
      "     |              print_artifact_info(artifact)\n",
      "     |          client.set_terminated(run.info.run_id)\n",
      "     |      \n",
      "     |      .. code-block:: text\n",
      "     |          :caption: Output\n",
      "     |      \n",
      "     |          artifact: features.txt\n",
      "     |          is_dir: False\n",
      "     |          size: 53\n",
      "     |          artifact: labels.txt\n",
      "     |          is_dir: False\n",
      "     |          size: 5\n",
      "     |  \n",
      "     |  log_artifact(self, run_id, local_path, artifact_path=None) -> None\n",
      "     |      Write a local file or directory to the remote ``artifact_uri``.\n",
      "     |      \n",
      "     |      :param local_path: Path to the file or directory to write.\n",
      "     |      :param artifact_path: If provided, the directory in ``artifact_uri`` to write to.\n",
      "     |      \n",
      "     |      .. code-block:: python\n",
      "     |          :caption: Example\n",
      "     |      \n",
      "     |          from mlflow import MlflowClient\n",
      "     |      \n",
      "     |          features = \"rooms, zipcode, median_price, school_rating, transport\"\n",
      "     |          with open(\"features.txt\", \"w\") as f:\n",
      "     |              f.write(features)\n",
      "     |      \n",
      "     |          # Create a run under the default experiment (whose id is '0').\n",
      "     |          client = MlflowClient()\n",
      "     |          experiment_id = \"0\"\n",
      "     |          run = client.create_run(experiment_id)\n",
      "     |      \n",
      "     |          # log and fetch the artifact\n",
      "     |          client.log_artifact(run.info.run_id, \"features.txt\")\n",
      "     |          artifacts = client.list_artifacts(run.info.run_id)\n",
      "     |          for artifact in artifacts:\n",
      "     |              print(\"artifact: {}\".format(artifact.path))\n",
      "     |              print(\"is_dir: {}\".format(artifact.is_dir))\n",
      "     |          client.set_terminated(run.info.run_id)\n",
      "     |      \n",
      "     |      .. code-block:: text\n",
      "     |          :caption: Output\n",
      "     |      \n",
      "     |          artifact: features.txt\n",
      "     |          is_dir: False\n",
      "     |  \n",
      "     |  log_artifacts(self, run_id: str, local_dir: str, artifact_path: Optional[str] = None) -> None\n",
      "     |      Write a directory of files to the remote ``artifact_uri``.\n",
      "     |      \n",
      "     |      :param local_dir: Path to the directory of files to write.\n",
      "     |      :param artifact_path: If provided, the directory in ``artifact_uri`` to write to.\n",
      "     |      \n",
      "     |      .. code-block:: python\n",
      "     |          :caption: Example\n",
      "     |      \n",
      "     |          import os\n",
      "     |          import json\n",
      "     |      \n",
      "     |          # Create some artifacts data to preserve\n",
      "     |          features = \"rooms, zipcode, median_price, school_rating, transport\"\n",
      "     |          data = {\"state\": \"TX\", \"Available\": 25, \"Type\": \"Detached\"}\n",
      "     |      \n",
      "     |          # Create couple of artifact files under the local directory \"data\"\n",
      "     |          os.makedirs(\"data\", exist_ok=True)\n",
      "     |          with open(\"data/data.json\", \"w\", encoding=\"utf-8\") as f:\n",
      "     |              json.dump(data, f, indent=2)\n",
      "     |          with open(\"data/features.txt\", \"w\") as f:\n",
      "     |              f.write(features)\n",
      "     |      \n",
      "     |          # Create a run under the default experiment (whose id is '0'), and log\n",
      "     |          # all files in \"data\" to root artifact_uri/states\n",
      "     |          client = MlflowClient()\n",
      "     |          experiment_id = \"0\"\n",
      "     |          run = client.create_run(experiment_id)\n",
      "     |          client.log_artifacts(run.info.run_id, \"data\", artifact_path=\"states\")\n",
      "     |          artifacts = client.list_artifacts(run.info.run_id)\n",
      "     |          for artifact in artifacts:\n",
      "     |              print(\"artifact: {}\".format(artifact.path))\n",
      "     |              print(\"is_dir: {}\".format(artifact.is_dir))\n",
      "     |          client.set_terminated(run.info.run_id)\n",
      "     |      \n",
      "     |      .. code-block:: text\n",
      "     |          :caption: Output\n",
      "     |      \n",
      "     |          artifact: states\n",
      "     |          is_dir: True\n",
      "     |  \n",
      "     |  log_batch(self, run_id: str, metrics: Sequence[mlflow.entities.metric.Metric] = (), params: Sequence[mlflow.entities.param.Param] = (), tags: Sequence[mlflow.entities.run_tag.RunTag] = ()) -> None\n",
      "     |      Log multiple metrics, params, and/or tags.\n",
      "     |      \n",
      "     |      :param run_id: String ID of the run\n",
      "     |      :param metrics: If provided, List of Metric(key, value, timestamp) instances.\n",
      "     |      :param params: If provided, List of Param(key, value) instances.\n",
      "     |      :param tags: If provided, List of RunTag(key, value) instances.\n",
      "     |      \n",
      "     |      Raises an MlflowException if any errors occur.\n",
      "     |      :return: None\n",
      "     |      \n",
      "     |      .. code-block:: python\n",
      "     |          :caption: Example\n",
      "     |      \n",
      "     |          import time\n",
      "     |      \n",
      "     |          from mlflow import MlflowClient\n",
      "     |          from mlflow.entities import Metric, Param, RunTag\n",
      "     |      \n",
      "     |      \n",
      "     |          def print_run_info(r):\n",
      "     |              print(\"run_id: {}\".format(r.info.run_id))\n",
      "     |              print(\"params: {}\".format(r.data.params))\n",
      "     |              print(\"metrics: {}\".format(r.data.metrics))\n",
      "     |              print(\"tags: {}\".format(r.data.tags))\n",
      "     |              print(\"status: {}\".format(r.info.status))\n",
      "     |      \n",
      "     |      \n",
      "     |          # Create MLflow entities and a run under the default experiment (whose id is '0').\n",
      "     |          timestamp = int(time.time() * 1000)\n",
      "     |          metrics = [Metric(\"m\", 1.5, timestamp, 1)]\n",
      "     |          params = [Param(\"p\", \"p\")]\n",
      "     |          tags = [RunTag(\"t\", \"t\")]\n",
      "     |          experiment_id = \"0\"\n",
      "     |          client = MlflowClient()\n",
      "     |          run = client.create_run(experiment_id)\n",
      "     |      \n",
      "     |          # Log entities, terminate the run, and fetch run status\n",
      "     |          client.log_batch(run.info.run_id, metrics=metrics, params=params, tags=tags)\n",
      "     |          client.set_terminated(run.info.run_id)\n",
      "     |          run = client.get_run(run.info.run_id)\n",
      "     |          print_run_info(run)\n",
      "     |      \n",
      "     |      .. code-block:: text\n",
      "     |          :caption: Output\n",
      "     |      \n",
      "     |          run_id: ef0247fa3205410595acc0f30f620871\n",
      "     |          params: {'p': 'p'}\n",
      "     |          metrics: {'m': 1.5}\n",
      "     |          tags: {'t': 't'}\n",
      "     |          status: FINISHED\n",
      "     |  \n",
      "     |  log_dict(self, run_id: str, dictionary: Any, artifact_file: str) -> None\n",
      "     |      Log a JSON/YAML-serializable object (e.g. `dict`) as an artifact. The serialization\n",
      "     |      format (JSON or YAML) is automatically inferred from the extension of `artifact_file`.\n",
      "     |      If the file extension doesn't exist or match any of [\".json\", \".yml\", \".yaml\"],\n",
      "     |      JSON format is used.\n",
      "     |      \n",
      "     |      :param run_id: String ID of the run.\n",
      "     |      :param dictionary: Dictionary to log.\n",
      "     |      :param artifact_file: The run-relative artifact file path in posixpath format to which\n",
      "     |                            the dictionary is saved (e.g. \"dir/data.json\").\n",
      "     |      \n",
      "     |      .. code-block:: python\n",
      "     |          :caption: Example\n",
      "     |      \n",
      "     |          from mlflow import MlflowClient\n",
      "     |      \n",
      "     |          client = MlflowClient()\n",
      "     |          run = client.create_run(experiment_id=\"0\")\n",
      "     |          run_id = run.info.run_id\n",
      "     |      \n",
      "     |          dictionary = {\"k\": \"v\"}\n",
      "     |      \n",
      "     |          # Log a dictionary as a JSON file under the run's root artifact directory\n",
      "     |          client.log_dict(run_id, dictionary, \"data.json\")\n",
      "     |      \n",
      "     |          # Log a dictionary as a YAML file in a subdirectory of the run's root artifact directory\n",
      "     |          client.log_dict(run_id, dictionary, \"dir/data.yml\")\n",
      "     |      \n",
      "     |          # If the file extension doesn't exist or match any of [\".json\", \".yaml\", \".yml\"],\n",
      "     |          # JSON format is used.\n",
      "     |          mlflow.log_dict(run_id, dictionary, \"data\")\n",
      "     |          mlflow.log_dict(run_id, dictionary, \"data.txt\")\n",
      "     |  \n",
      "     |  log_figure(self, run_id: str, figure: Union[ForwardRef('matplotlib.figure.Figure'), ForwardRef('plotly.graph_objects.Figure')], artifact_file: str) -> None\n",
      "     |      Log a figure as an artifact. The following figure objects are supported:\n",
      "     |      \n",
      "     |      - `matplotlib.figure.Figure`_\n",
      "     |      - `plotly.graph_objects.Figure`_\n",
      "     |      \n",
      "     |      .. _matplotlib.figure.Figure:\n",
      "     |          https://matplotlib.org/api/_as_gen/matplotlib.figure.Figure.html\n",
      "     |      \n",
      "     |      .. _plotly.graph_objects.Figure:\n",
      "     |          https://plotly.com/python-api-reference/generated/plotly.graph_objects.Figure.html\n",
      "     |      \n",
      "     |      :param run_id: String ID of the run.\n",
      "     |      :param figure: Figure to log.\n",
      "     |      :param artifact_file: The run-relative artifact file path in posixpath format to which\n",
      "     |                            the figure is saved (e.g. \"dir/file.png\").\n",
      "     |      \n",
      "     |      .. code-block:: python\n",
      "     |          :caption: Matplotlib Example\n",
      "     |      \n",
      "     |          import mlflow\n",
      "     |          import matplotlib.pyplot as plt\n",
      "     |      \n",
      "     |          fig, ax = plt.subplots()\n",
      "     |          ax.plot([0, 1], [2, 3])\n",
      "     |      \n",
      "     |          run = client.create_run(experiment_id=\"0\")\n",
      "     |          client.log_figure(run.info.run_id, fig, \"figure.png\")\n",
      "     |      \n",
      "     |      .. code-block:: python\n",
      "     |          :caption: Plotly Example\n",
      "     |      \n",
      "     |          import mlflow\n",
      "     |          from plotly import graph_objects as go\n",
      "     |      \n",
      "     |          fig = go.Figure(go.Scatter(x=[0, 1], y=[2, 3]))\n",
      "     |      \n",
      "     |          run = client.create_run(experiment_id=\"0\")\n",
      "     |          client.log_figure(run.info.run_id, fig, \"figure.html\")\n",
      "     |  \n",
      "     |  log_image(self, run_id: str, image: Union[ForwardRef('numpy.ndarray'), ForwardRef('PIL.Image.Image')], artifact_file: str) -> None\n",
      "     |      Log an image as an artifact. The following image objects are supported:\n",
      "     |      \n",
      "     |      - `numpy.ndarray`_\n",
      "     |      - `PIL.Image.Image`_\n",
      "     |      \n",
      "     |      .. _numpy.ndarray:\n",
      "     |          https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html\n",
      "     |      \n",
      "     |      .. _PIL.Image.Image:\n",
      "     |          https://pillow.readthedocs.io/en/stable/reference/Image.html#PIL.Image.Image\n",
      "     |      \n",
      "     |      Numpy array support\n",
      "     |          - data type (( ) represents a valid value range):\n",
      "     |      \n",
      "     |              - bool\n",
      "     |              - integer (0 ~ 255)\n",
      "     |              - unsigned integer (0 ~ 255)\n",
      "     |              - float (0.0 ~ 1.0)\n",
      "     |      \n",
      "     |              .. warning::\n",
      "     |      \n",
      "     |                  - Out-of-range integer values will be **clipped** to [0, 255].\n",
      "     |                  - Out-of-range float values will be **clipped** to [0, 1].\n",
      "     |      \n",
      "     |          - shape (H: height, W: width):\n",
      "     |      \n",
      "     |              - H x W (Grayscale)\n",
      "     |              - H x W x 1 (Grayscale)\n",
      "     |              - H x W x 3 (an RGB channel order is assumed)\n",
      "     |              - H x W x 4 (an RGBA channel order is assumed)\n",
      "     |      \n",
      "     |      :param run_id: String ID of the run.\n",
      "     |      :param image: Image to log.\n",
      "     |      :param artifact_file: The run-relative artifact file path in posixpath format to which\n",
      "     |                            the image is saved (e.g. \"dir/image.png\").\n",
      "     |      \n",
      "     |      .. code-block:: python\n",
      "     |          :caption: Numpy Example\n",
      "     |      \n",
      "     |          import mlflow\n",
      "     |          import numpy as np\n",
      "     |      \n",
      "     |          image = np.random.randint(0, 256, size=(100, 100, 3), dtype=np.uint8)\n",
      "     |      \n",
      "     |          run = client.create_run(experiment_id=\"0\")\n",
      "     |          client.log_image(run.info.run_id, image, \"image.png\")\n",
      "     |      \n",
      "     |      .. code-block:: python\n",
      "     |          :caption: Pillow Example\n",
      "     |      \n",
      "     |          import mlflow\n",
      "     |          from PIL import Image\n",
      "     |      \n",
      "     |          image = Image.new(\"RGB\", (100, 100))\n",
      "     |      \n",
      "     |          run = client.create_run(experiment_id=\"0\")\n",
      "     |          client.log_image(run.info.run_id, image, \"image.png\")\n",
      "     |  \n",
      "     |  log_metric(self, run_id: str, key: str, value: float, timestamp: Optional[int] = None, step: Optional[int] = None) -> None\n",
      "     |      Log a metric against the run ID.\n",
      "     |      \n",
      "     |      :param run_id: The run id to which the metric should be logged.\n",
      "     |      :param key: Metric name (string). This string may only contain alphanumerics, underscores\n",
      "     |                  (_), dashes (-), periods (.), spaces ( ), and slashes (/).\n",
      "     |                  All backend stores will support keys up to length 250, but some may\n",
      "     |                  support larger keys.\n",
      "     |      :param value: Metric value (float). Note that some special values such\n",
      "     |                    as +/- Infinity may be replaced by other values depending on the store. For\n",
      "     |                    example, the SQLAlchemy store replaces +/- Inf with max / min float values.\n",
      "     |                    All backend stores will support values up to length 5000, but some\n",
      "     |                    may support larger values.\n",
      "     |      :param timestamp: Time when this metric was calculated. Defaults to the current system time.\n",
      "     |      :param step: Integer training step (iteration) at which was the metric calculated.\n",
      "     |                   Defaults to 0.\n",
      "     |      \n",
      "     |      .. code-block:: python\n",
      "     |          :caption: Example\n",
      "     |      \n",
      "     |          from mlflow import MlflowClient\n",
      "     |      \n",
      "     |      \n",
      "     |          def print_run_info(r):\n",
      "     |              print(\"run_id: {}\".format(r.info.run_id))\n",
      "     |              print(\"metrics: {}\".format(r.data.metrics))\n",
      "     |              print(\"status: {}\".format(r.info.status))\n",
      "     |      \n",
      "     |      \n",
      "     |          # Create a run under the default experiment (whose id is '0').\n",
      "     |          # Since these are low-level CRUD operations, this method will create a run.\n",
      "     |          # To end the run, you'll have to explicitly end it.\n",
      "     |          client = MlflowClient()\n",
      "     |          experiment_id = \"0\"\n",
      "     |          run = client.create_run(experiment_id)\n",
      "     |          print_run_info(run)\n",
      "     |          print(\"--\")\n",
      "     |      \n",
      "     |          # Log the metric. Unlike mlflow.log_metric this method\n",
      "     |          # does not start a run if one does not exist. It will log\n",
      "     |          # the metric for the run id in the backend store.\n",
      "     |          client.log_metric(run.info.run_id, \"m\", 1.5)\n",
      "     |          client.set_terminated(run.info.run_id)\n",
      "     |          run = client.get_run(run.info.run_id)\n",
      "     |          print_run_info(run)\n",
      "     |      \n",
      "     |      .. code-block:: text\n",
      "     |          :caption: Output\n",
      "     |      \n",
      "     |          run_id: 95e79843cb2c463187043d9065185e24\n",
      "     |          metrics: {}\n",
      "     |          status: RUNNING\n",
      "     |          --\n",
      "     |          run_id: 95e79843cb2c463187043d9065185e24\n",
      "     |          metrics: {'m': 1.5}\n",
      "     |          status: FINISHED\n",
      "     |  \n",
      "     |  log_param(self, run_id: str, key: str, value: Any) -> Any\n",
      "     |      Log a parameter (e.g. model hyperparameter) against the run ID.\n",
      "     |      \n",
      "     |      :param run_id: The run id to which the param should be logged.\n",
      "     |      :param key: Parameter name (string). This string may only contain alphanumerics, underscores\n",
      "     |                  (_), dashes (-), periods (.), spaces ( ), and slashes (/).\n",
      "     |                  All backend stores support keys up to length 250, but some may\n",
      "     |                  support larger keys.\n",
      "     |      :param value: Parameter value (string, but will be string-ified if not).\n",
      "     |                    All backend stores support values up to length 500, but some\n",
      "     |                    may support larger values.\n",
      "     |      :return: the parameter value that is logged.\n",
      "     |      \n",
      "     |      .. code-block:: python\n",
      "     |          :caption: Example\n",
      "     |      \n",
      "     |          from mlflow import MlflowClient\n",
      "     |      \n",
      "     |      \n",
      "     |          def print_run_info(r):\n",
      "     |              print(\"run_id: {}\".format(r.info.run_id))\n",
      "     |              print(\"params: {}\".format(r.data.params))\n",
      "     |              print(\"status: {}\".format(r.info.status))\n",
      "     |      \n",
      "     |      \n",
      "     |          # Create a run under the default experiment (whose id is '0').\n",
      "     |          # Since these are low-level CRUD operations, this method will create a run.\n",
      "     |          # To end the run, you'll have to explicitly end it.\n",
      "     |          client = MlflowClient()\n",
      "     |          experiment_id = \"0\"\n",
      "     |          run = client.create_run(experiment_id)\n",
      "     |          print_run_info(run)\n",
      "     |          print(\"--\")\n",
      "     |      \n",
      "     |          # Log the parameter. Unlike mlflow.log_param this method\n",
      "     |          # does not start a run if one does not exist. It will log\n",
      "     |          # the parameter in the backend store\n",
      "     |          p_value = client.log_param(run.info.run_id, \"p\", 1)\n",
      "     |          assert p_value == 1\n",
      "     |          client.set_terminated(run.info.run_id)\n",
      "     |          run = client.get_run(run.info.run_id)\n",
      "     |          print_run_info(run)\n",
      "     |      \n",
      "     |      .. code-block:: text\n",
      "     |          :caption: Output\n",
      "     |      \n",
      "     |          run_id: e649e49c7b504be48ee3ae33c0e76c93\n",
      "     |          params: {}\n",
      "     |          status: RUNNING\n",
      "     |          --\n",
      "     |          run_id: e649e49c7b504be48ee3ae33c0e76c93\n",
      "     |          params: {'p': '1'}\n",
      "     |          status: FINISHED\n",
      "     |  \n",
      "     |  log_text(self, run_id: str, text: str, artifact_file: str) -> None\n",
      "     |      Log text as an artifact.\n",
      "     |      \n",
      "     |      :param run_id: String ID of the run.\n",
      "     |      :param text: String containing text to log.\n",
      "     |      :param artifact_file: The run-relative artifact file path in posixpath format to which\n",
      "     |                            the text is saved (e.g. \"dir/file.txt\").\n",
      "     |      \n",
      "     |      .. code-block:: python\n",
      "     |          :caption: Example\n",
      "     |      \n",
      "     |          from mlflow import MlflowClient\n",
      "     |      \n",
      "     |          client = MlflowClient()\n",
      "     |          run = client.create_run(experiment_id=\"0\")\n",
      "     |      \n",
      "     |          # Log text to a file under the run's root artifact directory\n",
      "     |          client.log_text(run.info.run_id, \"text1\", \"file1.txt\")\n",
      "     |      \n",
      "     |          # Log text in a subdirectory of the run's root artifact directory\n",
      "     |          client.log_text(run.info.run_id, \"text2\", \"dir/file2.txt\")\n",
      "     |      \n",
      "     |          # Log HTML text\n",
      "     |          client.log_text(run.info.run_id, \"<h1>header</h1>\", \"index.html\")\n",
      "     |  \n",
      "     |  rename_experiment(self, experiment_id: str, new_name: str) -> None\n",
      "     |      Update an experiment's name. The new name must be unique.\n",
      "     |      \n",
      "     |      :param experiment_id: The experiment ID returned from ``create_experiment``.\n",
      "     |      \n",
      "     |      .. code-block:: python\n",
      "     |          :caption: Example\n",
      "     |      \n",
      "     |          from mlflow import MlflowClient\n",
      "     |      \n",
      "     |      \n",
      "     |          def print_experiment_info(experiment):\n",
      "     |              print(\"Name: {}\".format(experiment.name))\n",
      "     |              print(\"Experiment_id: {}\".format(experiment.experiment_id))\n",
      "     |              print(\"Lifecycle_stage: {}\".format(experiment.lifecycle_stage))\n",
      "     |      \n",
      "     |      \n",
      "     |          # Create an experiment with a name that is unique and case sensitive\n",
      "     |          client = MlflowClient()\n",
      "     |          experiment_id = client.create_experiment(\"Social NLP Experiments\")\n",
      "     |      \n",
      "     |          # Fetch experiment metadata information\n",
      "     |          experiment = client.get_experiment(experiment_id)\n",
      "     |          print_experiment_info(experiment)\n",
      "     |          print(\"--\")\n",
      "     |      \n",
      "     |          # Rename and fetch experiment metadata information\n",
      "     |          client.rename_experiment(experiment_id, \"Social Media NLP Experiments\")\n",
      "     |          experiment = client.get_experiment(experiment_id)\n",
      "     |          print_experiment_info(experiment)\n",
      "     |      \n",
      "     |      .. code-block:: text\n",
      "     |          :caption: Output\n",
      "     |      \n",
      "     |          Name: Social NLP Experiments\n",
      "     |          Experiment_id: 1\n",
      "     |          Lifecycle_stage: active\n",
      "     |          --\n",
      "     |          Name: Social Media NLP Experiments\n",
      "     |          Experiment_id: 1\n",
      "     |          Lifecycle_stage: active\n",
      "     |  \n",
      "     |  rename_registered_model(self, name: str, new_name: str) -> mlflow.entities.model_registry.registered_model.RegisteredModel\n",
      "     |      Update registered model name.\n",
      "     |      \n",
      "     |      :param name: Name of the registered model to update.\n",
      "     |      :param new_name: New proposed name for the registered model.\n",
      "     |      \n",
      "     |      :return: A single updated :py:class:`mlflow.entities.model_registry.RegisteredModel` object.\n",
      "     |      \n",
      "     |      .. code-block:: python\n",
      "     |          :caption: Example\n",
      "     |      \n",
      "     |          import mlflow\n",
      "     |          from mlflow import MlflowClient\n",
      "     |      \n",
      "     |      \n",
      "     |          def print_registered_model_info(rm):\n",
      "     |              print(\"name: {}\".format(rm.name))\n",
      "     |              print(\"tags: {}\".format(rm.tags))\n",
      "     |              print(\"description: {}\".format(rm.description))\n",
      "     |      \n",
      "     |      \n",
      "     |          name = \"SocialTextAnalyzer\"\n",
      "     |          tags = {\"nlp.framework\": \"Spark NLP\"}\n",
      "     |          desc = \"This sentiment analysis model classifies the tone-happy, sad, angry.\"\n",
      "     |      \n",
      "     |          # create a new registered model name\n",
      "     |          mlflow.set_tracking_uri(\"sqlite:///mlruns.db\")\n",
      "     |          client = MlflowClient()\n",
      "     |          client.create_registered_model(name, tags, desc)\n",
      "     |          print_registered_model_info(client.get_registered_model(name))\n",
      "     |          print(\"--\")\n",
      "     |      \n",
      "     |          # rename the model\n",
      "     |          new_name = \"SocialMediaTextAnalyzer\"\n",
      "     |          client.rename_registered_model(name, new_name)\n",
      "     |          print_registered_model_info(client.get_registered_model(new_name))\n",
      "     |      \n",
      "     |      .. code-block:: text\n",
      "     |          :caption: Output\n",
      "     |      \n",
      "     |          name: SocialTextAnalyzer\n",
      "     |          tags: {'nlp.framework': 'Spark NLP'}\n",
      "     |          description: This sentiment analysis model classifies the tone-happy, sad, angry.\n",
      "     |          --\n",
      "     |          name: SocialMediaTextAnalyzer\n",
      "     |          tags: {'nlp.framework': 'Spark NLP'}\n",
      "     |          description: This sentiment analysis model classifies the tone-happy, sad, angry.\n",
      "     |  \n",
      "     |  restore_experiment(self, experiment_id: str) -> None\n",
      "     |      Restore a deleted experiment unless permanently deleted.\n",
      "     |      \n",
      "     |      :param experiment_id: The experiment ID returned from ``create_experiment``.\n",
      "     |      \n",
      "     |      .. code-block:: python\n",
      "     |          :caption: Example\n",
      "     |      \n",
      "     |          from mlflow import MlflowClient\n",
      "     |      \n",
      "     |      \n",
      "     |          def print_experiment_info(experiment):\n",
      "     |              print(\"Name: {}\".format(experiment.name))\n",
      "     |              print(\"Experiment Id: {}\".format(experiment.experiment_id))\n",
      "     |              print(\"Lifecycle_stage: {}\".format(experiment.lifecycle_stage))\n",
      "     |      \n",
      "     |      \n",
      "     |          # Create and delete an experiment\n",
      "     |          client = MlflowClient()\n",
      "     |          experiment_id = client.create_experiment(\"New Experiment\")\n",
      "     |          client.delete_experiment(experiment_id)\n",
      "     |      \n",
      "     |          # Examine the deleted experiment details.\n",
      "     |          experiment = client.get_experiment(experiment_id)\n",
      "     |          print_experiment_info(experiment)\n",
      "     |          print(\"--\")\n",
      "     |      \n",
      "     |          # Restore the experiment and fetch its info\n",
      "     |          client.restore_experiment(experiment_id)\n",
      "     |          experiment = client.get_experiment(experiment_id)\n",
      "     |          print_experiment_info(experiment)\n",
      "     |      \n",
      "     |      .. code-block:: text\n",
      "     |          :caption: Output\n",
      "     |      \n",
      "     |          Name: New Experiment\n",
      "     |          Experiment Id: 1\n",
      "     |          Lifecycle_stage: deleted\n",
      "     |          --\n",
      "     |          Name: New Experiment\n",
      "     |          Experiment Id: 1\n",
      "     |          Lifecycle_stage: active\n",
      "     |  \n",
      "     |  restore_run(self, run_id: str) -> None\n",
      "     |      Restores a deleted run with the given ID.\n",
      "     |      \n",
      "     |      :param run_id: The unique run id to restore.\n",
      "     |      \n",
      "     |      .. code-block:: python\n",
      "     |          :caption: Example\n",
      "     |      \n",
      "     |          from mlflow import MlflowClient\n",
      "     |      \n",
      "     |          # Create a run under the default experiment (whose id is '0').\n",
      "     |          client = MlflowClient()\n",
      "     |          experiment_id = \"0\"\n",
      "     |          run = client.create_run(experiment_id)\n",
      "     |          run_id = run.info.run_id\n",
      "     |          print(\"run_id: {}; lifecycle_stage: {}\".format(run_id, run.info.lifecycle_stage))\n",
      "     |          client.delete_run(run_id)\n",
      "     |          del_run = client.get_run(run_id)\n",
      "     |          print(\"run_id: {}; lifecycle_stage: {}\".format(run_id, del_run.info.lifecycle_stage))\n",
      "     |          client.restore_run(run_id)\n",
      "     |          rest_run = client.get_run(run_id)\n",
      "     |          print(\"run_id: {}; lifecycle_stage: {}\".format(run_id, rest_run.info.lifecycle_stage))\n",
      "     |      \n",
      "     |      .. code-block:: text\n",
      "     |          :caption: Output\n",
      "     |      \n",
      "     |          run_id: 7bc59754d7e74534a7917d62f2873ac0; lifecycle_stage: active\n",
      "     |          run_id: 7bc59754d7e74534a7917d62f2873ac0; lifecycle_stage: deleted\n",
      "     |          run_id: 7bc59754d7e74534a7917d62f2873ac0; lifecycle_stage: active\n",
      "     |  \n",
      "     |  search_experiments(self, view_type: int = 1, max_results: Optional[int] = 1000, filter_string: Optional[str] = None, order_by: Optional[List[str]] = None, page_token=None) -> mlflow.store.entities.paged_list.PagedList[mlflow.entities.experiment.Experiment]\n",
      "     |      Search for experiments that match the specified search query.\n",
      "     |      \n",
      "     |      :param view_type: One of enum values ``ACTIVE_ONLY``, ``DELETED_ONLY``, or ``ALL``\n",
      "     |                        defined in :py:class:`mlflow.entities.ViewType`.\n",
      "     |      :param max_results: Maximum number of experiments desired. Certain server backend may apply\n",
      "     |                          its own limit.\n",
      "     |      :param filter_string:\n",
      "     |          Filter query string (e.g., ``\"name = 'my_experiment'\"``), defaults to searching for all\n",
      "     |          experiments. The following identifiers, comparators, and logical operators are\n",
      "     |          supported.\n",
      "     |      \n",
      "     |          Identifiers\n",
      "     |            - ``name``: Experiment name\n",
      "     |            - ``creation_time``: Experiment creation time\n",
      "     |            - ``last_update_time``: Experiment last update time\n",
      "     |            - ``tags.<tag_key>``: Experiment tag. If ``tag_key`` contains\n",
      "     |              spaces, it must be wrapped with backticks (e.g., ``\"tags.`extra key`\"``).\n",
      "     |      \n",
      "     |          Comparators for string attributes and tags\n",
      "     |            - ``=``: Equal to\n",
      "     |            - ``!=``: Not equal to\n",
      "     |            - ``LIKE``: Case-sensitive pattern match\n",
      "     |            - ``ILIKE``: Case-insensitive pattern match\n",
      "     |      \n",
      "     |          Comparators for numeric attributes\n",
      "     |            - ``=``: Equal to\n",
      "     |            - ``!=``: Not equal to\n",
      "     |            - ``<``: Less than\n",
      "     |            - ``<=``: Less than or equal to\n",
      "     |            - ``>``: Greater than\n",
      "     |            - ``>=``: Greater than or equal to\n",
      "     |      \n",
      "     |          Logical operators\n",
      "     |            - ``AND``: Combines two sub-queries and returns True if both of them are True.\n",
      "     |      \n",
      "     |      :param order_by:\n",
      "     |          List of columns to order by. The ``order_by`` column can contain an optional ``DESC`` or\n",
      "     |          ``ASC`` value (e.g., ``\"name DESC\"``). The default ordering is ``ASC``, so ``\"name\"`` is\n",
      "     |          equivalent to ``\"name ASC\"``. If unspecified, defaults to ``[\"last_update_time DESC\"]``,\n",
      "     |          which lists experiments updated most recently first. The following fields are supported:\n",
      "     |      \n",
      "     |          - ``experiment_id``: Experiment ID\n",
      "     |          - ``name``: Experiment name\n",
      "     |          - ``creation_time``: Experiment creation time\n",
      "     |          - ``last_update_time``: Experiment last update time\n",
      "     |      \n",
      "     |      :param page_token: Token specifying the next page of results. It should be obtained from\n",
      "     |                         a ``search_experiments`` call.\n",
      "     |      :return: A :py:class:`PagedList <mlflow.store.entities.PagedList>` of\n",
      "     |               :py:class:`Experiment <mlflow.entities.Experiment>` objects. The pagination token\n",
      "     |               for the next page can be obtained via the ``token`` attribute of the object.\n",
      "     |      \n",
      "     |      .. code-block:: python\n",
      "     |          :caption: Example\n",
      "     |      \n",
      "     |          import mlflow\n",
      "     |      \n",
      "     |      \n",
      "     |          def assert_experiment_names_equal(experiments, expected_names):\n",
      "     |              actual_names = [e.name for e in experiments if e.name != \"Default\"]\n",
      "     |              assert actual_names == expected_names, (actual_names, expected_names)\n",
      "     |      \n",
      "     |      \n",
      "     |          mlflow.set_tracking_uri(\"sqlite:///:memory:\")\n",
      "     |          client = mlflow.MlflowClient()\n",
      "     |      \n",
      "     |          # Create experiments\n",
      "     |          for name, tags in [\n",
      "     |              (\"a\", None),\n",
      "     |              (\"b\", None),\n",
      "     |              (\"ab\", {\"k\": \"v\"}),\n",
      "     |              (\"bb\", {\"k\": \"V\"}),\n",
      "     |          ]:\n",
      "     |              client.create_experiment(name, tags=tags)\n",
      "     |      \n",
      "     |          # Search for experiments with name \"a\"\n",
      "     |          experiments = client.search_experiments(filter_string=\"name = 'a'\")\n",
      "     |          assert_experiment_names_equal(experiments, [\"a\"])\n",
      "     |      \n",
      "     |          # Search for experiments with name starting with \"a\"\n",
      "     |          experiments = client.search_experiments(filter_string=\"name LIKE 'a%'\")\n",
      "     |          assert_experiment_names_equal(experiments, [\"ab\", \"a\"])\n",
      "     |      \n",
      "     |          # Search for experiments with tag key \"k\" and value ending with \"v\" or \"V\"\n",
      "     |          experiments = client.search_experiments(filter_string=\"tags.k ILIKE '%v'\")\n",
      "     |          assert_experiment_names_equal(experiments, [\"bb\", \"ab\"])\n",
      "     |      \n",
      "     |          # Search for experiments with name ending with \"b\" and tag {\"k\": \"v\"}\n",
      "     |          experiments = client.search_experiments(filter_string=\"name LIKE '%b' AND tags.k = 'v'\")\n",
      "     |          assert_experiment_names_equal(experiments, [\"ab\"])\n",
      "     |      \n",
      "     |          # Sort experiments by name in ascending order\n",
      "     |          experiments = client.search_experiments(order_by=[\"name\"])\n",
      "     |          assert_experiment_names_equal(experiments, [\"a\", \"ab\", \"b\", \"bb\"])\n",
      "     |      \n",
      "     |          # Sort experiments by ID in descending order\n",
      "     |          experiments = client.search_experiments(order_by=[\"experiment_id DESC\"])\n",
      "     |          assert_experiment_names_equal(experiments, [\"bb\", \"ab\", \"b\", \"a\"])\n",
      "     |  \n",
      "     |  search_model_versions(self, filter_string: Optional[str] = None, max_results: int = 10000, order_by: Optional[List[str]] = None, page_token: Optional[str] = None) -> mlflow.store.entities.paged_list.PagedList[mlflow.entities.model_registry.model_version.ModelVersion]\n",
      "     |      Search for model versions in backend that satisfy the filter criteria.\n",
      "     |      \n",
      "     |      :param filter_string: Filter query string\n",
      "     |          (e.g., ``\"name = 'a_model_name' and tag.key = 'value1'\"``),\n",
      "     |          defaults to searching for all model versions. The following identifiers, comparators,\n",
      "     |          and logical operators are supported.\n",
      "     |      \n",
      "     |          Identifiers\n",
      "     |            - ``name``: model name.\n",
      "     |            - ``source_path``: model version source path.\n",
      "     |            - ``run_id``: The id of the mlflow run that generates the model version.\n",
      "     |            - ``tags.<tag_key>``: model version tag. If ``tag_key`` contains spaces, it must be\n",
      "     |              wrapped with backticks (e.g., ``\"tags.`extra key`\"``).\n",
      "     |      \n",
      "     |          Comparators\n",
      "     |            - ``=``: Equal to.\n",
      "     |            - ``!=``: Not equal to.\n",
      "     |            - ``LIKE``: Case-sensitive pattern match.\n",
      "     |            - ``ILIKE``: Case-insensitive pattern match.\n",
      "     |            - ``IN``: In a value list. Only ``run_id`` identifier supports ``IN`` comparator.\n",
      "     |      \n",
      "     |          Logical operators\n",
      "     |            - ``AND``: Combines two sub-queries and returns True if both of them are True.\n",
      "     |      \n",
      "     |      :param max_results: Maximum number of model versions desired.\n",
      "     |      :param order_by: List of column names with ASC|DESC annotation, to be used for ordering\n",
      "     |                       matching search results.\n",
      "     |      :param page_token: Token specifying the next page of results. It should be obtained from\n",
      "     |                          a ``search_model_versions`` call.\n",
      "     |      :return: A PagedList of :py:class:`mlflow.entities.model_registry.ModelVersion`\n",
      "     |               objects that satisfy the search expressions. The pagination token for the next\n",
      "     |               page can be obtained via the ``token`` attribute of the object.\n",
      "     |      \n",
      "     |      .. code-block:: python\n",
      "     |          :caption: Example\n",
      "     |      \n",
      "     |          import mlflow\n",
      "     |          from mlflow import MlflowClient\n",
      "     |      \n",
      "     |          client = MlflowClient()\n",
      "     |      \n",
      "     |          # Get all versions of the model filtered by name\n",
      "     |          model_name = \"CordobaWeatherForecastModel\"\n",
      "     |          filter_string = \"name='{}'\".format(model_name)\n",
      "     |          results = client.search_model_versions(filter_string)\n",
      "     |          print(\"-\" * 80)\n",
      "     |          for res in results:\n",
      "     |              print(\"name={}; run_id={}; version={}\".format(res.name, res.run_id, res.version))\n",
      "     |      \n",
      "     |          # Get the version of the model filtered by run_id\n",
      "     |          run_id = \"e14afa2f47a040728060c1699968fd43\"\n",
      "     |          filter_string = \"run_id='{}'\".format(run_id)\n",
      "     |          results = client.search_model_versions(filter_string)\n",
      "     |          print(\"-\" * 80)\n",
      "     |          for res in results:\n",
      "     |              print(\"name={}; run_id={}; version={}\".format(res.name, res.run_id, res.version))\n",
      "     |      \n",
      "     |      .. code-block:: text\n",
      "     |          :caption: Output\n",
      "     |      \n",
      "     |          ------------------------------------------------------------------------------------\n",
      "     |          name=CordobaWeatherForecastModel; run_id=eaef868ee3d14d10b4299c4c81ba8814; version=1\n",
      "     |          name=CordobaWeatherForecastModel; run_id=e14afa2f47a040728060c1699968fd43; version=2\n",
      "     |          ------------------------------------------------------------------------------------\n",
      "     |          name=CordobaWeatherForecastModel; run_id=e14afa2f47a040728060c1699968fd43; version=2\n",
      "     |  \n",
      "     |  search_registered_models(self, filter_string: Optional[str] = None, max_results: int = 100, order_by: Optional[List[str]] = None, page_token: Optional[str] = None) -> mlflow.store.entities.paged_list.PagedList[mlflow.entities.model_registry.registered_model.RegisteredModel]\n",
      "     |      Search for registered models in backend that satisfy the filter criteria.\n",
      "     |      \n",
      "     |      :param filter_string: Filter query string\n",
      "     |          (e.g., ``\"name = 'a_model_name' and tag.key = 'value1'\"``),\n",
      "     |          defaults to searching for all registered models. The following identifiers, comparators,\n",
      "     |          and logical operators are supported.\n",
      "     |      \n",
      "     |          Identifiers\n",
      "     |            - ``name``: registered model name.\n",
      "     |            - ``tags.<tag_key>``: registered model tag. If ``tag_key`` contains spaces, it must be\n",
      "     |              wrapped with backticks (e.g., ``\"tags.`extra key`\"``).\n",
      "     |      \n",
      "     |          Comparators\n",
      "     |            - ``=``: Equal to.\n",
      "     |            - ``!=``: Not equal to.\n",
      "     |            - ``LIKE``: Case-sensitive pattern match.\n",
      "     |            - ``ILIKE``: Case-insensitive pattern match.\n",
      "     |      \n",
      "     |          Logical operators\n",
      "     |            - ``AND``: Combines two sub-queries and returns True if both of them are True.\n",
      "     |      \n",
      "     |      :param max_results: Maximum number of registered models desired.\n",
      "     |      :param order_by: List of column names with ASC|DESC annotation, to be used for ordering\n",
      "     |                       matching search results.\n",
      "     |      :param page_token: Token specifying the next page of results. It should be obtained from\n",
      "     |                          a ``search_registered_models`` call.\n",
      "     |      :return: A PagedList of :py:class:`mlflow.entities.model_registry.RegisteredModel` objects\n",
      "     |              that satisfy the search expressions. The pagination token for the next page can be\n",
      "     |              obtained via the ``token`` attribute of the object.\n",
      "     |      \n",
      "     |      .. code-block:: python\n",
      "     |          :caption: Example\n",
      "     |      \n",
      "     |          import mlflow\n",
      "     |          from mlflow import MlflowClient\n",
      "     |      \n",
      "     |          client = MlflowClient()\n",
      "     |      \n",
      "     |          # Get search results filtered by the registered model name\n",
      "     |          model_name = \"CordobaWeatherForecastModel\"\n",
      "     |          filter_string = \"name='{}'\".format(model_name)\n",
      "     |          results = client.search_registered_models(filter_string=filter_string)\n",
      "     |          print(\"-\" * 80)\n",
      "     |          for res in results:\n",
      "     |              for mv in res.latest_versions:\n",
      "     |                  print(\"name={}; run_id={}; version={}\".format(mv.name, mv.run_id, mv.version))\n",
      "     |      \n",
      "     |          # Get search results filtered by the registered model name that matches\n",
      "     |          # prefix pattern\n",
      "     |          filter_string = \"name LIKE 'Boston%'\"\n",
      "     |          results = client.search_registered_models(filter_string=filter_string)\n",
      "     |          print(\"-\" * 80)\n",
      "     |          for res in results:\n",
      "     |              for mv in res.latest_versions:\n",
      "     |                  print(\"name={}; run_id={}; version={}\".format(mv.name, mv.run_id, mv.version))\n",
      "     |      \n",
      "     |          # Get all registered models and order them by ascending order of the names\n",
      "     |          results = client.search_registered_models(order_by=[\"name ASC\"])\n",
      "     |          print(\"-\" * 80)\n",
      "     |          for res in results:\n",
      "     |              for mv in res.latest_versions:\n",
      "     |                  print(\"name={}; run_id={}; version={}\".format(mv.name, mv.run_id, mv.version))\n",
      "     |      \n",
      "     |      .. code-block:: text\n",
      "     |          :caption: Output\n",
      "     |      \n",
      "     |          ------------------------------------------------------------------------------------\n",
      "     |          name=CordobaWeatherForecastModel; run_id=eaef868ee3d14d10b4299c4c81ba8814; version=1\n",
      "     |          name=CordobaWeatherForecastModel; run_id=e14afa2f47a040728060c1699968fd43; version=2\n",
      "     |          ------------------------------------------------------------------------------------\n",
      "     |          name=BostonWeatherForecastModel; run_id=ddc51b9407a54b2bb795c8d680e63ff6; version=1\n",
      "     |          name=BostonWeatherForecastModel; run_id=48ac94350fba40639a993e1b3d4c185d; version=2\n",
      "     |          -----------------------------------------------------------------------------------\n",
      "     |          name=AzureWeatherForecastModel; run_id=5fcec6c4f1c947fc9295fef3fa21e52d; version=1\n",
      "     |          name=AzureWeatherForecastModel; run_id=8198cb997692417abcdeb62e99052260; version=3\n",
      "     |          name=BostonWeatherForecastModel; run_id=ddc51b9407a54b2bb795c8d680e63ff6; version=1\n",
      "     |          name=BostonWeatherForecastModel; run_id=48ac94350fba40639a993e1b3d4c185d; version=2\n",
      "     |          name=CordobaWeatherForecastModel; run_id=eaef868ee3d14d10b4299c4c81ba8814; version=1\n",
      "     |          name=CordobaWeatherForecastModel; run_id=e14afa2f47a040728060c1699968fd43; version=2\n",
      "     |  \n",
      "     |  search_runs(self, experiment_ids: List[str], filter_string: str = '', run_view_type: int = 1, max_results: int = 1000, order_by: Optional[List[str]] = None, page_token: Optional[str] = None) -> mlflow.store.entities.paged_list.PagedList[mlflow.entities.run.Run]\n",
      "     |      Search for Runs that fit the specified criteria.\n",
      "     |      \n",
      "     |      :param experiment_ids: List of experiment IDs, or a single int or string id.\n",
      "     |      :param filter_string: Filter query string, defaults to searching all runs.\n",
      "     |      :param run_view_type: one of enum values ACTIVE_ONLY, DELETED_ONLY, or ALL runs\n",
      "     |                            defined in :py:class:`mlflow.entities.ViewType`.\n",
      "     |      :param max_results: Maximum number of runs desired.\n",
      "     |      :param order_by: List of columns to order by (e.g., \"metrics.rmse\"). The ``order_by`` column\n",
      "     |                   can contain an optional ``DESC`` or ``ASC`` value. The default is ``ASC``.\n",
      "     |                   The default ordering is to sort by ``start_time DESC``, then ``run_id``.\n",
      "     |      :param page_token: Token specifying the next page of results. It should be obtained from\n",
      "     |          a ``search_runs`` call.\n",
      "     |      \n",
      "     |      :return: A :py:class:`PagedList <mlflow.store.entities.PagedList>` of\n",
      "     |          :py:class:`Run <mlflow.entities.Run>` objects that satisfy the search expressions.\n",
      "     |          If the underlying tracking store supports pagination, the token for the next page may\n",
      "     |          be obtained via the ``token`` attribute of the returned object.\n",
      "     |      \n",
      "     |      .. code-block:: python\n",
      "     |          :caption: Example\n",
      "     |      \n",
      "     |          import mlflow\n",
      "     |          from mlflow import MlflowClient\n",
      "     |          from mlflow.entities import ViewType\n",
      "     |      \n",
      "     |      \n",
      "     |          def print_run_info(runs):\n",
      "     |              for r in runs:\n",
      "     |                  print(\"run_id: {}\".format(r.info.run_id))\n",
      "     |                  print(\"lifecycle_stage: {}\".format(r.info.lifecycle_stage))\n",
      "     |                  print(\"metrics: {}\".format(r.data.metrics))\n",
      "     |      \n",
      "     |                  # Exclude mlflow system tags\n",
      "     |                  tags = {k: v for k, v in r.data.tags.items() if not k.startswith(\"mlflow.\")}\n",
      "     |                  print(\"tags: {}\".format(tags))\n",
      "     |      \n",
      "     |      \n",
      "     |          # Create an experiment and log two runs with metrics and tags under the experiment\n",
      "     |          experiment_id = mlflow.create_experiment(\"Social NLP Experiments\")\n",
      "     |          with mlflow.start_run(experiment_id=experiment_id) as run:\n",
      "     |              mlflow.log_metric(\"m\", 1.55)\n",
      "     |              mlflow.set_tag(\"s.release\", \"1.1.0-RC\")\n",
      "     |          with mlflow.start_run(experiment_id=experiment_id):\n",
      "     |              mlflow.log_metric(\"m\", 2.50)\n",
      "     |              mlflow.set_tag(\"s.release\", \"1.2.0-GA\")\n",
      "     |      \n",
      "     |          # Search all runs under experiment id and order them by\n",
      "     |          # descending value of the metric 'm'\n",
      "     |          client = MlflowClient()\n",
      "     |          runs = client.search_runs(experiment_id, order_by=[\"metrics.m DESC\"])\n",
      "     |          print_run_info(runs)\n",
      "     |          print(\"--\")\n",
      "     |      \n",
      "     |          # Delete the first run\n",
      "     |          client.delete_run(run_id=run.info.run_id)\n",
      "     |      \n",
      "     |          # Search only deleted runs under the experiment id and use a case insensitive pattern\n",
      "     |          # in the filter_string for the tag.\n",
      "     |          filter_string = \"tags.s.release ILIKE '%rc%'\"\n",
      "     |          runs = client.search_runs(\n",
      "     |              experiment_id, run_view_type=ViewType.DELETED_ONLY, filter_string=filter_string\n",
      "     |          )\n",
      "     |          print_run_info(runs)\n",
      "     |      \n",
      "     |      .. code-block:: text\n",
      "     |          :caption: Output\n",
      "     |      \n",
      "     |          run_id: 0efb2a68833d4ee7860a964fad31cb3f\n",
      "     |          lifecycle_stage: active\n",
      "     |          metrics: {'m': 2.5}\n",
      "     |          tags: {'s.release': '1.2.0-GA'}\n",
      "     |          run_id: 7ab027fd72ee4527a5ec5eafebb923b8\n",
      "     |          lifecycle_stage: active\n",
      "     |          metrics: {'m': 1.55}\n",
      "     |          tags: {'s.release': '1.1.0-RC'}\n",
      "     |          --\n",
      "     |          run_id: 7ab027fd72ee4527a5ec5eafebb923b8\n",
      "     |          lifecycle_stage: deleted\n",
      "     |          metrics: {'m': 1.55}\n",
      "     |          tags: {'s.release': '1.1.0-RC'}\n",
      "     |  \n",
      "     |  set_experiment_tag(self, experiment_id: str, key: str, value: Any) -> None\n",
      "     |      Set a tag on the experiment with the specified ID. Value is converted to a string.\n",
      "     |      \n",
      "     |      :param experiment_id: String ID of the experiment.\n",
      "     |      :param key: Name of the tag.\n",
      "     |      :param value: Tag value (converted to a string).\n",
      "     |      \n",
      "     |      .. code-block:: python\n",
      "     |          :caption: Example\n",
      "     |      \n",
      "     |          from mlflow import MlflowClient\n",
      "     |      \n",
      "     |          # Create an experiment and set its tag\n",
      "     |          client = MlflowClient()\n",
      "     |          experiment_id = client.create_experiment(\"Social Media NLP Experiments\")\n",
      "     |          client.set_experiment_tag(experiment_id, \"nlp.framework\", \"Spark NLP\")\n",
      "     |      \n",
      "     |          # Fetch experiment metadata information\n",
      "     |          experiment = client.get_experiment(experiment_id)\n",
      "     |          print(\"Name: {}\".format(experiment.name))\n",
      "     |          print(\"Tags: {}\".format(experiment.tags))\n",
      "     |      \n",
      "     |      .. code-block:: text\n",
      "     |          :caption: Output\n",
      "     |      \n",
      "     |          Name: Social Media NLP Experiments\n",
      "     |          Tags: {'nlp.framework': 'Spark NLP'}\n",
      "     |  \n",
      "     |  set_model_version_tag(self, name: str, version: str = None, key: str = None, value: Any = None, stage: str = None) -> None\n",
      "     |      Set a tag for the model version.\n",
      "     |      When stage is set, tag will be set for latest model version of the stage.\n",
      "     |      Setting both version and stage parameter will result in error.\n",
      "     |      \n",
      "     |      :param name: Registered model name.\n",
      "     |      :param version: Registered model version.\n",
      "     |      :param key: Tag key to log. key is required.\n",
      "     |      :param value: Tag value to log. value is required.\n",
      "     |      :param stage: Registered model stage.\n",
      "     |      :return: None\n",
      "     |      \n",
      "     |      .. code-block:: python\n",
      "     |          :caption: Example\n",
      "     |      \n",
      "     |          import mlflow.sklearn\n",
      "     |          from mlflow import MlflowClient\n",
      "     |          from sklearn.ensemble import RandomForestRegressor\n",
      "     |      \n",
      "     |      \n",
      "     |          def print_model_version_info(mv):\n",
      "     |              print(\"Name: {}\".format(mv.name))\n",
      "     |              print(\"Version: {}\".format(mv.version))\n",
      "     |              print(\"Tags: {}\".format(mv.tags))\n",
      "     |      \n",
      "     |      \n",
      "     |          mlflow.set_tracking_uri(\"sqlite:///mlruns.db\")\n",
      "     |          params = {\"n_estimators\": 3, \"random_state\": 42}\n",
      "     |          name = \"RandomForestRegression\"\n",
      "     |          rfr = RandomForestRegressor(**params).fit([[0, 1]], [1])\n",
      "     |      \n",
      "     |          # Log MLflow entities\n",
      "     |          with mlflow.start_run() as run:\n",
      "     |              mlflow.log_params(params)\n",
      "     |              mlflow.sklearn.log_model(rfr, artifact_path=\"sklearn-model\")\n",
      "     |      \n",
      "     |          # Register model name in the model registry\n",
      "     |          client = MlflowClient()\n",
      "     |          client.create_registered_model(name)\n",
      "     |      \n",
      "     |          # Create a new version of the rfr model under the registered model name\n",
      "     |          # and set a tag\n",
      "     |          model_uri = \"runs:/{}/sklearn-model\".format(run.info.run_id)\n",
      "     |          mv = client.create_model_version(name, model_uri, run.info.run_id)\n",
      "     |          print_model_version_info(mv)\n",
      "     |          print(\"--\")\n",
      "     |      \n",
      "     |          # Tag using model version\n",
      "     |          client.set_model_version_tag(name, mv.version, \"t\", \"1\")\n",
      "     |      \n",
      "     |          # Tag using model stage\n",
      "     |          client.set_model_version_tag(name, key=\"t1\", value=\"1\", stage=mv.current_stage)\n",
      "     |      \n",
      "     |          mv = client.get_model_version(name, mv.version)\n",
      "     |          print_model_version_info(mv)\n",
      "     |      \n",
      "     |      .. code-block:: text\n",
      "     |          :caption: Output\n",
      "     |      \n",
      "     |          Name: RandomForestRegression\n",
      "     |          Version: 1\n",
      "     |          Tags: {}\n",
      "     |          --\n",
      "     |          Name: RandomForestRegression\n",
      "     |          Version: 1\n",
      "     |          Tags: {'t': '1', 't1': '1'}\n",
      "     |  \n",
      "     |  set_registered_model_tag(self, name, key, value) -> None\n",
      "     |      Set a tag for the registered model.\n",
      "     |      \n",
      "     |      :param name: Registered model name.\n",
      "     |      :param key: Tag key to log.\n",
      "     |      :param value: Tag value log.\n",
      "     |      :return: None\n",
      "     |      \n",
      "     |      .. code-block:: Python\n",
      "     |          :caption: Example\n",
      "     |      \n",
      "     |          import mlflow\n",
      "     |          from mlflow import MlflowClient\n",
      "     |      \n",
      "     |          def print_model_info(rm):\n",
      "     |              print(\"--\")\n",
      "     |              print(\"name: {}\".format(rm.name))\n",
      "     |              print(\"tags: {}\".format(rm.tags))\n",
      "     |      \n",
      "     |          name = \"SocialMediaTextAnalyzer\"\n",
      "     |          tags = {\"nlp.framework1\": \"Spark NLP\"}\n",
      "     |          mlflow.set_tracking_uri(\"sqlite:///mlruns.db\")\n",
      "     |          client = MlflowClient()\n",
      "     |      \n",
      "     |          # Create registered model, set an additional tag, and fetch\n",
      "     |          # update model info\n",
      "     |          client.create_registered_model(name, tags, desc)\n",
      "     |          model = client.get_registered_model(name)\n",
      "     |          print_model_info(model)\n",
      "     |      \n",
      "     |          client.set_registered_model_tag(name, \"nlp.framework2\", \"VADER\")\n",
      "     |          model = client.get_registered_model(name)\n",
      "     |          print_model_info(model)\n",
      "     |      \n",
      "     |      .. code-block:: text\n",
      "     |          :caption: Output\n",
      "     |      \n",
      "     |          --\n",
      "     |          name: SocialMediaTextAnalyzer\n",
      "     |          tags: {'nlp.framework1': 'Spark NLP'}\n",
      "     |          --\n",
      "     |          name: SocialMediaTextAnalyzer\n",
      "     |          tags: {'nlp.framework1': 'Spark NLP', 'nlp.framework2': 'VADER'}\n",
      "     |  \n",
      "     |  set_tag(self, run_id: str, key: str, value: Any) -> None\n",
      "     |      Set a tag on the run with the specified ID. Value is converted to a string.\n",
      "     |      \n",
      "     |      :param run_id: String ID of the run.\n",
      "     |      :param key: Tag name (string). This string may only contain alphanumerics,\n",
      "     |                  underscores (_), dashes (-), periods (.), spaces ( ), and slashes (/).\n",
      "     |                  All backend stores will support keys up to length 250, but some may\n",
      "     |                  support larger keys.\n",
      "     |      :param value: Tag value (string, but will be string-ified if not).\n",
      "     |                    All backend stores will support values up to length 5000, but some\n",
      "     |                    may support larger values.\n",
      "     |      \n",
      "     |      .. code-block:: python\n",
      "     |          :caption: Example\n",
      "     |      \n",
      "     |          from mlflow import MlflowClient\n",
      "     |      \n",
      "     |      \n",
      "     |          def print_run_info(run):\n",
      "     |              print(\"run_id: {}\".format(run.info.run_id))\n",
      "     |              print(\"Tags: {}\".format(run.data.tags))\n",
      "     |      \n",
      "     |      \n",
      "     |          # Create a run under the default experiment (whose id is '0').\n",
      "     |          client = MlflowClient()\n",
      "     |          experiment_id = \"0\"\n",
      "     |          run = client.create_run(experiment_id)\n",
      "     |          print_run_info(run)\n",
      "     |          print(\"--\")\n",
      "     |      \n",
      "     |          # Set a tag and fetch updated run info\n",
      "     |          client.set_tag(run.info.run_id, \"nlp.framework\", \"Spark NLP\")\n",
      "     |          run = client.get_run(run.info.run_id)\n",
      "     |          print_run_info(run)\n",
      "     |      \n",
      "     |      .. code-block:: text\n",
      "     |          :caption: Output\n",
      "     |      \n",
      "     |          run_id: 4f226eb5758145e9b28f78514b59a03b\n",
      "     |          Tags: {}\n",
      "     |          --\n",
      "     |          run_id: 4f226eb5758145e9b28f78514b59a03b\n",
      "     |          Tags: {'nlp.framework': 'Spark NLP'}\n",
      "     |  \n",
      "     |  set_terminated(self, run_id: str, status: Optional[str] = None, end_time: Optional[int] = None) -> None\n",
      "     |      Set a run's status to terminated.\n",
      "     |      \n",
      "     |      :param status: A string value of :py:class:`mlflow.entities.RunStatus`.\n",
      "     |                     Defaults to \"FINISHED\".\n",
      "     |      :param end_time: If not provided, defaults to the current time.\n",
      "     |      \n",
      "     |      .. code-block:: python\n",
      "     |          :caption: Example\n",
      "     |      \n",
      "     |          from mlflow import MlflowClient\n",
      "     |      \n",
      "     |      \n",
      "     |          def print_run_info(r):\n",
      "     |              print(\"run_id: {}\".format(r.info.run_id))\n",
      "     |              print(\"status: {}\".format(r.info.status))\n",
      "     |      \n",
      "     |      \n",
      "     |          # Create a run under the default experiment (whose id is '0').\n",
      "     |          # Since this is low-level CRUD operation, this method will create a run.\n",
      "     |          # To end the run, you'll have to explicitly terminate it.\n",
      "     |          client = MlflowClient()\n",
      "     |          experiment_id = \"0\"\n",
      "     |          run = client.create_run(experiment_id)\n",
      "     |          print_run_info(run)\n",
      "     |          print(\"--\")\n",
      "     |      \n",
      "     |          # Terminate the run and fetch updated status. By default,\n",
      "     |          # the status is set to \"FINISHED\". Other values you can\n",
      "     |          # set are \"KILLED\", \"FAILED\", \"RUNNING\", or \"SCHEDULED\".\n",
      "     |          client.set_terminated(run.info.run_id, status=\"KILLED\")\n",
      "     |          run = client.get_run(run.info.run_id)\n",
      "     |          print_run_info(run)\n",
      "     |      \n",
      "     |      .. code-block:: text\n",
      "     |          :caption: Output\n",
      "     |      \n",
      "     |          run_id: 575fb62af83f469e84806aee24945973\n",
      "     |          status: RUNNING\n",
      "     |          --\n",
      "     |          run_id: 575fb62af83f469e84806aee24945973\n",
      "     |          status: KILLED\n",
      "     |  \n",
      "     |  transition_model_version_stage(self, name: str, version: str, stage: str, archive_existing_versions: bool = False) -> mlflow.entities.model_registry.model_version.ModelVersion\n",
      "     |      Update model version stage.\n",
      "     |      \n",
      "     |      :param name: Registered model name.\n",
      "     |      :param version: Registered model version.\n",
      "     |      :param stage: New desired stage for this model version.\n",
      "     |      :param archive_existing_versions: If this flag is set to ``True``, all existing model\n",
      "     |          versions in the stage will be automatically moved to the \"archived\" stage. Only valid\n",
      "     |          when ``stage`` is ``\"staging\"`` or ``\"production\"`` otherwise an error will be raised.\n",
      "     |      \n",
      "     |      :return: A single :py:class:`mlflow.entities.model_registry.ModelVersion` object.\n",
      "     |      \n",
      "     |      .. code-block:: python\n",
      "     |          :caption: Example\n",
      "     |      \n",
      "     |          import mlflow.sklearn\n",
      "     |          from mlflow import MlflowClient\n",
      "     |          from sklearn.ensemble import RandomForestRegressor\n",
      "     |      \n",
      "     |      \n",
      "     |          def print_model_version_info(mv):\n",
      "     |              print(\"Name: {}\".format(mv.name))\n",
      "     |              print(\"Version: {}\".format(mv.version))\n",
      "     |              print(\"Description: {}\".format(mv.description))\n",
      "     |              print(\"Stage: {}\".format(mv.current_stage))\n",
      "     |      \n",
      "     |      \n",
      "     |          mlflow.set_tracking_uri(\"sqlite:///mlruns.db\")\n",
      "     |          params = {\"n_estimators\": 3, \"random_state\": 42}\n",
      "     |          name = \"RandomForestRegression\"\n",
      "     |          desc = \"A new version of the model using ensemble trees\"\n",
      "     |          rfr = RandomForestRegressor(**params).fit([[0, 1]], [1])\n",
      "     |      \n",
      "     |          # Log MLflow entities\n",
      "     |          with mlflow.start_run() as run:\n",
      "     |              mlflow.log_params(params)\n",
      "     |              mlflow.sklearn.log_model(rfr, artifact_path=\"sklearn-model\")\n",
      "     |      \n",
      "     |          # Register model name in the model registry\n",
      "     |          client = MlflowClient()\n",
      "     |          client.create_registered_model(name)\n",
      "     |      \n",
      "     |          # Create a new version of the rfr model under the registered model name\n",
      "     |          model_uri = \"runs:/{}/sklearn-model\".format(run.info.run_id)\n",
      "     |          mv = client.create_model_version(name, model_uri, run.info.run_id, description=desc)\n",
      "     |          print_model_version_info(mv)\n",
      "     |          print(\"--\")\n",
      "     |      \n",
      "     |          # transition model version from None -> staging\n",
      "     |          mv = client.transition_model_version_stage(name, mv.version, \"staging\")\n",
      "     |          print_model_version_info(mv)\n",
      "     |      \n",
      "     |      .. code-block:: text\n",
      "     |          :caption: Output\n",
      "     |      \n",
      "     |          Name: RandomForestRegression\n",
      "     |          Version: 1\n",
      "     |          Description: A new version of the model using ensemble trees\n",
      "     |          Stage: None\n",
      "     |          --\n",
      "     |          Name: RandomForestRegression\n",
      "     |          Version: 1\n",
      "     |          Description: A new version of the model using ensemble trees\n",
      "     |          Stage: Staging\n",
      "     |  \n",
      "     |  update_model_version(self, name: str, version: str, description: Optional[str] = None) -> mlflow.entities.model_registry.model_version.ModelVersion\n",
      "     |      Update metadata associated with a model version in backend.\n",
      "     |      \n",
      "     |      :param name: Name of the containing registered model.\n",
      "     |      :param version: Version number of the model version.\n",
      "     |      :param description: New description.\n",
      "     |      \n",
      "     |      :return: A single :py:class:`mlflow.entities.model_registry.ModelVersion` object.\n",
      "     |      \n",
      "     |      .. code-block:: python\n",
      "     |          :caption: Example\n",
      "     |      \n",
      "     |          import mlflow.sklearn\n",
      "     |          from mlflow import MlflowClient\n",
      "     |          from sklearn.ensemble import RandomForestRegressor\n",
      "     |      \n",
      "     |      \n",
      "     |          def print_model_version_info(mv):\n",
      "     |              print(\"Name: {}\".format(mv.name))\n",
      "     |              print(\"Version: {}\".format(mv.version))\n",
      "     |              print(\"Description: {}\".format(mv.description))\n",
      "     |      \n",
      "     |      \n",
      "     |          mlflow.set_tracking_uri(\"sqlite:///mlruns.db\")\n",
      "     |          params = {\"n_estimators\": 3, \"random_state\": 42}\n",
      "     |          name = \"RandomForestRegression\"\n",
      "     |          rfr = RandomForestRegressor(**params).fit([[0, 1]], [1])\n",
      "     |      \n",
      "     |          # Log MLflow entities\n",
      "     |          with mlflow.start_run() as run:\n",
      "     |              mlflow.log_params(params)\n",
      "     |              mlflow.sklearn.log_model(rfr, artifact_path=\"sklearn-model\")\n",
      "     |      \n",
      "     |          # Register model name in the model registry\n",
      "     |          client = MlflowClient()\n",
      "     |          client.create_registered_model(name)\n",
      "     |      \n",
      "     |          # Create a new version of the rfr model under the registered model name\n",
      "     |          model_uri = \"runs:/{}/sklearn-model\".format(run.info.run_id)\n",
      "     |          mv = client.create_model_version(name, model_uri, run.info.run_id)\n",
      "     |          print_model_version_info(mv)\n",
      "     |          print(\"--\")\n",
      "     |      \n",
      "     |          # Update model version's description\n",
      "     |          desc = \"A new version of the model using ensemble trees\"\n",
      "     |          mv = client.update_model_version(name, mv.version, desc)\n",
      "     |          print_model_version_info(mv)\n",
      "     |      \n",
      "     |      .. code-block:: text\n",
      "     |          :caption: Output\n",
      "     |      \n",
      "     |          Name: RandomForestRegression\n",
      "     |          Version: 1\n",
      "     |          Description: None\n",
      "     |          --\n",
      "     |          Name: RandomForestRegression\n",
      "     |          Version: 1\n",
      "     |          Description: A new version of the model using ensemble trees\n",
      "     |  \n",
      "     |  update_registered_model(self, name: str, description: Optional[str] = None) -> mlflow.entities.model_registry.registered_model.RegisteredModel\n",
      "     |      Updates metadata for RegisteredModel entity. Input field ``description`` should be non-None.\n",
      "     |      Backend raises exception if a registered model with given name does not exist.\n",
      "     |      \n",
      "     |      :param name: Name of the registered model to update.\n",
      "     |      :param description: (Optional) New description.\n",
      "     |      :return: A single updated :py:class:`mlflow.entities.model_registry.RegisteredModel` object.\n",
      "     |      \n",
      "     |      .. code-block:: python\n",
      "     |          :caption: Example\n",
      "     |      \n",
      "     |          def print_registered_model_info(rm):\n",
      "     |              print(\"name: {}\".format(rm.name))\n",
      "     |              print(\"tags: {}\".format(rm.tags))\n",
      "     |              print(\"description: {}\".format(rm.description))\n",
      "     |      \n",
      "     |      \n",
      "     |          name = \"SocialMediaTextAnalyzer\"\n",
      "     |          tags = {\"nlp.framework\": \"Spark NLP\"}\n",
      "     |          desc = \"This sentiment analysis model classifies the tone-happy, sad, angry.\"\n",
      "     |      \n",
      "     |          mlflow.set_tracking_uri(\"sqlite:///mlruns.db\")\n",
      "     |          client = MlflowClient()\n",
      "     |          client.create_registered_model(name, tags, desc)\n",
      "     |          print_registered_model_info(client.get_registered_model(name))\n",
      "     |          print(\"--\")\n",
      "     |      \n",
      "     |          # Update the model's description\n",
      "     |          desc = \"This sentiment analysis model classifies tweets' tone: happy, sad, angry.\"\n",
      "     |          client.update_registered_model(name, desc)\n",
      "     |          print_registered_model_info(client.get_registered_model(name))\n",
      "     |      \n",
      "     |      .. code-block:: text\n",
      "     |          :caption: Output\n",
      "     |      \n",
      "     |          name: SocialMediaTextAnalyzer\n",
      "     |          tags: {'nlp.framework': 'Spark NLP'}\n",
      "     |          description: This sentiment analysis model classifies the tone-happy, sad, angry.\n",
      "     |          --\n",
      "     |          name: SocialMediaTextAnalyzer\n",
      "     |          tags: {'nlp.framework': 'Spark NLP'}\n",
      "     |          description: This sentiment analysis model classifies tweets' tone: happy, sad, angry.\n",
      "     |  \n",
      "     |  update_run(self, run_id: str, status: Optional[str] = None, name: Optional[str] = None) -> None\n",
      "     |      Update a run with the specified ID to a new status or name.\n",
      "     |      \n",
      "     |      :param run_id: The ID of the Run to update.\n",
      "     |      :param status: The new status of the run to set, if specified.\n",
      "     |                     At least one of ``status`` or ``name`` should be specified.\n",
      "     |      :param name: The new name of the run to set, if specified.\n",
      "     |                   At least one of ``name`` or ``status`` should be specified.\n",
      "     |      \n",
      "     |      .. code-block:: python\n",
      "     |          :caption: Example\n",
      "     |      \n",
      "     |          from mlflow import MlflowClient\n",
      "     |      \n",
      "     |      \n",
      "     |          def print_run_info(run):\n",
      "     |              print(\"run_id: {}\".format(run.info.run_id))\n",
      "     |              print(\"run_name: {}\".format(run.info.run_name))\n",
      "     |              print(\"status: {}\".format(run.info.status))\n",
      "     |      \n",
      "     |      \n",
      "     |          # Create a run under the default experiment (whose id is '0').\n",
      "     |          client = MlflowClient()\n",
      "     |          experiment_id = \"0\"\n",
      "     |          run = client.create_run(experiment_id)\n",
      "     |          print_run_info(run)\n",
      "     |          print(\"--\")\n",
      "     |      \n",
      "     |          # Update run and fetch info\n",
      "     |          client.update_run(run.info.run_id, \"FINISHED\", \"new_name\")\n",
      "     |          run = client.get_run(run.info.run_id)\n",
      "     |          print_run_info(run)\n",
      "     |      \n",
      "     |      .. code-block:: text\n",
      "     |          :caption: Output\n",
      "     |      \n",
      "     |          run_id: 1cf6bf8bf6484dd8a598bd43be367b20\n",
      "     |          run_name: judicious-hog-915\n",
      "     |          status: RUNNING\n",
      "     |          --\n",
      "     |          run_id: 1cf6bf8bf6484dd8a598bd43be367b20\n",
      "     |          run_name: new_name\n",
      "     |          status: FINISHED\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Readonly properties defined here:\n",
      "     |  \n",
      "     |  tracking_uri\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors defined here:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "    \n",
      "    class MlflowException(builtins.Exception)\n",
      "     |  MlflowException(message, error_code=1, **kwargs)\n",
      "     |  \n",
      "     |  Generic exception thrown to surface failure information about external-facing operations.\n",
      "     |  The error message associated with this exception may be exposed to clients in HTTP responses\n",
      "     |  for debugging purposes. If the error text is sensitive, raise a generic `Exception` object\n",
      "     |  instead.\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      MlflowException\n",
      "     |      builtins.Exception\n",
      "     |      builtins.BaseException\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __init__(self, message, error_code=1, **kwargs)\n",
      "     |      :param message: The message or exception describing the error that occurred. This will be\n",
      "     |                      included in the exception's serialized JSON representation.\n",
      "     |      :param error_code: An appropriate error code for the error that occurred; it will be\n",
      "     |                         included in the exception's serialized JSON representation. This should\n",
      "     |                         be one of the codes listed in the `mlflow.protos.databricks_pb2` proto.\n",
      "     |      :param kwargs: Additional key-value pairs to include in the serialized JSON representation\n",
      "     |                     of the MlflowException.\n",
      "     |  \n",
      "     |  get_http_status_code(self)\n",
      "     |  \n",
      "     |  serialize_as_json(self)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Class methods defined here:\n",
      "     |  \n",
      "     |  invalid_parameter_value(message, **kwargs) from builtins.type\n",
      "     |      Constructs an `MlflowException` object with the `INVALID_PARAMETER_VALUE` error code.\n",
      "     |      \n",
      "     |      :param message: The message describing the error that occurred. This will be included in the\n",
      "     |                      exception's serialized JSON representation.\n",
      "     |      :param kwargs: Additional key-value pairs to include in the serialized JSON representation\n",
      "     |                     of the MlflowException.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors defined here:\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Static methods inherited from builtins.Exception:\n",
      "     |  \n",
      "     |  __new__(*args, **kwargs) from builtins.type\n",
      "     |      Create and return a new object.  See help(type) for accurate signature.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from builtins.BaseException:\n",
      "     |  \n",
      "     |  __delattr__(self, name, /)\n",
      "     |      Implement delattr(self, name).\n",
      "     |  \n",
      "     |  __getattribute__(self, name, /)\n",
      "     |      Return getattr(self, name).\n",
      "     |  \n",
      "     |  __reduce__(...)\n",
      "     |      Helper for pickle.\n",
      "     |  \n",
      "     |  __repr__(self, /)\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  __setattr__(self, name, value, /)\n",
      "     |      Implement setattr(self, name, value).\n",
      "     |  \n",
      "     |  __setstate__(...)\n",
      "     |  \n",
      "     |  __str__(self, /)\n",
      "     |      Return str(self).\n",
      "     |  \n",
      "     |  with_traceback(...)\n",
      "     |      Exception.with_traceback(tb) --\n",
      "     |      set self.__traceback__ to tb and return self.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from builtins.BaseException:\n",
      "     |  \n",
      "     |  __cause__\n",
      "     |      exception cause\n",
      "     |  \n",
      "     |  __context__\n",
      "     |      exception context\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |  \n",
      "     |  __suppress_context__\n",
      "     |  \n",
      "     |  __traceback__\n",
      "     |  \n",
      "     |  args\n",
      "\n",
      "FUNCTIONS\n",
      "    active_run() -> Optional[mlflow.tracking.fluent.ActiveRun]\n",
      "        Get the currently active ``Run``, or None if no such run exists.\n",
      "        \n",
      "        **Note**: You cannot access currently-active run attributes\n",
      "        (parameters, metrics, etc.) through the run returned by ``mlflow.active_run``. In order\n",
      "        to access such attributes, use the :py:class:`mlflow.client.MlflowClient` as follows:\n",
      "        \n",
      "        .. test-code-block:: python\n",
      "            :caption: Example\n",
      "        \n",
      "            import mlflow\n",
      "        \n",
      "            mlflow.start_run()\n",
      "            run = mlflow.active_run()\n",
      "            print(\"Active run_id: {}\".format(run.info.run_id))\n",
      "            mlflow.end_run()\n",
      "        \n",
      "        .. code-block:: text\n",
      "            :caption: Output\n",
      "        \n",
      "            Active run_id: 6f252757005748708cd3aad75d1ff462\n",
      "    \n",
      "    autolog(log_input_examples: bool = False, log_model_signatures: bool = True, log_models: bool = True, disable: bool = False, exclusive: bool = False, disable_for_unsupported_versions: bool = False, silent: bool = False) -> None\n",
      "        Enables (or disables) and configures autologging for all supported integrations.\n",
      "        \n",
      "        The parameters are passed to any autologging integrations that support them.\n",
      "        \n",
      "        See the :ref:`tracking docs <automatic-logging>` for a list of supported autologging\n",
      "        integrations.\n",
      "        \n",
      "        Note that framework-specific configurations set at any point will take precedence over\n",
      "        any configurations set by this function. For example:\n",
      "        \n",
      "        .. test-code-block:: python\n",
      "        \n",
      "            import mlflow\n",
      "        \n",
      "            mlflow.autolog(log_models=False, exclusive=True)\n",
      "            import sklearn\n",
      "        \n",
      "        would enable autologging for `sklearn` with `log_models=False` and `exclusive=True`,\n",
      "        but\n",
      "        \n",
      "        .. test-code-block:: python\n",
      "        \n",
      "            import mlflow\n",
      "        \n",
      "            mlflow.autolog(log_models=False, exclusive=True)\n",
      "        \n",
      "            import sklearn\n",
      "        \n",
      "            mlflow.sklearn.autolog(log_models=True)\n",
      "        \n",
      "        would enable autologging for `sklearn` with `log_models=True` and `exclusive=False`,\n",
      "        the latter resulting from the default value for `exclusive` in `mlflow.sklearn.autolog`;\n",
      "        other framework autolog functions (e.g. `mlflow.tensorflow.autolog`) would use the\n",
      "        configurations set by `mlflow.autolog` (in this instance, `log_models=False`, `exclusive=True`),\n",
      "        until they are explicitly called by the user.\n",
      "        \n",
      "        :param log_input_examples: If ``True``, input examples from training datasets are collected and\n",
      "                                   logged along with model artifacts during training. If ``False``,\n",
      "                                   input examples are not logged.\n",
      "                                   Note: Input examples are MLflow model attributes\n",
      "                                   and are only collected if ``log_models`` is also ``True``.\n",
      "        :param log_model_signatures: If ``True``,\n",
      "                                     :py:class:`ModelSignatures <mlflow.models.ModelSignature>`\n",
      "                                     describing model inputs and outputs are collected and logged along\n",
      "                                     with model artifacts during training. If ``False``, signatures are\n",
      "                                     not logged. Note: Model signatures are MLflow model attributes\n",
      "                                     and are only collected if ``log_models`` is also ``True``.\n",
      "        :param log_models: If ``True``, trained models are logged as MLflow model artifacts.\n",
      "                           If ``False``, trained models are not logged.\n",
      "                           Input examples and model signatures, which are attributes of MLflow models,\n",
      "                           are also omitted when ``log_models`` is ``False``.\n",
      "        :param disable: If ``True``, disables all supported autologging integrations. If ``False``,\n",
      "                        enables all supported autologging integrations.\n",
      "        :param exclusive: If ``True``, autologged content is not logged to user-created fluent runs.\n",
      "                          If ``False``, autologged content is logged to the active fluent run,\n",
      "                          which may be user-created.\n",
      "        :param disable_for_unsupported_versions: If ``True``, disable autologging for versions of\n",
      "                          all integration libraries that have not been tested against this version\n",
      "                          of the MLflow client or are incompatible.\n",
      "        :param silent: If ``True``, suppress all event logs and warnings from MLflow during autologging\n",
      "                       setup and training execution. If ``False``, show all events and warnings during\n",
      "                       autologging setup and training execution.\n",
      "        \n",
      "        .. test-code-block:: python\n",
      "            :caption: Example\n",
      "        \n",
      "            import numpy as np\n",
      "            import mlflow.sklearn\n",
      "            from mlflow import MlflowClient\n",
      "            from sklearn.linear_model import LinearRegression\n",
      "        \n",
      "        \n",
      "            def print_auto_logged_info(r):\n",
      "                tags = {k: v for k, v in r.data.tags.items() if not k.startswith(\"mlflow.\")}\n",
      "                artifacts = [f.path for f in MlflowClient().list_artifacts(r.info.run_id, \"model\")]\n",
      "                print(\"run_id: {}\".format(r.info.run_id))\n",
      "                print(\"artifacts: {}\".format(artifacts))\n",
      "                print(\"params: {}\".format(r.data.params))\n",
      "                print(\"metrics: {}\".format(r.data.metrics))\n",
      "                print(\"tags: {}\".format(tags))\n",
      "        \n",
      "        \n",
      "            # prepare training data\n",
      "            X = np.array([[1, 1], [1, 2], [2, 2], [2, 3]])\n",
      "            y = np.dot(X, np.array([1, 2])) + 3\n",
      "        \n",
      "            # Auto log all the parameters, metrics, and artifacts\n",
      "            mlflow.autolog()\n",
      "            model = LinearRegression()\n",
      "            with mlflow.start_run() as run:\n",
      "                model.fit(X, y)\n",
      "        \n",
      "            # fetch the auto logged parameters and metrics for ended run\n",
      "            print_auto_logged_info(mlflow.get_run(run_id=run.info.run_id))\n",
      "        \n",
      "        .. code-block:: text\n",
      "            :caption: Output\n",
      "        \n",
      "            run_id: fd10a17d028c47399a55ab8741721ef7\n",
      "            artifacts: ['model/MLmodel', 'model/conda.yaml', 'model/model.pkl']\n",
      "            params: {'copy_X': 'True',\n",
      "                     'normalize': 'False',\n",
      "                     'fit_intercept': 'True',\n",
      "                     'n_jobs': 'None'}\n",
      "            metrics: {'training_score': 1.0,\n",
      "                      'training_root_mean_squared_error': 4.440892098500626e-16,\n",
      "                      'training_r2_score': 1.0,\n",
      "                      'training_mean_absolute_error': 2.220446049250313e-16,\n",
      "                      'training_mean_squared_error': 1.9721522630525295e-31}\n",
      "            tags: {'estimator_class': 'sklearn.linear_model._base.LinearRegression',\n",
      "                   'estimator_name': 'LinearRegression'}\n",
      "    \n",
      "    create_experiment(name: str, artifact_location: Optional[str] = None, tags: Optional[Dict[str, Any]] = None) -> str\n",
      "        Create an experiment.\n",
      "        \n",
      "        :param name: The experiment name, which must be unique and is case sensitive\n",
      "        :param artifact_location: The location to store run artifacts.\n",
      "                                  If not provided, the server picks an appropriate default.\n",
      "        :param tags: An optional dictionary of string keys and values to set as\n",
      "                                tags on the experiment.\n",
      "        :return: String ID of the created experiment.\n",
      "        \n",
      "        .. test-code-block:: python\n",
      "            :caption: Example\n",
      "        \n",
      "            import mlflow\n",
      "            from pathlib import Path\n",
      "        \n",
      "            # Create an experiment name, which must be unique and case sensitive\n",
      "            experiment_id = mlflow.create_experiment(\n",
      "                \"Social NLP Experiments\",\n",
      "                artifact_location=Path.cwd().joinpath(\"mlruns\").as_uri(),\n",
      "                tags={\"version\": \"v1\", \"priority\": \"P1\"},\n",
      "            )\n",
      "            experiment = mlflow.get_experiment(experiment_id)\n",
      "            print(\"Name: {}\".format(experiment.name))\n",
      "            print(\"Experiment_id: {}\".format(experiment.experiment_id))\n",
      "            print(\"Artifact Location: {}\".format(experiment.artifact_location))\n",
      "            print(\"Tags: {}\".format(experiment.tags))\n",
      "            print(\"Lifecycle_stage: {}\".format(experiment.lifecycle_stage))\n",
      "            print(\"Creation timestamp: {}\".format(experiment.creation_time))\n",
      "        \n",
      "        .. code-block:: text\n",
      "            :caption: Output\n",
      "        \n",
      "            Name: Social NLP Experiments\n",
      "            Experiment_id: 1\n",
      "            Artifact Location: file:///.../mlruns\n",
      "            Tags: {'version': 'v1', 'priority': 'P1'}\n",
      "            Lifecycle_stage: active\n",
      "            Creation timestamp: 1662004217511\n",
      "    \n",
      "    delete_experiment(experiment_id: str) -> None\n",
      "        Delete an experiment from the backend store.\n",
      "        \n",
      "        :param experiment_id: The The string-ified experiment ID returned from ``create_experiment``.\n",
      "        \n",
      "        .. test-code-block:: python\n",
      "            :caption: Example\n",
      "        \n",
      "            import mlflow\n",
      "        \n",
      "            experiment_id = mlflow.create_experiment(\"New Experiment\")\n",
      "            mlflow.delete_experiment(experiment_id)\n",
      "        \n",
      "            # Examine the deleted experiment details.\n",
      "            experiment = mlflow.get_experiment(experiment_id)\n",
      "            print(\"Name: {}\".format(experiment.name))\n",
      "            print(\"Artifact Location: {}\".format(experiment.artifact_location))\n",
      "            print(\"Lifecycle_stage: {}\".format(experiment.lifecycle_stage))\n",
      "            print(\"Last Updated timestamp: {}\".format(experiment.last_update_time))\n",
      "        .. code-block:: text\n",
      "            :caption: Output\n",
      "        \n",
      "            Name: New Experiment\n",
      "            Artifact Location: file:///.../mlruns/2\n",
      "            Lifecycle_stage: deleted\n",
      "            Last Updated timestamp: 1662004217511\n",
      "    \n",
      "    delete_run(run_id: str) -> None\n",
      "        Deletes a run with the given ID.\n",
      "        \n",
      "        :param run_id: Unique identifier for the run to delete.\n",
      "        \n",
      "        .. test-code-block:: python\n",
      "            :caption: Example\n",
      "        \n",
      "            import mlflow\n",
      "        \n",
      "            with mlflow.start_run() as run:\n",
      "                mlflow.log_param(\"p\", 0)\n",
      "        \n",
      "            run_id = run.info.run_id\n",
      "            mlflow.delete_run(run_id)\n",
      "        \n",
      "            print(\n",
      "                \"run_id: {}; lifecycle_stage: {}\".format(\n",
      "                    run_id, mlflow.get_run(run_id).info.lifecycle_stage\n",
      "                )\n",
      "            )\n",
      "        \n",
      "        .. code-block:: text\n",
      "            :caption: Output\n",
      "        \n",
      "            run_id: 45f4af3e6fd349e58579b27fcb0b8277; lifecycle_stage: deleted\n",
      "    \n",
      "    delete_tag(key: str) -> None\n",
      "        Delete a tag from a run. This is irreversible. If no run is active, this method\n",
      "        will create a new active run.\n",
      "        \n",
      "        :param key: Name of the tag\n",
      "        \n",
      "        .. test-code-block:: python\n",
      "            :caption: Example\n",
      "        \n",
      "            import mlflow\n",
      "        \n",
      "            tags = {\"engineering\": \"ML Platform\", \"engineering_remote\": \"ML Platform\"}\n",
      "        \n",
      "            with mlflow.start_run() as run:\n",
      "                mlflow.set_tags(tags)\n",
      "        \n",
      "            with mlflow.start_run(run_id=run.info.run_id):\n",
      "                mlflow.delete_tag(\"engineering_remote\")\n",
      "    \n",
      "    doctor(mask_envs=False)\n",
      "        Prints out useful information for debugging issues with MLflow.\n",
      "        \n",
      "        :param mask_envs: If True, mask the MLflow environment variable values\n",
      "                          (e.g. `\"MLFLOW_ENV_VAR\": \"***\"`) in the output to prevent leaking sensitive\n",
      "                          information.\n",
      "        \n",
      "        .. warning::\n",
      "        \n",
      "            - This API should only be used for debugging purposes.\n",
      "            - The output may contain sensitive information such as a database URI containing a password.\n",
      "        \n",
      "        .. code-block:: python\n",
      "            :caption: Example\n",
      "        \n",
      "            import mlflow\n",
      "        \n",
      "            with mlflow.start_run():\n",
      "                mlflow.doctor()\n",
      "        \n",
      "        .. code-block:: text\n",
      "            :caption: Output\n",
      "        \n",
      "            System information: Linux #58~20.04.1-Ubuntu SMP Thu Oct 13 13:09:46 UTC 2022\n",
      "            Python version: 3.8.13\n",
      "            MLflow version: 2.0.1\n",
      "            MLflow module location: /usr/local/lib/python3.8/site-packages/mlflow/__init__.py\n",
      "            Tracking URI: sqlite:///mlflow.db\n",
      "            Registry URI: sqlite:///mlflow.db\n",
      "            MLflow environment variables:\n",
      "              MLFLOW_TRACKING_URI: sqlite:///mlflow.db\n",
      "            MLflow dependencies:\n",
      "              Flask: 2.2.2\n",
      "              Jinja2: 3.0.3\n",
      "              alembic: 1.8.1\n",
      "              click: 8.1.3\n",
      "              cloudpickle: 2.2.0\n",
      "              databricks-cli: 0.17.4.dev0\n",
      "              docker: 6.0.0\n",
      "              entrypoints: 0.4\n",
      "              gitpython: 3.1.29\n",
      "              gunicorn: 20.1.0\n",
      "              importlib-metadata: 5.0.0\n",
      "              markdown: 3.4.1\n",
      "              matplotlib: 3.6.1\n",
      "              numpy: 1.23.4\n",
      "              packaging: 21.3\n",
      "              pandas: 1.5.1\n",
      "              protobuf: 3.19.6\n",
      "              pyarrow: 9.0.0\n",
      "              pytz: 2022.6\n",
      "              pyyaml: 6.0\n",
      "              querystring-parser: 1.2.4\n",
      "              requests: 2.28.1\n",
      "              scikit-learn: 1.1.3\n",
      "              scipy: 1.9.3\n",
      "              shap: 0.41.0\n",
      "              sqlalchemy: 1.4.42\n",
      "              sqlparse: 0.4.3\n",
      "    \n",
      "    end_run(status: str = 'FINISHED') -> None\n",
      "        End an active MLflow run (if there is one).\n",
      "        \n",
      "        .. test-code-block:: python\n",
      "            :caption: Example\n",
      "        \n",
      "            import mlflow\n",
      "        \n",
      "            # Start run and get status\n",
      "            mlflow.start_run()\n",
      "            run = mlflow.active_run()\n",
      "            print(\"run_id: {}; status: {}\".format(run.info.run_id, run.info.status))\n",
      "        \n",
      "            # End run and get status\n",
      "            mlflow.end_run()\n",
      "            run = mlflow.get_run(run.info.run_id)\n",
      "            print(\"run_id: {}; status: {}\".format(run.info.run_id, run.info.status))\n",
      "            print(\"--\")\n",
      "        \n",
      "            # Check for any active runs\n",
      "            print(\"Active run: {}\".format(mlflow.active_run()))\n",
      "        \n",
      "        .. code-block:: text\n",
      "            :caption: Output\n",
      "        \n",
      "            run_id: b47ee4563368419880b44ad8535f6371; status: RUNNING\n",
      "            run_id: b47ee4563368419880b44ad8535f6371; status: FINISHED\n",
      "            --\n",
      "            Active run: None\n",
      "    \n",
      "    evaluate(model: str, data, *, targets, model_type: str, dataset_path=None, feature_names: list = None, evaluators=None, evaluator_config=None, custom_metrics=None, custom_artifacts=None, validation_thresholds=None, baseline_model=None, env_manager='local')\n",
      "        Evaluate a PyFunc model on the specified dataset using one or more specified ``evaluators``, and\n",
      "        log resulting metrics & artifacts to MLflow Tracking. Set thresholds on the generated metrics to\n",
      "        validate model quality. For additional overview information, see\n",
      "        :ref:`the Model Evaluation documentation <model-evaluation>`.\n",
      "        \n",
      "        Default Evaluator behavior:\n",
      "         - The default evaluator, which can be invoked with ``evaluators=\"default\"`` or\n",
      "           ``evaluators=None``, supports the ``\"regressor\"`` and ``\"classifier\"`` model types.\n",
      "           It generates a variety of model performance metrics, model performance plots, and\n",
      "           model explanations.\n",
      "        \n",
      "         - For both the ``\"regressor\"`` and ``\"classifier\"`` model types, the default evaluator\n",
      "           generates model summary plots and feature importance plots using\n",
      "           `SHAP <https://shap.readthedocs.io/en/latest/index.html>`_.\n",
      "        \n",
      "         - For regressor models, the default evaluator additionally logs:\n",
      "            - **metrics**: example_count, mean_absolute_error, mean_squared_error,\n",
      "              root_mean_squared_error, sum_on_target, mean_on_target, r2_score, max_error,\n",
      "              mean_absolute_percentage_error.\n",
      "        \n",
      "         - For binary classifiers, the default evaluator additionally logs:\n",
      "            - **metrics**: true_negatives, false_positives, false_negatives, true_positives, recall,\n",
      "              precision, f1_score, accuracy_score, example_count, log_loss, roc_auc,\n",
      "              precision_recall_auc.\n",
      "            - **artifacts**: lift curve plot, precision-recall plot, ROC plot.\n",
      "        \n",
      "         - For multiclass classifiers, the default evaluator additionally logs:\n",
      "            - **metrics**: accuracy_score, example_count, f1_score_micro, f1_score_macro, log_loss\n",
      "            - **artifacts**: A CSV file for \"per_class_metrics\" (per-class metrics includes\n",
      "              true_negatives/false_positives/false_negatives/true_positives/recall/precision/roc_auc,\n",
      "              precision_recall_auc), precision-recall merged curves plot, ROC merged curves plot.\n",
      "        \n",
      "         - For sklearn models, the default evaluator additionally logs the model's evaluation criterion\n",
      "           (e.g. mean accuracy for a classifier) computed by `model.score` method.\n",
      "        \n",
      "         - The metrics/artifacts listed above are logged to the active MLflow run.\n",
      "           If no active run exists, a new MLflow run is created for logging these metrics and\n",
      "           artifacts. Note that no metrics/artifacts are logged for the ``baseline_model``.\n",
      "        \n",
      "         - Additionally, information about the specified dataset - hash, name (if specified), path\n",
      "           (if specified), and the UUID of the model that evaluated it - is logged to the\n",
      "           ``mlflow.datasets`` tag.\n",
      "        \n",
      "         - The available ``evaluator_config`` options for the default evaluator include:\n",
      "            - **log_model_explainability**: A boolean value specifying whether or not to log model\n",
      "              explainability insights, default value is True.\n",
      "            - **explainability_algorithm**: A string to specify the SHAP Explainer algorithm for model\n",
      "              explainability. Supported algorithm includes: 'exact', 'permutation', 'partition',\n",
      "              'kernel'.\n",
      "              If not set, ``shap.Explainer`` is used with the \"auto\" algorithm, which chooses the best\n",
      "              Explainer based on the model.\n",
      "            - **explainability_nsamples**: The number of sample rows to use for computing model\n",
      "              explainability insights. Default value is 2000.\n",
      "            - **explainability_kernel_link**: The kernel link function used by shap kernal explainer.\n",
      "              Available values are \"identity\" and \"logit\". Default value is \"identity\".\n",
      "            - **max_classes_for_multiclass_roc_pr**:\n",
      "              For multiclass classification tasks, the maximum number of classes for which to log\n",
      "              the per-class ROC curve and Precision-Recall curve. If the number of classes is\n",
      "              larger than the configured maximum, these curves are not logged.\n",
      "            - **metric_prefix**: An optional prefix to prepend to the name of each metric produced\n",
      "              during evaluation.\n",
      "            - **log_metrics_with_dataset_info**: A boolean value specifying whether or not to include\n",
      "              information about the evaluation dataset in the name of each metric logged to MLflow\n",
      "              Tracking during evaluation, default value is True.\n",
      "            - **pos_label**: If specified, the positive label to use when computing classification\n",
      "              metrics such as precision, recall, f1, etc. for binary classification models. For\n",
      "              multiclass classification and regression models, this parameter will be ignored.\n",
      "            - **average**: The averaging method to use when computing classification metrics such as\n",
      "              precision, recall, f1, etc. for multiclass classification models\n",
      "              (default: ``'weighted'``). For binary classification and regression models, this\n",
      "              parameter will be ignored.\n",
      "            - **sample_weights**: Weights for each sample to apply when computing model performance\n",
      "              metrics.\n",
      "        \n",
      "         - Limitations of evaluation dataset:\n",
      "            - For classification tasks, dataset labels are used to infer the total number of classes.\n",
      "            - For binary classification tasks, the negative label value must be 0 or -1 or False, and\n",
      "              the positive label value must be 1 or True.\n",
      "        \n",
      "         - Limitations of metrics/artifacts computation:\n",
      "            - For classification tasks, some metric and artifact computations require the model to\n",
      "              output class probabilities. Currently, for scikit-learn models, the default evaluator\n",
      "              calls the ``predict_proba`` method on the underlying model to obtain probabilities. For\n",
      "              other model types, the default evaluator does not compute metrics/artifacts that require\n",
      "              probability outputs.\n",
      "        \n",
      "         - Limitations of default evaluator logging model explainability insights:\n",
      "            - The ``shap.Explainer`` ``auto`` algorithm uses the ``Linear`` explainer for linear models\n",
      "              and the ``Tree`` explainer for tree models. Because SHAP's ``Linear`` and ``Tree``\n",
      "              explainers do not support multi-class classification, the default evaluator falls back to\n",
      "              using the ``Exact`` or ``Permutation`` explainers for multi-class classification tasks.\n",
      "            - Logging model explainability insights is not currently supported for PySpark models.\n",
      "            - The evaluation dataset label values must be numeric or boolean, all feature values\n",
      "              must be numeric, and each feature column must only contain scalar values.\n",
      "        \n",
      "         - Limitations when environment restoration is enabled:\n",
      "            - When environment restoration is enabled for the evaluated model (i.e. a non-local\n",
      "              ``env_manager`` is specified), the model is loaded as a client that invokes a MLflow\n",
      "              Model Scoring Server process in an independent Python environment with the model's\n",
      "              training time dependencies installed. As such, methods like ``predict_proba`` (for\n",
      "              probability outputs) or ``score`` (computes the evaluation criterian for sklearn models)\n",
      "              of the model become inaccessible and the default evaluator does not compute metrics or\n",
      "              artifacts that require those methods.\n",
      "            - Because the model is an MLflow Model Server process, SHAP explanations are slower to\n",
      "              compute. As such, model explainaibility is disabled when a non-local ``env_manager``\n",
      "              specified, unless the ``evaluator_config`` option **log_model_explainability** is\n",
      "              explicitly set to ``True``.\n",
      "        \n",
      "        :param model: A pyfunc model instance, or a URI referring to such a model.\n",
      "        \n",
      "        :param data: One of the following:\n",
      "        \n",
      "                     - A numpy array or list of evaluation features, excluding labels.\n",
      "        \n",
      "                     - A Pandas DataFrame or Spark DataFrame, containing evaluation features and\n",
      "                       labels. If ``feature_names`` argument not specified, all columns are regarded\n",
      "                       as feature columns. Otherwise, only column names present in ``feature_names``\n",
      "                       are regarded as feature columns. If it is Spark DataFrame, only the first 10000\n",
      "                       rows in the Spark DataFrame will be used as evaluation data.\n",
      "        \n",
      "        :param targets: If ``data`` is a numpy array or list, a numpy array or list of evaluation\n",
      "                        labels. If ``data`` is a DataFrame, the string name of a column from ``data``\n",
      "                        that contains evaluation labels.\n",
      "        \n",
      "        :param model_type: A string describing the model type. The default evaluator\n",
      "                           supports ``\"regressor\"`` and ``\"classifier\"`` as model types.\n",
      "        \n",
      "        :param dataset_path: (Optional) The path where the data is stored. Must not contain double\n",
      "                             quotes (``“``). If specified, the path is logged to the ``mlflow.datasets``\n",
      "                             tag for lineage tracking purposes.\n",
      "        \n",
      "        :param feature_names: (Optional) If the ``data`` argument is a feature data numpy array or list,\n",
      "                              ``feature_names`` is a list of the feature names for each feature. If\n",
      "                              ``None``, then the ``feature_names`` are generated using the format\n",
      "                              ``feature_{feature_index}``. If the ``data`` argument is a Pandas\n",
      "                              DataFrame or a Spark DataFrame, ``feature_names`` is a list of the names\n",
      "                              of the feature columns in the DataFrame. If ``None``, then all columns\n",
      "                              except the label column are regarded as feature columns.\n",
      "        \n",
      "        :param evaluators: The name of the evaluator to use for model evaluation, or a list of\n",
      "                           evaluator names. If unspecified, all evaluators capable of evaluating the\n",
      "                           specified model on the specified dataset are used. The default evaluator\n",
      "                           can be referred to by the name ``\"default\"``. To see all available\n",
      "                           evaluators, call :py:func:`mlflow.models.list_evaluators`.\n",
      "        \n",
      "        :param evaluator_config: A dictionary of additional configurations to supply to the evaluator.\n",
      "                                 If multiple evaluators are specified, each configuration should be\n",
      "                                 supplied as a nested dictionary whose key is the evaluator name.\n",
      "        \n",
      "        :param custom_metrics:\n",
      "            (Optional) A list of :py:class:`EvaluationMetric <mlflow.models.EvaluationMetric>` objects.\n",
      "        \n",
      "            .. code-block:: python\n",
      "                :caption: Example usage of custom metrics\n",
      "        \n",
      "                import mlflow\n",
      "                import numpy as np\n",
      "        \n",
      "        \n",
      "                def root_mean_squared_error(eval_df, _builtin_metrics):\n",
      "                    return np.sqrt((np.abs(eval_df[\"prediction\"] - eval_df[\"target\"]) ** 2).mean)\n",
      "        \n",
      "        \n",
      "                rmse_metric = mlflow.models.make_metric(\n",
      "                    eval_fn=root_mean_squared_error,\n",
      "                    greater_is_better=False,\n",
      "                )\n",
      "                mlflow.evaluate(..., custom_metrics=[rmse_metric])\n",
      "        \n",
      "        :param custom_artifacts:\n",
      "            (Optional) A list of custom artifact functions with the following signature:\n",
      "        \n",
      "            .. code-block:: python\n",
      "        \n",
      "                def custom_artifact(\n",
      "                    eval_df: Union[pandas.Dataframe, pyspark.sql.DataFrame],\n",
      "                    builtin_metrics: Dict[str, float],\n",
      "                    artifacts_dir: str,\n",
      "                ) -> Dict[str, Any]:\n",
      "                    \"\"\"\n",
      "                    :param eval_df:\n",
      "                        A Pandas or Spark DataFrame containing ``prediction`` and ``target`` column.\n",
      "                        The ``prediction`` column contains the predictions made by the model.\n",
      "                        The ``target`` column contains the corresponding labels to the predictions made\n",
      "                        on that row.\n",
      "                    :param builtin_metrics:\n",
      "                        A dictionary containing the metrics calculated by the default evaluator.\n",
      "                        The keys are the names of the metrics and the values are the scalar values of\n",
      "                        the metrics. Refer to the DefaultEvaluator behavior section for what metrics\n",
      "                        will be returned based on the type of model (i.e. classifier or regressor).\n",
      "                    :param artifacts_dir:\n",
      "                        A temporary directory path that can be used by the custom artifacts function to\n",
      "                        temporarily store produced artifacts. The directory will be deleted after the\n",
      "                        artifacts are logged.\n",
      "                    :return:\n",
      "                        A dictionary that maps artifact names to artifact objects\n",
      "                        (e.g. a Matplotlib Figure) or to artifact paths within ``artifacts_dir``.\n",
      "                    \"\"\"\n",
      "                    ...\n",
      "        \n",
      "            Object types that artifacts can be represented as:\n",
      "        \n",
      "                - A string uri representing the file path to the artifact. MLflow will infer the type of\n",
      "                  the artifact based on the file extension.\n",
      "                - A string representation of a JSON object. This will be saved as a .json artifact.\n",
      "                - Pandas DataFrame. This will be resolved as a CSV artifact.\n",
      "                - Numpy array. This will be saved as a .npy artifact.\n",
      "                - Matplotlib Figure. This will be saved as an image artifact. Note that\n",
      "                  ``matplotlib.pyplot.savefig`` is called behind the scene with default configurations.\n",
      "                  To customize, either save the figure with the desired configurations and return its\n",
      "                  file path or define customizations through environment variables in\n",
      "                  ``matplotlib.rcParams``.\n",
      "                - Other objects will be attempted to be pickled with the default protocol.\n",
      "        \n",
      "            .. code-block:: python\n",
      "                :caption: Example usage of custom artifacts\n",
      "        \n",
      "                import mlflow\n",
      "                import matplotlib.pyplot as plt\n",
      "        \n",
      "        \n",
      "                def scatter_plot(eval_df, builtin_metrics, artifacts_dir):\n",
      "                    plt.scatter(eval_df[\"prediction\"], eval_df[\"target\"])\n",
      "                    plt.xlabel(\"Targets\")\n",
      "                    plt.ylabel(\"Predictions\")\n",
      "                    plt.title(\"Targets vs. Predictions\")\n",
      "                    plt.savefig(os.path.join(artifacts_dir, \"example.png\"))\n",
      "                    plt.close()\n",
      "                    return {\"pred_target_scatter\": os.path.join(artifacts_dir, \"example.png\")}\n",
      "        \n",
      "        \n",
      "                def pred_sample(eval_df, _builtin_metrics, _artifacts_dir):\n",
      "                    return {\"pred_sample\": pred_sample.head(10)}\n",
      "        \n",
      "        \n",
      "                mlflow.evaluate(..., custom_artifacts=[scatter_plot, pred_sample])\n",
      "        \n",
      "        :param validation_thresholds: (Optional) A dictionary of metric name to\n",
      "            :py:class:`mlflow.models.MetricThreshold` used for model validation. Each metric name must\n",
      "            either be the name of a builtin metric or the name of a custom metric defined in the\n",
      "            ``custom_metrics`` parameter.\n",
      "        \n",
      "            .. code-block:: python\n",
      "                :caption: Example of Model Validation\n",
      "        \n",
      "                from mlflow.models import MetricThreshold\n",
      "        \n",
      "                thresholds = {\n",
      "                    \"accuracy_score\": MetricThreshold(\n",
      "                        # accuracy should be >=0.8\n",
      "                        threshold=0.8,\n",
      "                        # accuracy should be at least 5 percent greater than baseline model accuracy\n",
      "                        min_absolute_change=0.05,\n",
      "                        # accuracy should be at least 0.05 greater than baseline model accuracy\n",
      "                        min_relative_change=0.05,\n",
      "                        higher_is_better=True,\n",
      "                    ),\n",
      "                }\n",
      "        \n",
      "                with mlflow.start_run():\n",
      "                    mlflow.evaluate(\n",
      "                        model=your_candidate_model,\n",
      "                        data,\n",
      "                        targets,\n",
      "                        model_type,\n",
      "                        dataset_name,\n",
      "                        evaluators,\n",
      "                        validation_thresholds=thresholds,\n",
      "                        baseline_model=your_baseline_model,\n",
      "                    )\n",
      "        \n",
      "            See :ref:`the Model Validation documentation <model-validation>`\n",
      "            for more details.\n",
      "        \n",
      "        :param baseline_model: (Optional) A string URI referring to an MLflow model with the pyfunc\n",
      "                               flavor. If specified, the candidate ``model`` is compared to this\n",
      "                               baseline for model validation purposes.\n",
      "        \n",
      "        :param env_manager: Specify an environment manager to load the candidate ``model`` and\n",
      "                            ``baseline_model`` in isolated Python evironments and restore their\n",
      "                            dependencies. Default value is ``local``, and the following values are\n",
      "                            supported:\n",
      "        \n",
      "                             - ``virtualenv``: (Recommended) Use virtualenv to restore the python\n",
      "                               environment that was used to train the model.\n",
      "                             - ``conda``:  Use Conda to restore the software environment that was used\n",
      "                               to train the model.\n",
      "                             - ``local``: Use the current Python environment for model inference, which\n",
      "                               may differ from the environment used to train the model and may lead to\n",
      "                               errors or invalid predictions.\n",
      "        \n",
      "        :return: An :py:class:`mlflow.models.EvaluationResult` instance containing\n",
      "                 metrics of candidate model and baseline model, and artifacts of candidate model.\n",
      "    \n",
      "    get_artifact_uri(artifact_path: Optional[str] = None) -> str\n",
      "        Get the absolute URI of the specified artifact in the currently active run.\n",
      "        If `path` is not specified, the artifact root URI of the currently active\n",
      "        run will be returned; calls to ``log_artifact`` and ``log_artifacts`` write\n",
      "        artifact(s) to subdirectories of the artifact root URI.\n",
      "        \n",
      "        If no run is active, this method will create a new active run.\n",
      "        \n",
      "        :param artifact_path: The run-relative artifact path for which to obtain an absolute URI.\n",
      "                              For example, \"path/to/artifact\". If unspecified, the artifact root URI\n",
      "                              for the currently active run will be returned.\n",
      "        :return: An *absolute* URI referring to the specified artifact or the currently active run's\n",
      "                 artifact root. For example, if an artifact path is provided and the currently active\n",
      "                 run uses an S3-backed store, this may be a uri of the form\n",
      "                 ``s3://<bucket_name>/path/to/artifact/root/path/to/artifact``. If an artifact path\n",
      "                 is not provided and the currently active run uses an S3-backed store, this may be a\n",
      "                 URI of the form ``s3://<bucket_name>/path/to/artifact/root``.\n",
      "        \n",
      "        .. test-code-block:: python\n",
      "            :caption: Example\n",
      "        \n",
      "            import mlflow\n",
      "        \n",
      "            features = \"rooms, zipcode, median_price, school_rating, transport\"\n",
      "            with open(\"features.txt\", \"w\") as f:\n",
      "                f.write(features)\n",
      "        \n",
      "            # Log the artifact in a directory \"features\" under the root artifact_uri/features\n",
      "            with mlflow.start_run():\n",
      "                mlflow.log_artifact(\"features.txt\", artifact_path=\"features\")\n",
      "        \n",
      "                # Fetch the artifact uri root directory\n",
      "                artifact_uri = mlflow.get_artifact_uri()\n",
      "                print(\"Artifact uri: {}\".format(artifact_uri))\n",
      "        \n",
      "                # Fetch a specific artifact uri\n",
      "                artifact_uri = mlflow.get_artifact_uri(artifact_path=\"features/features.txt\")\n",
      "                print(\"Artifact uri: {}\".format(artifact_uri))\n",
      "        \n",
      "        .. code-block:: text\n",
      "            :caption: Output\n",
      "        \n",
      "            Artifact uri: file:///.../0/a46a80f1c9644bd8f4e5dd5553fffce/artifacts\n",
      "            Artifact uri: file:///.../0/a46a80f1c9644bd8f4e5dd5553fffce/artifacts/features/features.txt\n",
      "    \n",
      "    get_experiment(experiment_id: str) -> mlflow.entities.experiment.Experiment\n",
      "        Retrieve an experiment by experiment_id from the backend store\n",
      "        \n",
      "        :param experiment_id: The string-ified experiment ID returned from ``create_experiment``.\n",
      "        :return: :py:class:`mlflow.entities.Experiment`\n",
      "        \n",
      "        .. test-code-block:: python\n",
      "            :caption: Example\n",
      "        \n",
      "            import mlflow\n",
      "        \n",
      "            experiment = mlflow.get_experiment(\"0\")\n",
      "            print(\"Name: {}\".format(experiment.name))\n",
      "            print(\"Artifact Location: {}\".format(experiment.artifact_location))\n",
      "            print(\"Tags: {}\".format(experiment.tags))\n",
      "            print(\"Lifecycle_stage: {}\".format(experiment.lifecycle_stage))\n",
      "            print(\"Creation timestamp: {}\".format(experiment.creation_time))\n",
      "        \n",
      "        .. code-block:: text\n",
      "            :caption: Output\n",
      "        \n",
      "            Name: Default\n",
      "            Artifact Location: file:///.../mlruns/0\n",
      "            Tags: {}\n",
      "            Lifecycle_stage: active\n",
      "            Creation timestamp: 1662004217511\n",
      "    \n",
      "    get_experiment_by_name(name: str) -> Optional[mlflow.entities.experiment.Experiment]\n",
      "        Retrieve an experiment by experiment name from the backend store\n",
      "        \n",
      "        :param name: The case sensitive experiment name.\n",
      "        :return: An instance of :py:class:`mlflow.entities.Experiment`\n",
      "                 if an experiment with the specified name exists, otherwise None.\n",
      "        \n",
      "        .. test-code-block:: python\n",
      "            :caption: Example\n",
      "        \n",
      "            import mlflow\n",
      "        \n",
      "            # Case sensitive name\n",
      "            experiment = mlflow.get_experiment_by_name(\"Default\")\n",
      "            print(\"Experiment_id: {}\".format(experiment.experiment_id))\n",
      "            print(\"Artifact Location: {}\".format(experiment.artifact_location))\n",
      "            print(\"Tags: {}\".format(experiment.tags))\n",
      "            print(\"Lifecycle_stage: {}\".format(experiment.lifecycle_stage))\n",
      "            print(\"Creation timestamp: {}\".format(experiment.creation_time))\n",
      "        \n",
      "        .. code-block:: text\n",
      "            :caption: Output\n",
      "        \n",
      "            Experiment_id: 0\n",
      "            Artifact Location: file:///.../mlruns/0\n",
      "            Tags: {}\n",
      "            Lifecycle_stage: active\n",
      "            Creation timestamp: 1662004217511\n",
      "    \n",
      "    get_registry_uri() -> str\n",
      "        Get the current registry URI. If none has been specified, defaults to the tracking URI.\n",
      "        \n",
      "        :return: The registry URI.\n",
      "        \n",
      "        .. code-block:: python\n",
      "            :caption: Example\n",
      "        \n",
      "            # Get the current model registry uri\n",
      "            mr_uri = mlflow.get_registry_uri()\n",
      "            print(\"Current model registry uri: {}\".format(mr_uri))\n",
      "        \n",
      "            # Get the current tracking uri\n",
      "            tracking_uri = mlflow.get_tracking_uri()\n",
      "            print(\"Current tracking uri: {}\".format(tracking_uri))\n",
      "        \n",
      "            # They should be the same\n",
      "            assert mr_uri == tracking_uri\n",
      "        \n",
      "        .. code-block:: text\n",
      "            :caption: Output\n",
      "        \n",
      "            Current model registry uri: file:///.../mlruns\n",
      "            Current tracking uri: file:///.../mlruns\n",
      "    \n",
      "    get_run(run_id: str) -> mlflow.entities.run.Run\n",
      "        Fetch the run from backend store. The resulting :py:class:`Run <mlflow.entities.Run>`\n",
      "        contains a collection of run metadata -- :py:class:`RunInfo <mlflow.entities.RunInfo>`,\n",
      "        as well as a collection of run parameters, tags, and metrics --\n",
      "        :py:class:`RunData <mlflow.entities.RunData>`. In the case where multiple metrics with the\n",
      "        same key are logged for the run, the :py:class:`RunData <mlflow.entities.RunData>` contains\n",
      "        the most recently logged value at the largest step for each metric.\n",
      "        \n",
      "        :param run_id: Unique identifier for the run.\n",
      "        \n",
      "        :return: A single :py:class:`mlflow.entities.Run` object, if the run exists. Otherwise,\n",
      "                    raises an exception.\n",
      "        \n",
      "        .. test-code-block:: python\n",
      "            :caption: Example\n",
      "        \n",
      "            import mlflow\n",
      "        \n",
      "            with mlflow.start_run() as run:\n",
      "                mlflow.log_param(\"p\", 0)\n",
      "        \n",
      "            run_id = run.info.run_id\n",
      "            print(\n",
      "                \"run_id: {}; lifecycle_stage: {}\".format(\n",
      "                    run_id, mlflow.get_run(run_id).info.lifecycle_stage\n",
      "                )\n",
      "            )\n",
      "        \n",
      "        .. code-block:: text\n",
      "            :caption: Output\n",
      "        \n",
      "            run_id: 7472befefc754e388e8e922824a0cca5; lifecycle_stage: active\n",
      "    \n",
      "    get_tracking_uri() -> str\n",
      "        Get the current tracking URI. This may not correspond to the tracking URI of\n",
      "        the currently active run, since the tracking URI can be updated via ``set_tracking_uri``.\n",
      "        \n",
      "        :return: The tracking URI.\n",
      "        \n",
      "        .. code-block:: python\n",
      "            :caption: Example\n",
      "        \n",
      "            import mlflow\n",
      "        \n",
      "            # Get the current tracking uri\n",
      "            tracking_uri = mlflow.get_tracking_uri()\n",
      "            print(\"Current tracking uri: {}\".format(tracking_uri))\n",
      "        \n",
      "        .. code-block:: text\n",
      "            :caption: Output\n",
      "        \n",
      "            Current tracking uri: file:///.../mlruns\n",
      "    \n",
      "    is_tracking_uri_set()\n",
      "        Returns True if the tracking URI has been set, False otherwise.\n",
      "    \n",
      "    last_active_run() -> Optional[mlflow.entities.run.Run]\n",
      "        Gets the most recent active run.\n",
      "        \n",
      "        Examples:\n",
      "        \n",
      "        .. test-code-block:: python\n",
      "            :caption: To retrieve the most recent autologged run:\n",
      "        \n",
      "            import mlflow\n",
      "        \n",
      "            from sklearn.model_selection import train_test_split\n",
      "            from sklearn.datasets import load_diabetes\n",
      "            from sklearn.ensemble import RandomForestRegressor\n",
      "        \n",
      "            mlflow.autolog()\n",
      "        \n",
      "            db = load_diabetes()\n",
      "            X_train, X_test, y_train, y_test = train_test_split(db.data, db.target)\n",
      "        \n",
      "            # Create and train models.\n",
      "            rf = RandomForestRegressor(n_estimators=100, max_depth=6, max_features=3)\n",
      "            rf.fit(X_train, y_train)\n",
      "        \n",
      "            # Use the model to make predictions on the test dataset.\n",
      "            predictions = rf.predict(X_test)\n",
      "            autolog_run = mlflow.last_active_run()\n",
      "        \n",
      "        .. test-code-block:: python\n",
      "            :caption: To get the most recently active run that ended:\n",
      "        \n",
      "            import mlflow\n",
      "        \n",
      "            mlflow.start_run()\n",
      "            mlflow.end_run()\n",
      "            run = mlflow.last_active_run()\n",
      "        \n",
      "        .. test-code-block:: python\n",
      "            :caption: To retrieve the currently active run:\n",
      "        \n",
      "            import mlflow\n",
      "        \n",
      "            mlflow.start_run()\n",
      "            run = mlflow.last_active_run()\n",
      "            mlflow.end_run()\n",
      "        \n",
      "        :return: The active run (this is equivalent to ``mlflow.active_run()``) if one exists.\n",
      "                 Otherwise, the last run started from the current Python process that reached\n",
      "                 a terminal status (i.e. FINISHED, FAILED, or KILLED).\n",
      "    \n",
      "    log_artifact(local_path: str, artifact_path: Optional[str] = None) -> None\n",
      "        Log a local file or directory as an artifact of the currently active run. If no run is\n",
      "        active, this method will create a new active run.\n",
      "        \n",
      "        :param local_path: Path to the file to write.\n",
      "        :param artifact_path: If provided, the directory in ``artifact_uri`` to write to.\n",
      "        \n",
      "        .. test-code-block:: python\n",
      "            :caption: Example\n",
      "        \n",
      "            import mlflow\n",
      "        \n",
      "            # Create a features.txt artifact file\n",
      "            features = \"rooms, zipcode, median_price, school_rating, transport\"\n",
      "            with open(\"features.txt\", \"w\") as f:\n",
      "                f.write(features)\n",
      "        \n",
      "            # With artifact_path=None write features.txt under\n",
      "            # root artifact_uri/artifacts directory\n",
      "            with mlflow.start_run():\n",
      "                mlflow.log_artifact(\"features.txt\")\n",
      "    \n",
      "    log_artifacts(local_dir: str, artifact_path: Optional[str] = None) -> None\n",
      "        Log all the contents of a local directory as artifacts of the run. If no run is active,\n",
      "        this method will create a new active run.\n",
      "        \n",
      "        :param local_dir: Path to the directory of files to write.\n",
      "        :param artifact_path: If provided, the directory in ``artifact_uri`` to write to.\n",
      "        \n",
      "        .. test-code-block:: python\n",
      "            :caption: Example\n",
      "        \n",
      "            import json\n",
      "            import os\n",
      "            import mlflow\n",
      "        \n",
      "            # Create some files to preserve as artifacts\n",
      "            features = \"rooms, zipcode, median_price, school_rating, transport\"\n",
      "            data = {\"state\": \"TX\", \"Available\": 25, \"Type\": \"Detached\"}\n",
      "        \n",
      "            # Create couple of artifact files under the directory \"data\"\n",
      "            os.makedirs(\"data\", exist_ok=True)\n",
      "            with open(\"data/data.json\", \"w\", encoding=\"utf-8\") as f:\n",
      "                json.dump(data, f, indent=2)\n",
      "            with open(\"data/features.txt\", \"w\") as f:\n",
      "                f.write(features)\n",
      "        \n",
      "            # Write all files in \"data\" to root artifact_uri/states\n",
      "            with mlflow.start_run():\n",
      "                mlflow.log_artifacts(\"data\", artifact_path=\"states\")\n",
      "    \n",
      "    log_dict(dictionary: Any, artifact_file: str) -> None\n",
      "        Log a JSON/YAML-serializable object (e.g. `dict`) as an artifact. The serialization\n",
      "        format (JSON or YAML) is automatically inferred from the extension of `artifact_file`.\n",
      "        If the file extension doesn't exist or match any of [\".json\", \".yml\", \".yaml\"],\n",
      "        JSON format is used.\n",
      "        \n",
      "        :param dictionary: Dictionary to log.\n",
      "        :param artifact_file: The run-relative artifact file path in posixpath format to which\n",
      "                              the dictionary is saved (e.g. \"dir/data.json\").\n",
      "        \n",
      "        .. test-code-block:: python\n",
      "            :caption: Example\n",
      "        \n",
      "            import mlflow\n",
      "        \n",
      "            dictionary = {\"k\": \"v\"}\n",
      "        \n",
      "            with mlflow.start_run():\n",
      "                # Log a dictionary as a JSON file under the run's root artifact directory\n",
      "                mlflow.log_dict(dictionary, \"data.json\")\n",
      "        \n",
      "                # Log a dictionary as a YAML file in a subdirectory of the run's root artifact directory\n",
      "                mlflow.log_dict(dictionary, \"dir/data.yml\")\n",
      "        \n",
      "                # If the file extension doesn't exist or match any of [\".json\", \".yaml\", \".yml\"],\n",
      "                # JSON format is used.\n",
      "                mlflow.log_dict(dictionary, \"data\")\n",
      "                mlflow.log_dict(dictionary, \"data.txt\")\n",
      "    \n",
      "    log_figure(figure: Union[ForwardRef('matplotlib.figure.Figure'), ForwardRef('plotly.graph_objects.Figure')], artifact_file: str) -> None\n",
      "        Log a figure as an artifact. The following figure objects are supported:\n",
      "        \n",
      "        - `matplotlib.figure.Figure`_\n",
      "        - `plotly.graph_objects.Figure`_\n",
      "        \n",
      "        .. _matplotlib.figure.Figure:\n",
      "            https://matplotlib.org/api/_as_gen/matplotlib.figure.Figure.html\n",
      "        \n",
      "        .. _plotly.graph_objects.Figure:\n",
      "            https://plotly.com/python-api-reference/generated/plotly.graph_objects.Figure.html\n",
      "        \n",
      "        :param figure: Figure to log.\n",
      "        :param artifact_file: The run-relative artifact file path in posixpath format to which\n",
      "                              the figure is saved (e.g. \"dir/file.png\").\n",
      "        \n",
      "        .. test-code-block:: python\n",
      "            :caption: Matplotlib Example\n",
      "        \n",
      "            import mlflow\n",
      "            import matplotlib.pyplot as plt\n",
      "        \n",
      "            fig, ax = plt.subplots()\n",
      "            ax.plot([0, 1], [2, 3])\n",
      "        \n",
      "            with mlflow.start_run():\n",
      "                mlflow.log_figure(fig, \"figure.png\")\n",
      "        \n",
      "        .. test-code-block:: python\n",
      "            :caption: Plotly Example\n",
      "        \n",
      "            import mlflow\n",
      "            from plotly import graph_objects as go\n",
      "        \n",
      "            fig = go.Figure(go.Scatter(x=[0, 1], y=[2, 3]))\n",
      "        \n",
      "            with mlflow.start_run():\n",
      "                mlflow.log_figure(fig, \"figure.html\")\n",
      "    \n",
      "    log_image(image: Union[ForwardRef('numpy.ndarray'), ForwardRef('PIL.Image.Image')], artifact_file: str) -> None\n",
      "        Log an image as an artifact. The following image objects are supported:\n",
      "        \n",
      "        - `numpy.ndarray`_\n",
      "        - `PIL.Image.Image`_\n",
      "        \n",
      "        .. _numpy.ndarray:\n",
      "            https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html\n",
      "        \n",
      "        .. _PIL.Image.Image:\n",
      "            https://pillow.readthedocs.io/en/stable/reference/Image.html#PIL.Image.Image\n",
      "        \n",
      "        Numpy array support\n",
      "            - data type (( ) represents a valid value range):\n",
      "        \n",
      "                - bool\n",
      "                - integer (0 ~ 255)\n",
      "                - unsigned integer (0 ~ 255)\n",
      "                - float (0.0 ~ 1.0)\n",
      "        \n",
      "                .. warning::\n",
      "        \n",
      "                    - Out-of-range integer values will be **clipped** to [0, 255].\n",
      "                    - Out-of-range float values will be **clipped** to [0, 1].\n",
      "        \n",
      "            - shape (H: height, W: width):\n",
      "        \n",
      "                - H x W (Grayscale)\n",
      "                - H x W x 1 (Grayscale)\n",
      "                - H x W x 3 (an RGB channel order is assumed)\n",
      "                - H x W x 4 (an RGBA channel order is assumed)\n",
      "        \n",
      "        :param image: Image to log.\n",
      "        :param artifact_file: The run-relative artifact file path in posixpath format to which\n",
      "                              the image is saved (e.g. \"dir/image.png\").\n",
      "        \n",
      "        .. test-code-block:: python\n",
      "            :caption: Numpy Example\n",
      "        \n",
      "            import mlflow\n",
      "            import numpy as np\n",
      "        \n",
      "            image = np.random.randint(0, 256, size=(100, 100, 3), dtype=np.uint8)\n",
      "        \n",
      "            with mlflow.start_run():\n",
      "                mlflow.log_image(image, \"image.png\")\n",
      "        \n",
      "        .. test-code-block:: python\n",
      "            :caption: Pillow Example\n",
      "        \n",
      "            import mlflow\n",
      "            from PIL import Image\n",
      "        \n",
      "            image = Image.new(\"RGB\", (100, 100))\n",
      "        \n",
      "            with mlflow.start_run():\n",
      "                mlflow.log_image(image, \"image.png\")\n",
      "    \n",
      "    log_metric(key: str, value: float, step: Optional[int] = None) -> None\n",
      "        Log a metric under the current run. If no run is active, this method will create\n",
      "        a new active run.\n",
      "        \n",
      "        :param key: Metric name (string). This string may only contain alphanumerics, underscores (_),\n",
      "                    dashes (-), periods (.), spaces ( ), and slashes (/).\n",
      "                    All backend stores will support keys up to length 250, but some may\n",
      "                    support larger keys.\n",
      "        :param value: Metric value (float). Note that some special values such as +/- Infinity may be\n",
      "                      replaced by other values depending on the store. For example, the\n",
      "                      SQLAlchemy store replaces +/- Infinity with max / min float values.\n",
      "                      All backend stores will support values up to length 5000, but some\n",
      "                      may support larger values.\n",
      "        :param step: Metric step (int). Defaults to zero if unspecified.\n",
      "        \n",
      "        .. test-code-block:: python\n",
      "            :caption: Example\n",
      "        \n",
      "            import mlflow\n",
      "        \n",
      "            with mlflow.start_run():\n",
      "                mlflow.log_metric(\"mse\", 2500.00)\n",
      "    \n",
      "    log_metrics(metrics: Dict[str, float], step: Optional[int] = None) -> None\n",
      "        Log multiple metrics for the current run. If no run is active, this method will create a new\n",
      "        active run.\n",
      "        \n",
      "        :param metrics: Dictionary of metric_name: String -> value: Float. Note that some special\n",
      "                        values such as +/- Infinity may be replaced by other values depending on\n",
      "                        the store. For example, sql based store may replace +/- Infinity with\n",
      "                        max / min float values.\n",
      "        :param step: A single integer step at which to log the specified\n",
      "                     Metrics. If unspecified, each metric is logged at step zero.\n",
      "        \n",
      "        :returns: None\n",
      "        \n",
      "        .. test-code-block:: python\n",
      "            :caption: Example\n",
      "        \n",
      "            import mlflow\n",
      "        \n",
      "            metrics = {\"mse\": 2500.00, \"rmse\": 50.00}\n",
      "        \n",
      "            # Log a batch of metrics\n",
      "            with mlflow.start_run():\n",
      "                mlflow.log_metrics(metrics)\n",
      "    \n",
      "    log_param(key: str, value: Any) -> Any\n",
      "        Log a parameter (e.g. model hyperparameter) under the current run. If no run is active,\n",
      "        this method will create a new active run.\n",
      "        \n",
      "        :param key: Parameter name (string). This string may only contain alphanumerics,\n",
      "                    underscores (_), dashes (-), periods (.), spaces ( ), and slashes (/).\n",
      "                    All backend stores support keys up to length 250, but some may\n",
      "                    support larger keys.\n",
      "        :param value: Parameter value (string, but will be string-ified if not).\n",
      "                      All backend stores support values up to length 500, but some\n",
      "                      may support larger values.\n",
      "        \n",
      "        :return: the parameter value that is logged.\n",
      "        \n",
      "        .. test-code-block:: python\n",
      "            :caption: Example\n",
      "        \n",
      "            import mlflow\n",
      "        \n",
      "            with mlflow.start_run():\n",
      "                value = mlflow.log_param(\"learning_rate\", 0.01)\n",
      "                assert value == 0.01\n",
      "    \n",
      "    log_params(params: Dict[str, Any]) -> None\n",
      "        Log a batch of params for the current run. If no run is active, this method will create a\n",
      "        new active run.\n",
      "        \n",
      "        :param params: Dictionary of param_name: String -> value: (String, but will be string-ified if\n",
      "                       not)\n",
      "        :returns: None\n",
      "        \n",
      "        .. test-code-block:: python\n",
      "            :caption: Example\n",
      "        \n",
      "            import mlflow\n",
      "        \n",
      "            params = {\"learning_rate\": 0.01, \"n_estimators\": 10}\n",
      "        \n",
      "            # Log a batch of parameters\n",
      "            with mlflow.start_run():\n",
      "                mlflow.log_params(params)\n",
      "    \n",
      "    log_text(text: str, artifact_file: str) -> None\n",
      "        Log text as an artifact.\n",
      "        \n",
      "        :param text: String containing text to log.\n",
      "        :param artifact_file: The run-relative artifact file path in posixpath format to which\n",
      "                              the text is saved (e.g. \"dir/file.txt\").\n",
      "        \n",
      "        .. test-code-block:: python\n",
      "            :caption: Example\n",
      "        \n",
      "            import mlflow\n",
      "        \n",
      "            with mlflow.start_run():\n",
      "                # Log text to a file under the run's root artifact directory\n",
      "                mlflow.log_text(\"text1\", \"file1.txt\")\n",
      "        \n",
      "                # Log text in a subdirectory of the run's root artifact directory\n",
      "                mlflow.log_text(\"text2\", \"dir/file2.txt\")\n",
      "        \n",
      "                # Log HTML text\n",
      "                mlflow.log_text(\"<h1>header</h1>\", \"index.html\")\n",
      "    \n",
      "    register_model(model_uri, name, await_registration_for=300, *, tags: Optional[Dict[str, Any]] = None) -> mlflow.entities.model_registry.model_version.ModelVersion\n",
      "        Create a new model version in model registry for the model files specified by ``model_uri``.\n",
      "        Note that this method assumes the model registry backend URI is the same as that of the\n",
      "        tracking backend.\n",
      "        \n",
      "        :param model_uri: URI referring to the MLmodel directory. Use a ``runs:/`` URI if you want to\n",
      "                          record the run ID with the model in model registry. ``models:/`` URIs are\n",
      "                          currently not supported.\n",
      "        :param name: Name of the registered model under which to create a new model version. If a\n",
      "                     registered model with the given name does not exist, it will be created\n",
      "                     automatically.\n",
      "        :param await_registration_for: Number of seconds to wait for the model version to finish\n",
      "                                being created and is in ``READY`` status. By default, the function\n",
      "                                waits for five minutes. Specify 0 or None to skip waiting.\n",
      "        :param tags: A dictionary of key-value pairs that are converted into\n",
      "                     :py:class:`mlflow.entities.model_registry.ModelVersionTag` objects.\n",
      "        :return: Single :py:class:`mlflow.entities.model_registry.ModelVersion` object created by\n",
      "                 backend.\n",
      "        \n",
      "        .. test-code-block:: python\n",
      "            :caption: Example\n",
      "        \n",
      "            import mlflow.sklearn\n",
      "            from sklearn.ensemble import RandomForestRegressor\n",
      "        \n",
      "            mlflow.set_tracking_uri(\"sqlite:////tmp/mlruns.db\")\n",
      "            params = {\"n_estimators\": 3, \"random_state\": 42}\n",
      "        \n",
      "            # Log MLflow entities\n",
      "            with mlflow.start_run() as run:\n",
      "                rfr = RandomForestRegressor(**params).fit([[0, 1]], [1])\n",
      "                mlflow.log_params(params)\n",
      "                mlflow.sklearn.log_model(rfr, artifact_path=\"sklearn-model\")\n",
      "        \n",
      "            model_uri = \"runs:/{}/sklearn-model\".format(run.info.run_id)\n",
      "            mv = mlflow.register_model(model_uri, \"RandomForestRegressionModel\")\n",
      "            print(\"Name: {}\".format(mv.name))\n",
      "            print(\"Version: {}\".format(mv.version))\n",
      "        \n",
      "        .. code-block:: text\n",
      "            :caption: Output\n",
      "        \n",
      "            Name: RandomForestRegressionModel\n",
      "            Version: 1\n",
      "    \n",
      "    run(uri, entry_point='main', version=None, parameters=None, docker_args=None, experiment_name=None, experiment_id=None, backend='local', backend_config=None, storage_dir=None, synchronous=True, run_id=None, run_name=None, env_manager=None, build_image=False, docker_auth=None)\n",
      "        Run an MLflow project. The project can be local or stored at a Git URI.\n",
      "        \n",
      "        MLflow provides built-in support for running projects locally or remotely on a Databricks or\n",
      "        Kubernetes cluster. You can also run projects against other targets by installing an appropriate\n",
      "        third-party plugin. See `Community Plugins <../plugins.html#community-plugins>`_ for more\n",
      "        information.\n",
      "        \n",
      "        For information on using this method in chained workflows, see `Building Multistep Workflows\n",
      "        <../projects.html#building-multistep-workflows>`_.\n",
      "        \n",
      "        :raises: :py:class:`mlflow.exceptions.ExecutionException` If a run launched in blocking mode\n",
      "                 is unsuccessful.\n",
      "        \n",
      "        :param uri: URI of project to run. A local filesystem path\n",
      "                    or a Git repository URI (e.g. https://github.com/mlflow/mlflow-example)\n",
      "                    pointing to a project directory containing an MLproject file.\n",
      "        :param entry_point: Entry point to run within the project. If no entry point with the specified\n",
      "                            name is found, runs the project file ``entry_point`` as a script,\n",
      "                            using \"python\" to run ``.py`` files and the default shell (specified by\n",
      "                            environment variable ``$SHELL``) to run ``.sh`` files.\n",
      "        :param version: For Git-based projects, either a commit hash or a branch name.\n",
      "        :param parameters: Parameters (dictionary) for the entry point command.\n",
      "        :param docker_args: Arguments (dictionary) for the docker command.\n",
      "        :param experiment_name: Name of experiment under which to launch the run.\n",
      "        :param experiment_id: ID of experiment under which to launch the run.\n",
      "        :param backend: Execution backend for the run: MLflow provides built-in support for \"local\",\n",
      "                        \"databricks\", and \"kubernetes\" (experimental) backends. If running against\n",
      "                        Databricks, will run against a Databricks workspace determined as follows:\n",
      "                        if a Databricks tracking URI of the form ``databricks://profile`` has been set\n",
      "                        (e.g. by setting the MLFLOW_TRACKING_URI environment variable), will run\n",
      "                        against the workspace specified by <profile>. Otherwise, runs against the\n",
      "                        workspace specified by the default Databricks CLI profile.\n",
      "        :param backend_config: A dictionary, or a path to a JSON file (must end in '.json'), which will\n",
      "                               be passed as config to the backend. The exact content which should be\n",
      "                               provided is different for each execution backend and is documented\n",
      "                               at https://www.mlflow.org/docs/latest/projects.html.\n",
      "        :param storage_dir: Used only if ``backend`` is \"local\". MLflow downloads artifacts from\n",
      "                            distributed URIs passed to parameters of type ``path`` to subdirectories of\n",
      "                            ``storage_dir``.\n",
      "        :param synchronous: Whether to block while waiting for a run to complete. Defaults to True.\n",
      "                            Note that if ``synchronous`` is False and ``backend`` is \"local\", this\n",
      "                            method will return, but the current process will block when exiting until\n",
      "                            the local run completes. If the current process is interrupted, any\n",
      "                            asynchronous runs launched via this method will be terminated. If\n",
      "                            ``synchronous`` is True and the run fails, the current process will\n",
      "                            error out as well.\n",
      "        :param run_id: Note: this argument is used internally by the MLflow project APIs and should\n",
      "                       not be specified. If specified, the run ID will be used instead of\n",
      "                       creating a new run.\n",
      "        :param run_name: The name to give the MLflow Run associated with the project execution.\n",
      "                         If ``None``, the MLflow Run name is left unset.\n",
      "        :param env_manager: Specify an environment manager to create a new environment for the run and\n",
      "                            install project dependencies within that environment. The following values\n",
      "                            are supported:\n",
      "        \n",
      "                            - local: use the local environment\n",
      "                            - virtualenv: use virtualenv (and pyenv for Python version management)\n",
      "                            - conda: use conda\n",
      "        \n",
      "                            If unspecified, MLflow automatically determines the environment manager to\n",
      "                            use by inspecting files in the project directory. For example, if\n",
      "                            ``python_env.yaml`` is present, virtualenv will be used.\n",
      "        :param build_image: Whether to build a new docker image of the project or to reuse an existing\n",
      "                            image. Default: False (reuse an existing image)\n",
      "        :param docker_auth: A dictionary representing information to authenticate with a Docker\n",
      "                            registry. See `docker.client.DockerClient.login\n",
      "                            <https://docker-py.readthedocs.io/en/stable/client.html#docker.client.DockerClient.login>`_\n",
      "                            for available options.\n",
      "        :return: :py:class:`mlflow.projects.SubmittedRun` exposing information (e.g. run ID)\n",
      "                 about the launched run.\n",
      "        \n",
      "        .. code-block:: python\n",
      "            :caption: Example\n",
      "        \n",
      "            import mlflow\n",
      "        \n",
      "            project_uri = \"https://github.com/mlflow/mlflow-example\"\n",
      "            params = {\"alpha\": 0.5, \"l1_ratio\": 0.01}\n",
      "        \n",
      "            # Run MLflow project and create a reproducible conda environment\n",
      "            # on a local host\n",
      "            mlflow.run(project_uri, parameters=params)\n",
      "        \n",
      "        .. code-block:: text\n",
      "            :caption: Output\n",
      "        \n",
      "            ...\n",
      "            ...\n",
      "            Elasticnet model (alpha=0.500000, l1_ratio=0.010000):\n",
      "            RMSE: 0.788347345611717\n",
      "            MAE: 0.6155576449938276\n",
      "            R2: 0.19729662005412607\n",
      "            ... mlflow.projects: === Run (ID '6a5109febe5e4a549461e149590d0a7c') succeeded ===\n",
      "    \n",
      "    search_experiments(view_type: int = 1, max_results: Optional[int] = None, filter_string: Optional[str] = None, order_by: Optional[List[str]] = None) -> List[mlflow.entities.experiment.Experiment]\n",
      "        Search for experiments that match the specified search query.\n",
      "        \n",
      "        :param view_type: One of enum values ``ACTIVE_ONLY``, ``DELETED_ONLY``, or ``ALL``\n",
      "                          defined in :py:class:`mlflow.entities.ViewType`.\n",
      "        :param max_results: If passed, specifies the maximum number of experiments desired. If not\n",
      "                            passed, all experiments will be returned.\n",
      "        :param filter_string:\n",
      "            Filter query string (e.g., ``\"name = 'my_experiment'\"``), defaults to searching for all\n",
      "            experiments. The following identifiers, comparators, and logical operators are supported.\n",
      "        \n",
      "            Identifiers\n",
      "              - ``name``: Experiment name\n",
      "              - ``creation_time``: Experiment creation time\n",
      "              - ``last_update_time``: Experiment last update time\n",
      "              - ``tags.<tag_key>``: Experiment tag. If ``tag_key`` contains\n",
      "                spaces, it must be wrapped with backticks (e.g., ``\"tags.`extra key`\"``).\n",
      "        \n",
      "            Comparators for string attributes and tags\n",
      "                - ``=``: Equal to\n",
      "                - ``!=``: Not equal to\n",
      "                - ``LIKE``: Case-sensitive pattern match\n",
      "                - ``ILIKE``: Case-insensitive pattern match\n",
      "        \n",
      "            Comparators for numeric attributes\n",
      "                - ``=``: Equal to\n",
      "                - ``!=``: Not equal to\n",
      "                - ``<``: Less than\n",
      "                - ``<=``: Less than or equal to\n",
      "                - ``>``: Greater than\n",
      "                - ``>=``: Greater than or equal to\n",
      "        \n",
      "            Logical operators\n",
      "              - ``AND``: Combines two sub-queries and returns True if both of them are True.\n",
      "        \n",
      "        :param order_by:\n",
      "            List of columns to order by. The ``order_by`` column can contain an optional ``DESC`` or\n",
      "            ``ASC`` value (e.g., ``\"name DESC\"``). The default ordering is ``ASC``, so ``\"name\"`` is\n",
      "            equivalent to ``\"name ASC\"``. If unspecified, defaults to ``[\"last_update_time DESC\"]``,\n",
      "            which lists experiments updated most recently first. The following fields are supported:\n",
      "        \n",
      "                - ``experiment_id``: Experiment ID\n",
      "                - ``name``: Experiment name\n",
      "                - ``creation_time``: Experiment creation time\n",
      "                - ``last_update_time``: Experiment last update time\n",
      "        \n",
      "        :return: A list of :py:class:`Experiment <mlflow.entities.Experiment>` objects.\n",
      "        \n",
      "        .. test-code-block:: python\n",
      "            :caption: Example\n",
      "        \n",
      "            import mlflow\n",
      "        \n",
      "        \n",
      "            def assert_experiment_names_equal(experiments, expected_names):\n",
      "                actual_names = [e.name for e in experiments if e.name != \"Default\"]\n",
      "                assert actual_names == expected_names, (actual_names, expected_names)\n",
      "        \n",
      "        \n",
      "            mlflow.set_tracking_uri(\"sqlite:///:memory:\")\n",
      "        \n",
      "            # Create experiments\n",
      "            for name, tags in [\n",
      "                (\"a\", None),\n",
      "                (\"b\", None),\n",
      "                (\"ab\", {\"k\": \"v\"}),\n",
      "                (\"bb\", {\"k\": \"V\"}),\n",
      "            ]:\n",
      "                mlflow.create_experiment(name, tags=tags)\n",
      "        \n",
      "            # Search for experiments with name \"a\"\n",
      "            experiments = mlflow.search_experiments(filter_string=\"name = 'a'\")\n",
      "            assert_experiment_names_equal(experiments, [\"a\"])\n",
      "        \n",
      "            # Search for experiments with name starting with \"a\"\n",
      "            experiments = mlflow.search_experiments(filter_string=\"name LIKE 'a%'\")\n",
      "            assert_experiment_names_equal(experiments, [\"ab\", \"a\"])\n",
      "        \n",
      "            # Search for experiments with tag key \"k\" and value ending with \"v\" or \"V\"\n",
      "            experiments = mlflow.search_experiments(filter_string=\"tags.k ILIKE '%v'\")\n",
      "            assert_experiment_names_equal(experiments, [\"bb\", \"ab\"])\n",
      "        \n",
      "            # Search for experiments with name ending with \"b\" and tag {\"k\": \"v\"}\n",
      "            experiments = mlflow.search_experiments(filter_string=\"name LIKE '%b' AND tags.k = 'v'\")\n",
      "            assert_experiment_names_equal(experiments, [\"ab\"])\n",
      "        \n",
      "            # Sort experiments by name in ascending order\n",
      "            experiments = mlflow.search_experiments(order_by=[\"name\"])\n",
      "            assert_experiment_names_equal(experiments, [\"a\", \"ab\", \"b\", \"bb\"])\n",
      "        \n",
      "            # Sort experiments by ID in descending order\n",
      "            experiments = mlflow.search_experiments(order_by=[\"experiment_id DESC\"])\n",
      "            assert_experiment_names_equal(experiments, [\"bb\", \"ab\", \"b\", \"a\"])\n",
      "    \n",
      "    search_registered_models(max_results: Optional[int] = None, filter_string: Optional[str] = None, order_by: Optional[List[str]] = None) -> List[mlflow.entities.model_registry.registered_model.RegisteredModel]\n",
      "        Search for registered models that satisfy the filter criteria.\n",
      "        \n",
      "        :param filter_string: Filter query string\n",
      "            (e.g., ``\"name = 'a_model_name' and tag.key = 'value1'\"``),\n",
      "            defaults to searching for all registered models. The following identifiers, comparators,\n",
      "            and logical operators are supported.\n",
      "        \n",
      "            Identifiers\n",
      "              - ``name``: registered model name.\n",
      "              - ``tags.<tag_key>``: registered model tag. If ``tag_key`` contains spaces, it must be\n",
      "                wrapped with backticks (e.g., ``\"tags.`extra key`\"``).\n",
      "        \n",
      "            Comparators\n",
      "              - ``=``: Equal to.\n",
      "              - ``!=``: Not equal to.\n",
      "              - ``LIKE``: Case-sensitive pattern match.\n",
      "              - ``ILIKE``: Case-insensitive pattern match.\n",
      "        \n",
      "            Logical operators\n",
      "              - ``AND``: Combines two sub-queries and returns True if both of them are True.\n",
      "        \n",
      "        :param max_results: If passed, specifies the maximum number of models desired. If not\n",
      "                            passed, all models will be returned.\n",
      "        :param order_by: List of column names with ASC|DESC annotation, to be used for ordering\n",
      "                         matching search results.\n",
      "        :return: A list of :py:class:`mlflow.entities.model_registry.RegisteredModel` objects\n",
      "                 that satisfy the search expressions.\n",
      "        \n",
      "        .. test-code-block:: python\n",
      "            :caption: Example\n",
      "        \n",
      "            import mlflow\n",
      "            from sklearn.linear_model import LogisticRegression\n",
      "        \n",
      "            with mlflow.start_run():\n",
      "                mlflow.sklearn.log_model(\n",
      "                    LogisticRegression(),\n",
      "                    \"Cordoba\",\n",
      "                    registered_model_name=\"CordobaWeatherForecastModel\",\n",
      "                )\n",
      "                mlflow.sklearn.log_model(\n",
      "                    LogisticRegression(),\n",
      "                    \"Boston\",\n",
      "                    registered_model_name=\"BostonWeatherForecastModel\",\n",
      "                )\n",
      "        \n",
      "            # Get search results filtered by the registered model name\n",
      "            filter_string = \"name = 'CordobaWeatherForecastModel'\"\n",
      "            results = mlflow.search_registered_models(filter_string=filter_string)\n",
      "            print(\"-\" * 80)\n",
      "            for res in results:\n",
      "                for mv in res.latest_versions:\n",
      "                    print(\"name={}; run_id={}; version={}\".format(mv.name, mv.run_id, mv.version))\n",
      "        \n",
      "            # Get search results filtered by the registered model name that matches\n",
      "            # prefix pattern\n",
      "            filter_string = \"name LIKE 'Boston%'\"\n",
      "            results = mlflow.search_registered_models(filter_string=filter_string)\n",
      "            print(\"-\" * 80)\n",
      "            for res in results:\n",
      "                for mv in res.latest_versions:\n",
      "                    print(\"name={}; run_id={}; version={}\".format(mv.name, mv.run_id, mv.version))\n",
      "        \n",
      "            # Get all registered models and order them by ascending order of the names\n",
      "            results = mlflow.search_registered_models(order_by=[\"name ASC\"])\n",
      "            print(\"-\" * 80)\n",
      "            for res in results:\n",
      "                for mv in res.latest_versions:\n",
      "                    print(\"name={}; run_id={}; version={}\".format(mv.name, mv.run_id, mv.version))\n",
      "        \n",
      "        .. code-block:: text\n",
      "            :caption: Output\n",
      "        \n",
      "            --------------------------------------------------------------------------------\n",
      "            name=CordobaWeatherForecastModel; run_id=248c66a666744b4887bdeb2f9cf7f1c6; version=1\n",
      "            --------------------------------------------------------------------------------\n",
      "            name=BostonWeatherForecastModel; run_id=248c66a666744b4887bdeb2f9cf7f1c6; version=1\n",
      "            --------------------------------------------------------------------------------\n",
      "            name=BostonWeatherForecastModel; run_id=248c66a666744b4887bdeb2f9cf7f1c6; version=1\n",
      "            name=CordobaWeatherForecastModel; run_id=248c66a666744b4887bdeb2f9cf7f1c6; version=1\n",
      "    \n",
      "    search_runs(experiment_ids: Optional[List[str]] = None, filter_string: str = '', run_view_type: int = 1, max_results: int = 100000, order_by: Optional[List[str]] = None, output_format: str = 'pandas', search_all_experiments: bool = False, experiment_names: Optional[List[str]] = None) -> Union[List[mlflow.entities.run.Run], ForwardRef('pandas.DataFrame')]\n",
      "        Search for Runs that fit the specified criteria.\n",
      "        \n",
      "        :param experiment_ids: List of experiment IDs. Search can work with experiment IDs or\n",
      "                               experiment names, but not both in the same call. Values other than\n",
      "                               ``None`` or ``[]`` will result in error if ``experiment_names`` is\n",
      "                               also not ``None`` or ``[]``. ``None`` will default to the active\n",
      "                               experiment if ``experiment_names`` is ``None`` or ``[]``.\n",
      "        :param filter_string: Filter query string, defaults to searching all runs.\n",
      "        :param run_view_type: one of enum values ``ACTIVE_ONLY``, ``DELETED_ONLY``, or ``ALL`` runs\n",
      "                                defined in :py:class:`mlflow.entities.ViewType`.\n",
      "        :param max_results: The maximum number of runs to put in the dataframe. Default is 100,000\n",
      "                            to avoid causing out-of-memory issues on the user's machine.\n",
      "        :param order_by: List of columns to order by (e.g., \"metrics.rmse\"). The ``order_by`` column\n",
      "                         can contain an optional ``DESC`` or ``ASC`` value. The default is ``ASC``.\n",
      "                         The default ordering is to sort by ``start_time DESC``, then ``run_id``.\n",
      "        :param output_format: The output format to be returned. If ``pandas``, a ``pandas.DataFrame``\n",
      "                              is returned and, if ``list``, a list of :py:class:`mlflow.entities.Run`\n",
      "                              is returned.\n",
      "        :param search_all_experiments: Boolean specifying whether all experiments should be searched.\n",
      "            Only honored if ``experiment_ids`` is ``[]`` or ``None``.\n",
      "        :param experiment_names: List of experiment names. Search can work with experiment IDs or\n",
      "                                 experiment names, but not both in the same call. Values other\n",
      "                                 than ``None`` or ``[]`` will result in error if ``experiment_ids``\n",
      "                                 is also not ``None`` or ``[]``. ``None`` will default to the active\n",
      "                                 experiment if ``experiment_ids`` is ``None`` or ``[]``.\n",
      "        :return: If output_format is ``list``: a list of :py:class:`mlflow.entities.Run`. If\n",
      "                 output_format is ``pandas``: ``pandas.DataFrame`` of runs, where each metric,\n",
      "                 parameter, and tag is expanded into its own column named metrics.*, params.*, or\n",
      "                 tags.* respectively. For runs that don't have a particular metric, parameter, or tag,\n",
      "                 the value for the corresponding column is (NumPy) ``Nan``, ``None``, or ``None``\n",
      "                 respectively.\n",
      "        \n",
      "        .. test-code-block:: python\n",
      "            :caption: Example\n",
      "        \n",
      "            import mlflow\n",
      "        \n",
      "            # Create an experiment and log two runs under it\n",
      "            experiment_name = \"Social NLP Experiments\"\n",
      "            experiment_id = mlflow.create_experiment(experiment_name)\n",
      "            with mlflow.start_run(experiment_id=experiment_id):\n",
      "                mlflow.log_metric(\"m\", 1.55)\n",
      "                mlflow.set_tag(\"s.release\", \"1.1.0-RC\")\n",
      "            with mlflow.start_run(experiment_id=experiment_id):\n",
      "                mlflow.log_metric(\"m\", 2.50)\n",
      "                mlflow.set_tag(\"s.release\", \"1.2.0-GA\")\n",
      "        \n",
      "            # Search for all the runs in the experiment with the given experiment ID\n",
      "            df = mlflow.search_runs([experiment_id], order_by=[\"metrics.m DESC\"])\n",
      "            print(df[[\"metrics.m\", \"tags.s.release\", \"run_id\"]])\n",
      "            print(\"--\")\n",
      "        \n",
      "            # Search the experiment_id using a filter_string with tag\n",
      "            # that has a case insensitive pattern\n",
      "            filter_string = \"tags.s.release ILIKE '%rc%'\"\n",
      "            df = mlflow.search_runs([experiment_id], filter_string=filter_string)\n",
      "            print(df[[\"metrics.m\", \"tags.s.release\", \"run_id\"]])\n",
      "            print(\"--\")\n",
      "        \n",
      "            # Search for all the runs in the experiment with the given experiment name\n",
      "            df = mlflow.search_runs(experiment_names=[experiment_name], order_by=[\"metrics.m DESC\"])\n",
      "            print(df[[\"metrics.m\", \"tags.s.release\", \"run_id\"]])\n",
      "        \n",
      "        \n",
      "        .. code-block:: text\n",
      "            :caption: Output\n",
      "        \n",
      "               metrics.m tags.s.release                            run_id\n",
      "            0       2.50       1.2.0-GA  147eed886ab44633902cc8e19b2267e2\n",
      "            1       1.55       1.1.0-RC  5cc7feaf532f496f885ad7750809c4d4\n",
      "            --\n",
      "               metrics.m tags.s.release                            run_id\n",
      "            0       1.55       1.1.0-RC  5cc7feaf532f496f885ad7750809c4d4\n",
      "            --\n",
      "               metrics.m tags.s.release                            run_id\n",
      "            0       2.50       1.2.0-GA  147eed886ab44633902cc8e19b2267e2\n",
      "            1       1.55       1.1.0-RC  5cc7feaf532f496f885ad7750809c4d4\n",
      "    \n",
      "    set_experiment(experiment_name: str = None, experiment_id: str = None) -> mlflow.entities.experiment.Experiment\n",
      "        Set the given experiment as the active experiment. The experiment must either be specified by\n",
      "        name via `experiment_name` or by ID via `experiment_id`. The experiment name and ID cannot\n",
      "        both be specified.\n",
      "        \n",
      "        :param experiment_name: Case sensitive name of the experiment to be activated. If an experiment\n",
      "                                with this name does not exist, a new experiment wth this name is\n",
      "                                created.\n",
      "        :param experiment_id: ID of the experiment to be activated. If an experiment with this ID\n",
      "                              does not exist, an exception is thrown.\n",
      "        :return: An instance of :py:class:`mlflow.entities.Experiment` representing the new active\n",
      "                 experiment.\n",
      "        \n",
      "        .. test-code-block:: python\n",
      "            :caption: Example\n",
      "        \n",
      "            import mlflow\n",
      "        \n",
      "            # Set an experiment name, which must be unique and case-sensitive.\n",
      "            experiment = mlflow.set_experiment(\"Social NLP Experiments\")\n",
      "        \n",
      "            # Get Experiment Details\n",
      "            print(\"Experiment_id: {}\".format(experiment.experiment_id))\n",
      "            print(\"Artifact Location: {}\".format(experiment.artifact_location))\n",
      "            print(\"Tags: {}\".format(experiment.tags))\n",
      "            print(\"Lifecycle_stage: {}\".format(experiment.lifecycle_stage))\n",
      "        \n",
      "        .. code-block:: text\n",
      "            :caption: Output\n",
      "        \n",
      "            Experiment_id: 1\n",
      "            Artifact Location: file:///.../mlruns/1\n",
      "            Tags: {}\n",
      "            Lifecycle_stage: active\n",
      "    \n",
      "    set_experiment_tag(key: str, value: Any) -> None\n",
      "        Set a tag on the current experiment. Value is converted to a string.\n",
      "        \n",
      "        :param key: Tag name (string). This string may only contain alphanumerics, underscores\n",
      "                    (_), dashes (-), periods (.), spaces ( ), and slashes (/).\n",
      "                    All backend stores will support keys up to length 250, but some may\n",
      "                    support larger keys.\n",
      "        :param value: Tag value (string, but will be string-ified if not).\n",
      "                      All backend stores will support values up to length 5000, but some\n",
      "                      may support larger values.\n",
      "        \n",
      "        .. test-code-block:: python\n",
      "            :caption: Example\n",
      "        \n",
      "            import mlflow\n",
      "        \n",
      "            with mlflow.start_run():\n",
      "                mlflow.set_experiment_tag(\"release.version\", \"2.2.0\")\n",
      "    \n",
      "    set_experiment_tags(tags: Dict[str, Any]) -> None\n",
      "        Set tags for the current active experiment.\n",
      "        \n",
      "        :param tags: Dictionary containing tag names and corresponding values.\n",
      "        \n",
      "        .. test-code-block:: python\n",
      "            :caption: Example\n",
      "        \n",
      "            import mlflow\n",
      "        \n",
      "            tags = {\n",
      "                \"engineering\": \"ML Platform\",\n",
      "                \"release.candidate\": \"RC1\",\n",
      "                \"release.version\": \"2.2.0\",\n",
      "            }\n",
      "        \n",
      "            # Set a batch of tags\n",
      "            with mlflow.start_run():\n",
      "                mlflow.set_experiment_tags(tags)\n",
      "    \n",
      "    set_registry_uri(uri: str) -> None\n",
      "        Set the registry server URI. This method is especially useful if you have a registry server\n",
      "        that's different from the tracking server.\n",
      "        \n",
      "        :param uri:\n",
      "        \n",
      "                    - An empty string, or a local file path, prefixed with ``file:/``. Data is stored\n",
      "                      locally at the provided file (or ``./mlruns`` if empty).\n",
      "                    - An HTTP URI like ``https://my-tracking-server:5000``.\n",
      "                    - A Databricks workspace, provided as the string \"databricks\" or, to use a\n",
      "                      Databricks CLI\n",
      "                      `profile <https://github.com/databricks/databricks-cli#installation>`_,\n",
      "                      \"databricks://<profileName>\".\n",
      "        \n",
      "        .. code-block:: python\n",
      "            :caption: Example\n",
      "        \n",
      "            import mflow\n",
      "        \n",
      "            # Set model registry uri, fetch the set uri, and compare\n",
      "            # it with the tracking uri. They should be different\n",
      "            mlflow.set_registry_uri(\"sqlite:////tmp/registry.db\")\n",
      "            mr_uri = mlflow.get_registry_uri()\n",
      "            print(\"Current registry uri: {}\".format(mr_uri))\n",
      "            tracking_uri = mlflow.get_tracking_uri()\n",
      "            print(\"Current tracking uri: {}\".format(tracking_uri))\n",
      "        \n",
      "            # They should be different\n",
      "            assert tracking_uri != mr_uri\n",
      "        \n",
      "        .. code-block:: text\n",
      "            :caption: Output\n",
      "        \n",
      "            Current registry uri: sqlite:////tmp/registry.db\n",
      "            Current tracking uri: file:///.../mlruns\n",
      "    \n",
      "    set_tag(key: str, value: Any) -> None\n",
      "        Set a tag under the current run. If no run is active, this method will create a\n",
      "        new active run.\n",
      "        \n",
      "        :param key: Tag name (string). This string may only contain alphanumerics, underscores\n",
      "                    (_), dashes (-), periods (.), spaces ( ), and slashes (/).\n",
      "                    All backend stores will support keys up to length 250, but some may\n",
      "                    support larger keys.\n",
      "        :param value: Tag value (string, but will be string-ified if not).\n",
      "                      All backend stores will support values up to length 5000, but some\n",
      "                      may support larger values.\n",
      "        \n",
      "        .. test-code-block:: python\n",
      "            :caption: Example\n",
      "        \n",
      "            import mlflow\n",
      "        \n",
      "            with mlflow.start_run():\n",
      "                mlflow.set_tag(\"release.version\", \"2.2.0\")\n",
      "    \n",
      "    set_tags(tags: Dict[str, Any]) -> None\n",
      "        Log a batch of tags for the current run. If no run is active, this method will create a\n",
      "        new active run.\n",
      "        \n",
      "        :param tags: Dictionary of tag_name: String -> value: (String, but will be string-ified if\n",
      "                     not)\n",
      "        :returns: None\n",
      "        \n",
      "        .. test-code-block:: python\n",
      "            :caption: Example\n",
      "        \n",
      "            import mlflow\n",
      "        \n",
      "            tags = {\n",
      "                \"engineering\": \"ML Platform\",\n",
      "                \"release.candidate\": \"RC1\",\n",
      "                \"release.version\": \"2.2.0\",\n",
      "            }\n",
      "        \n",
      "            # Set a batch of tags\n",
      "            with mlflow.start_run():\n",
      "                mlflow.set_tags(tags)\n",
      "    \n",
      "    set_tracking_uri(uri: Union[str, pathlib.Path]) -> None\n",
      "        Set the tracking server URI. This does not affect the\n",
      "        currently active run (if one exists), but takes effect for successive runs.\n",
      "        \n",
      "        :param uri:\n",
      "        \n",
      "                    - An empty string, or a local file path, prefixed with ``file:/``. Data is stored\n",
      "                      locally at the provided file (or ``./mlruns`` if empty).\n",
      "                    - An HTTP URI like ``https://my-tracking-server:5000``.\n",
      "                    - A Databricks workspace, provided as the string \"databricks\" or, to use a\n",
      "                      Databricks CLI\n",
      "                      `profile <https://github.com/databricks/databricks-cli#installation>`_,\n",
      "                      \"databricks://<profileName>\".\n",
      "                    - A :py:class:`pathlib.Path` instance\n",
      "        \n",
      "        .. test-code-block:: python\n",
      "            :caption: Example\n",
      "        \n",
      "            import mlflow\n",
      "        \n",
      "            mlflow.set_tracking_uri(\"file:///tmp/my_tracking\")\n",
      "            tracking_uri = mlflow.get_tracking_uri()\n",
      "            print(\"Current tracking uri: {}\".format(tracking_uri))\n",
      "        \n",
      "        .. code-block:: text\n",
      "            :caption: Output\n",
      "        \n",
      "            Current tracking uri: file:///tmp/my_tracking\n",
      "    \n",
      "    start_run(run_id: str = None, experiment_id: Optional[str] = None, run_name: Optional[str] = None, nested: bool = False, tags: Optional[Dict[str, Any]] = None, description: Optional[str] = None) -> mlflow.tracking.fluent.ActiveRun\n",
      "        Start a new MLflow run, setting it as the active run under which metrics and parameters\n",
      "        will be logged. The return value can be used as a context manager within a ``with`` block;\n",
      "        otherwise, you must call ``end_run()`` to terminate the current run.\n",
      "        \n",
      "        If you pass a ``run_id`` or the ``MLFLOW_RUN_ID`` environment variable is set,\n",
      "        ``start_run`` attempts to resume a run with the specified run ID and\n",
      "        other parameters are ignored. ``run_id`` takes precedence over ``MLFLOW_RUN_ID``.\n",
      "        \n",
      "        If resuming an existing run, the run status is set to ``RunStatus.RUNNING``.\n",
      "        \n",
      "        MLflow sets a variety of default tags on the run, as defined in\n",
      "        :ref:`MLflow system tags <system_tags>`.\n",
      "        \n",
      "        :param run_id: If specified, get the run with the specified UUID and log parameters\n",
      "                         and metrics under that run. The run's end time is unset and its status\n",
      "                         is set to running, but the run's other attributes (``source_version``,\n",
      "                         ``source_type``, etc.) are not changed.\n",
      "        :param experiment_id: ID of the experiment under which to create the current run (applicable\n",
      "                              only when ``run_id`` is not specified). If ``experiment_id`` argument\n",
      "                              is unspecified, will look for valid experiment in the following order:\n",
      "                              activated using ``set_experiment``, ``MLFLOW_EXPERIMENT_NAME``\n",
      "                              environment variable, ``MLFLOW_EXPERIMENT_ID`` environment variable,\n",
      "                              or the default experiment as defined by the tracking server.\n",
      "        :param run_name: Name of new run.\n",
      "                         Used only when ``run_id`` is unspecified. If a new run is created and\n",
      "                         ``run_name`` is not specified, a unique name will be generated for the run.\n",
      "        :param nested: Controls whether run is nested in parent run. ``True`` creates a nested run.\n",
      "        :param tags: An optional dictionary of string keys and values to set as tags on the run.\n",
      "                     If a run is being resumed, these tags are set on the resumed run. If a new run is\n",
      "                     being created, these tags are set on the new run.\n",
      "        :param description: An optional string that populates the description box of the run.\n",
      "                            If a run is being resumed, the description is set on the resumed run.\n",
      "                            If a new run is being created, the description is set on the new run.\n",
      "        :return: :py:class:`mlflow.ActiveRun` object that acts as a context manager wrapping\n",
      "                 the run's state.\n",
      "        \n",
      "        .. test-code-block:: python\n",
      "            :caption: Example\n",
      "        \n",
      "            import mlflow\n",
      "        \n",
      "            # Create nested runs\n",
      "            experiment_id = mlflow.create_experiment(\"experiment1\")\n",
      "            with mlflow.start_run(\n",
      "                run_name=\"PARENT_RUN\",\n",
      "                experiment_id=experiment_id,\n",
      "                tags={\"version\": \"v1\", \"priority\": \"P1\"},\n",
      "                description=\"parent\",\n",
      "            ) as parent_run:\n",
      "                mlflow.log_param(\"parent\", \"yes\")\n",
      "                with mlflow.start_run(\n",
      "                    run_name=\"CHILD_RUN\",\n",
      "                    experiment_id=experiment_id,\n",
      "                    description=\"child\",\n",
      "                    nested=True,\n",
      "                ) as child_run:\n",
      "                    mlflow.log_param(\"child\", \"yes\")\n",
      "        \n",
      "            print(\"parent run:\")\n",
      "        \n",
      "            print(\"run_id: {}\".format(parent_run.info.run_id))\n",
      "            print(\"description: {}\".format(parent_run.data.tags.get(\"mlflow.note.content\")))\n",
      "            print(\"version tag value: {}\".format(parent_run.data.tags.get(\"version\")))\n",
      "            print(\"priority tag value: {}\".format(parent_run.data.tags.get(\"priority\")))\n",
      "            print(\"--\")\n",
      "        \n",
      "            # Search all child runs with a parent id\n",
      "            query = \"tags.mlflow.parentRunId = '{}'\".format(parent_run.info.run_id)\n",
      "            results = mlflow.search_runs(experiment_ids=[experiment_id], filter_string=query)\n",
      "            print(\"child runs:\")\n",
      "            print(results[[\"run_id\", \"params.child\", \"tags.mlflow.runName\"]])\n",
      "        \n",
      "        .. code-block:: text\n",
      "            :caption: Output\n",
      "        \n",
      "            parent run:\n",
      "            run_id: 8979459433a24a52ab3be87a229a9cdf\n",
      "            description: starting a parent for experiment 7\n",
      "            version tag value: v1\n",
      "            priority tag value: P1\n",
      "            --\n",
      "            child runs:\n",
      "                                         run_id params.child tags.mlflow.runName\n",
      "            0  7d175204675e40328e46d9a6a5a7ee6a          yes           CHILD_RUN\n",
      "\n",
      "DATA\n",
      "    __all__ = ['ActiveRun', 'log_param', 'log_params', 'log_metric', 'log_...\n",
      "\n",
      "VERSION\n",
      "    2.2.2\n",
      "\n",
      "FILE\n",
      "    /Users/s.porreca/.local/share/virtualenvs/cheat_sheets-EiW5VkhA/lib/python3.10/site-packages/mlflow/__init__.py\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(mlflow)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4921819e-259d-4340-a916-b95b9fa2310f",
   "metadata": {},
   "source": [
    "# Basic Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "554f7039-96d4-447b-addc-9dbe2a7baea4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023/03/19 22:38:59 INFO mlflow.tracking.fluent: Experiment with name 'basic_code' does not exist. Creating a new experiment.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Experiment: artifact_location='file:///Users/s.porreca/Projects/cheat_sheets/machine_learning/mlflow/mlruns/176222180829175951', creation_time=1679261939948, experiment_id='176222180829175951', last_update_time=1679261939948, lifecycle_stage='active', name='basic_code', tags={}>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Set experiment\n",
    "mlflow.set_experiment('basic_code')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "662bfed3-73a6-4123-8022-f8f3248a94b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLflow Run:  3918cf37c28945b38967dec892726529\n",
      "MLflow Run:  Run Name 24\n"
     ]
    }
   ],
   "source": [
    "# Start MLflow Run\n",
    "with mlflow.start_run(run_name='Run Name {}'.format(np.random.randint(1, 100))) as mlflow_run:\n",
    "    \n",
    "    # Show run ID\n",
    "    print('MLflow Run: ', mlflow_run.info.run_uuid)\n",
    "    \n",
    "    # Show Run Name\n",
    "    print('MLflow Run: ', mlflow_run.info.run_name)\n",
    "    \n",
    "    # Set a Run tag\n",
    "    mlflow.set_tag('tag', 'Tag {}'.format(np.random.randint(1, 100)))\n",
    "    \n",
    "    # Log a Parameter\n",
    "    mlflow.log_param('parameter_1', np.random.randint(1, 100))\n",
    "    \n",
    "    # Log a Metric\n",
    "    mlflow.log_metric('accuracy', np.random.randint(0, 100))\n",
    "    \n",
    "    mlflow.end_run()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "840fd790-7b1a-4f85-9d6e-b581d5492fd1",
   "metadata": {},
   "source": [
    "# Regression Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b61874d8-cc08-42d8-9f00-c333efca34cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read data\n",
    "data = pd.read_csv('./../../data/books_sold_train.csv', \n",
    "                   parse_dates=['date'], \n",
    "                   index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2c89db35-4512-41ad-923b-70a64d6359cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>country</th>\n",
       "      <th>store</th>\n",
       "      <th>product</th>\n",
       "      <th>num_sold</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>row_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2017-01-01</td>\n",
       "      <td>Belgium</td>\n",
       "      <td>KaggleMart</td>\n",
       "      <td>Kaggle Advanced Techniques</td>\n",
       "      <td>663</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2017-01-01</td>\n",
       "      <td>Belgium</td>\n",
       "      <td>KaggleMart</td>\n",
       "      <td>Kaggle Getting Started</td>\n",
       "      <td>615</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2017-01-01</td>\n",
       "      <td>Belgium</td>\n",
       "      <td>KaggleMart</td>\n",
       "      <td>Kaggle Recipe Book</td>\n",
       "      <td>480</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2017-01-01</td>\n",
       "      <td>Belgium</td>\n",
       "      <td>KaggleMart</td>\n",
       "      <td>Kaggle for Kids: One Smart Goose</td>\n",
       "      <td>710</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2017-01-01</td>\n",
       "      <td>Belgium</td>\n",
       "      <td>KaggleRama</td>\n",
       "      <td>Kaggle Advanced Techniques</td>\n",
       "      <td>240</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             date  country       store                           product  \\\n",
       "row_id                                                                     \n",
       "0      2017-01-01  Belgium  KaggleMart        Kaggle Advanced Techniques   \n",
       "1      2017-01-01  Belgium  KaggleMart            Kaggle Getting Started   \n",
       "2      2017-01-01  Belgium  KaggleMart                Kaggle Recipe Book   \n",
       "3      2017-01-01  Belgium  KaggleMart  Kaggle for Kids: One Smart Goose   \n",
       "4      2017-01-01  Belgium  KaggleRama        Kaggle Advanced Techniques   \n",
       "\n",
       "        num_sold  \n",
       "row_id            \n",
       "0            663  \n",
       "1            615  \n",
       "2            480  \n",
       "3            710  \n",
       "4            240  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "911f1962-bb48-4c0b-89e9-645732c16674",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Engineering the date\n",
    "data['day'] = data['date'].dt.day"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "884025d6-49c3-4008-bbfd-c29d3cee7eb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define features and labell\n",
    "numerical_features = ['day']\n",
    "\n",
    "categorical_features = ['product', \n",
    "                        'store', \n",
    "                        'country']\n",
    "\n",
    "labels = ['num_sold']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2db2db15-1ef5-4acd-9d8d-ef2e41006faf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Numerical features pipeline\n",
    "numerical_features_pipeline = Pipeline(steps=[\n",
    "    ('numerical_scaler', StandardScaler())\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8231922f-0718-4eea-8b9d-43e563755423",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Categorical features pipeline\n",
    "categorical_features_pipeline = Pipeline(steps=[\n",
    "    ('categorical_one_hot_encoder', OneHotEncoder(handle_unknown='ignore'))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b7b5a9df-ae25-4d33-82f1-d2537d4d720d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bunlde data preprocessing steps\n",
    "data_preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('numerical_preprocessing', numerical_features_pipeline, numerical_features),\n",
    "        ('categorical_preprocessing', categorical_features_pipeline, categorical_features)\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f46514ce-3911-4628-89ef-9f7f72ac9468",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define X and y for the training set\n",
    "X = data[numerical_features + categorical_features]\n",
    "y = data[labels]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c0f4c551-43e7-4080-9ec8-d7154124d4ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split training data into train and validation\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "636fc942-fb4d-44f4-8a95-4512bdbd4bca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define experiment name\n",
    "mlflow_experiment_name = 'Regression Example'\n",
    "\n",
    "# Create experiment or retrieve already existing experiment\n",
    "try:\n",
    "    mlflow_experiment_id = mlflow.create_experiment(name=mlflow_experiment_name)\n",
    "except Exception as e:\n",
    "    mlflow_experiment_id = mlflow.get_experiment_by_name(mlflow_experiment_name).experiment_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60f76de0-c47f-4e7a-84cf-9deb621068e4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
