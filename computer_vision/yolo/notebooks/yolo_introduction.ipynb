{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ccaca3a7-c8d0-4dba-9219-011fd83e323b",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "\n",
    "Implement YOLO usage as explained in the [reference article](https://towardsdatascience.com/yolo-object-detection-with-opencv-and-python-21e50ac599e9).\n",
    "\n",
    "<br>\n",
    "\n",
    "The model has been trained over the [COCO Dataset](https://cocodataset.org/#home)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "01978881-349a-4132-8aa2-afa4913d80a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Standard Libraries\n",
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "from urllib.request import urlretrieve\n",
    "from typing import List, Tuple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "911b345d-0771-4483-a70f-9b6ae0d8f951",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Notebook variables\n",
    "sample_image_path = './../images/dog_image_1.jpeg'\n",
    "classes_path = './../files/yolov3_classes.txt'\n",
    "nn_config_path = './../files/yolov3.cfg'\n",
    "nn_weights_url = 'https://pjreddie.com/media/files/yolov3.weights'\n",
    "nn_weights_path = './../files/yolov3.weights'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f510b96d-2c51-4b08-a856-4da6a440d948",
   "metadata": {},
   "source": [
    "# Read Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11754f8c-cafe-422b-9d86-c6aef3781129",
   "metadata": {},
   "source": [
    "## Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "621458eb-7e0b-4470-ab8d-79598a063d89",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the image with OpenCV\n",
    "image = cv2.imread(sample_image_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "380a6142-a2a7-4040-b8ca-025870408bcd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(576, 768, 3)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The image is 576 x 768 dimension in pixels\n",
    "# It has 3 channels, since it is colored (RGB)\n",
    "image.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1613c106-1df4-419a-b6c9-5566bf8116e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute image's width and height\n",
    "image_width = image.shape[1]\n",
    "image_height = image.shape[0]\n",
    "\n",
    "# Define the scale factor for each image's pixel\n",
    "scale = 0.00392"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc73f6b1-a7df-4199-97b4-a04895701d41",
   "metadata": {},
   "source": [
    " ## Classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f99a8726-a792-48a3-8a59-c4ce3660a157",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Open the classes file and extract the list of available classes\n",
    "with open(classes_path, 'r') as classes_file:\n",
    "    classes = [line.strip() for line in classes_file.readlines()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fc679149-6448-48c1-8d02-29e3231683e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate different colors for each class \n",
    "class_colors = np.random.uniform(0, 255, size=(len(classes), 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e29cfdc-61da-4853-bd14-b2c780c6ad8e",
   "metadata": {},
   "source": [
    "## Neural Network\n",
    "\n",
    "The neural network is divided into two files:\n",
    "1. **yolov3.weights** - It contains the weights of the single neuron in the Neural Network\n",
    "2. **yolov3.cfg** - It contains the structure of the Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0baa1038-19c2-4b81-9917-96ed483442cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check whatever the 'yolov3.weights' file is not present and download it\n",
    "if not os.path.isfile(nn_weights_path):\n",
    "    \n",
    "    # Download 'yolov3.weights'\n",
    "    urlretrieve(nn_weights_url, nn_weights_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eca8b0ff-ffc9-4828-8ead-d6f6cd7c92aa",
   "metadata": {},
   "source": [
    "# Model Definition"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "945838ca-d5d8-4938-a864-010b4b6072f5",
   "metadata": {},
   "source": [
    "## Create the Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8b0c5f64-775e-44e3-aa00-71f66fc31f49",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read pr-trained model and configuration file if the required files are available\n",
    "if os.path.isfile(nn_weights_path) and os.path.isfile(nn_config_path):\n",
    "    \n",
    "    neural_network = cv2.dnn.readNet(nn_weights_path, nn_config_path)\n",
    "    \n",
    "else:\n",
    "    \n",
    "    print('Missing required files: yolov3.weights and yolov3.cfg')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd3b3a73-3cfc-4472-8e69-31b3fd537a9d",
   "metadata": {},
   "source": [
    "## Create Blob Object from Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "77b61ddc-fb38-4db4-87cd-a9c40dcea670",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a 4-dimensional Blob from an image\n",
    "blob_image = cv2.dnn.blobFromImage(image=image, # Input image for the NN\n",
    "                                   size=(416,416), # Resize the image\n",
    "                                   mean=(0, 0, 0), # Do not multiply channels for their mean, set to zero\n",
    "                                   scalefactor=scale, # Scale each pixel value (swapRB switches the first and last channel)\n",
    "                                   swapRB=True, # Swap first and last channel\n",
    "                                   crop=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6a7ba5a3-f7d8-46f9-a829-62250a0039d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the Blob as Neural Network's input\n",
    "neural_network.setInput(blob_image)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "168319ba-2e75-456a-bebc-ec9738dfb6cc",
   "metadata": {},
   "source": [
    "# Utils Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1a14fdc-c180-4e20-9ea9-dda6025b6b62",
   "metadata": {},
   "source": [
    "## Draw Bounding Box"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "90d56604-21ef-444c-8f71-1d63eb20e55e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_bounding_bow(image: np.ndarray, \n",
    "                      class_id: int, \n",
    "                      point_1: Tuple[float, float], \n",
    "                      point_2: Tuple[float, float]) -> None:\n",
    "    \"\"\"\n",
    "    Draw a bounding box over the passed image from the points 1 and 2\n",
    "    \n",
    "    Parameters:\n",
    "        image: numpy.ndarray of image shape (n, m, 3)\n",
    "        class_id: Integer of class color\n",
    "        point_1: Tuple of floats for x and y coordinates\n",
    "        point_2: Tuple of floats for x and y coordinates\n",
    "    \n",
    "    Returns:\n",
    "        Draw bounding box over the image\n",
    "    \"\"\"\n",
    "    \n",
    "    # Retrieve the label\n",
    "    label = classes[class_id]\n",
    "    \n",
    "    # Retrieve the color\n",
    "    color = class_colors[class_id]\n",
    "    \n",
    "    # Draw the bounding box\n",
    "    cv2.rectangle(imgage, \n",
    "                  point_1, \n",
    "                  point_2, \n",
    "                  color, \n",
    "                  2)\n",
    "    \n",
    "    # Put the text over the bounding box\n",
    "    cv2.putText(imgage, \n",
    "                label, \n",
    "                (point_1[0] - 10, point_1[0] - 10), \n",
    "                cv2.FONT_HERSHEY_SIMPLEX, \n",
    "                0.5, \n",
    "                color, \n",
    "                2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b30c39d-a211-4c6b-8267-3c326c5bacb3",
   "metadata": {},
   "source": [
    "## Retrieve Output Layers\n",
    "\n",
    "YOLO v3 architecture has 3 output layers and it is required to retrieve their names."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "91cce75e-05f7-4e0b-ac27-2513a55939c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_output_layers(neural_network: cv2.dnn.Net) -> List:\n",
    "    \"\"\"\n",
    "    Retrieve the list of output layers names\n",
    "    \n",
    "    Parameters:\n",
    "        neural_network: cv.dnn.Net neural network instance\n",
    "        \n",
    "    Returns:\n",
    "        output_layers: List of output layers names\n",
    "    \"\"\"\n",
    "    \n",
    "    # Reitreve layer's names\n",
    "    layer_names = neural_network.getLayerNames()\n",
    "    \n",
    "    # Get output layers names since by the non-output connected ones\n",
    "    output_layers = [layer_names[i - 1] for i in neural_network.getUnconnectedOutLayers()]\n",
    "    \n",
    "    return output_layers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74c875d1-0b2c-4b66-875e-223cc717aebc",
   "metadata": {},
   "source": [
    "# Model Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5fe71449-dbaa-465a-a091-8fb9e9faf62a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute the model's output\n",
    "outputs = neural_network.forward(get_output_layers(neural_network))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d0a074c2-4b50-425e-a569-dd65578f8df2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.0356999  0.04303573 0.3919562  ... 0.         0.         0.        ]\n",
      " [0.04494962 0.03649348 0.28322312 ... 0.         0.         0.        ]\n",
      " [0.04346073 0.03806101 0.7536548  ... 0.         0.         0.        ]\n",
      " ...\n",
      " [0.9562979  0.9496912  0.3989708  ... 0.         0.         0.        ]\n",
      " [0.965184   0.96166253 0.29429185 ... 0.         0.         0.        ]\n",
      " [0.9644326  0.96320397 0.78286254 ... 0.         0.         0.        ]]\n"
     ]
    }
   ],
   "source": [
    "for output in outputs:\n",
    "    \n",
    "    for detection in output\n",
    "    \n",
    "        \n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2257cb64-ce64-42a6-a937-aadb565c2714",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "507"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4efebdd8-1dd0-4f7d-ad67-c7d03aef9789",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  },
  "toc-autonumbering": false,
  "toc-showcode": false,
  "toc-showmarkdowntxt": false
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
